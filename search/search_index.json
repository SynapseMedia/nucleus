{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started","text":""},{"location":"#nucleus","title":"Nucleus","text":"<p>NOTE! Nucleus is alpha-stage software. It means nucleus hasn't been security audited and programming APIs and data formats can still change.</p> <p>Nucleus is a collection of low-level tools for decentralized media management, that simplifies the processing, storage, and distribution of multimedia. Its key features include:</p> <ol> <li>Metadata harvesting: Simplify the extraction and collection of metadata associated with multimedia resources.</li> <li>Multimedia processing: Offers robust tools for processing multimedia content, including transcoding and image manipulation.</li> <li>Multimedia storage: Enables secure and efficient storage of multimedia files within the IPFS ecosystem.</li> <li>Metadata distribution: Facilitates seamless distribution of metadata across federated networks.</li> <li>Web3 instruments: Integrates with Web3 technologies, leveraging blockchain and smart contracts.</li> </ol> <p>These features empower users to manage multimedia content in a decentralized ecosystem, promoting greater control, privacy, and efficiency in media operations.</p>"},{"location":"#help","title":"Help","text":"<p>See documentation for more details.</p>"},{"location":"#installing","title":"Installing","text":"<p>Try nucleus! Install is simple using pip: <code>pip install nucleus-sdk</code></p> <p>Before using <code>nucleus</code>, FFmpeg and IPFS must be installed:</p> <ul> <li>Check the official docs to install IPFS.</li> <li>There are a variety of ways to install FFmpeg, such as the official download links, or using your package manager of choice (e.g. <code>sudo apt install ffmpeg</code> on Debian/Ubuntu, <code>brew install ffmpeg</code> on OS X, etc.).</li> </ul>"},{"location":"#more-info","title":"More info","text":"<ul> <li>Visit our website synapsemedia.io</li> <li>Get in touch with us in slack | discord | reddit</li> <li>For help or bugs please create an issue.</li> </ul>"},{"location":"example/","title":"Example","text":""},{"location":"example/#full-pipeline-flow","title":"Full pipeline flow","text":"<pre><code>import nucleus.core.logger as logger\nimport nucleus.sdk.harvest as harvest\nimport nucleus.sdk.processing as processing\nimport nucleus.sdk.storage as storage\nimport nucleus.sdk.expose as expose\n\nfrom nucleus.core.types import List, Path\nfrom nucleus.sdk.harvest import Image, Model\nfrom nucleus.sdk.storage import Store, Service, Client, Object\nfrom nucleus.sdk.processing import Resize, Engine, File\nfrom nucleus.sdk.expose import (\n    Structural,\n    Descriptive,\n    Technical,\n    DagJose,\n    Sign,\n    # Compact\n)\n\n\ndef main():\n\n    LOCAL_ENDPOINT = \"http://localhost:5001\"\n    FAKE_KEY = \"ESTbb693fa8-d758-48ce-9843-a8acadb98a53ARY\"\n\n    # 1. prepare our model schema to collect/validate/clean data\n    with logger.console.status(\"Harvesting\"):\n\n        class Nucleus(Model):\n            name: str\n            description: str\n            contributors: List[str]\n\n        # set our data in the model\n        nucleus: Model = Nucleus(\n            name=\"Nucleus the SDK\",\n            description=\"Building block for multimedia decentralization\",\n            contributors=[\"Jacob\", \"Geo\", \"Dennis\", \"Mark\"],\n        )\n\n    # 2. init our processing engine based on our media model\n    with logger.console.status(\"Processing\"):\n        # \"infer\" engine based on input media type\n        image: Image = harvest.image(path=Path(\"arch.png\"))\n        image_engine: Engine = processing.engine(image)\n        image_engine.configure(Resize(50, 50))\n        # finally save the processed image to our custom dir\n        output_file: File = image_engine.save(Path(\"arch2.png\"))\n\n    # 3. store our processed image in local IPFS node and pin it in estuary\n    with logger.console.status(\"Storage\"):\n        local_storage: Store = storage.ipfs(LOCAL_ENDPOINT)\n        stored_file_object: Object = local_storage(output_file)\n        # choose and connect an edge service to pin our resources. eg. estuary\n        estuary: Service = storage.estuary(FAKE_KEY)\n        edge_client: Client = storage.client(estuary)\n        edge_client.pin(stored_file_object)\n\n    # 4. expose our media through the standard\n    with logger.console.status(\"Expose\"):\n        # technical information about image\n        size = output_file.meta.size\n        width = output_file.meta.width\n        height = output_file.meta.height\n        media_type = output_file.meta.type\n\n        # standard implementation\n        # https://github.com/SynapseMedia/sep/blob/main/SEP/SEP-001.md\n        sep001 = expose.standard(media_type)  # image/png\n        # Prepare serialization\n        sep001.set_operation(Sign)\n        sep001.set_serialization(DagJose)\n        # Add signature/recipient key\n        sep001.add_key(expose.es256())\n        # add metadata into payload\n        sep001.add_metadata(Descriptive(**dict(nucleus)))\n        sep001.add_metadata(Structural(cid=stored_file_object.hash))\n        sep001.add_metadata(Technical(size=size, width=width, height=height))\n        # we get signed dag-jose serialization.. let's store it\n        obj: Object = sep001.serialize().save_to(local_storage)\n        # what we do with our new and cool CID?\n        logger.console.print(obj.hash)\n\n\"\"\"\n        Lets try:\n\n            ipfs dag get bagcqceraajwo66kumbcrxf2todw7wjrmayh7tjwaegwigcgpzk745my4qa5a\n\n        \"\"\"\n</code></pre>"},{"location":"dev/","title":"Overview","text":"<p>Nucleus follows a modular and layered design approach:</p> <ol> <li> <p>The Core: This layer contains the building block packages that have minimal or no external dependencies. Any dependencies within the core layer will be limited to other internal packages.</p> </li> <li> <p>The SDK: The SDK exposes the programming-level API to interact with the core functions in a safe and conformant way.</p> </li> <li> <p>The CLI and HTTP API: These components utilize the SDK to provide services through command-line interfaces (CLI) and HTTP API endpoints.</p> </li> </ol>"},{"location":"dev/#development-tools","title":"Development tools","text":"<p>Some available capabilities for dev support:</p> <ul> <li>Install: <code>make install</code></li> <li>Tests: <code>make test</code></li> <li>Debug: <code>make debug</code></li> <li>Lint: <code>make lint</code></li> <li>Lint Fix: <code>make format</code></li> </ul> <p>Note: Run <code>make help</code> to check for more capabilities.  </p>"},{"location":"dev/#more-info","title":"More info","text":"<ul> <li>Visit our website synapsemedia.io</li> <li>Get in touch with us in slack | discord | reddit</li> <li>For help or bugs please create an issue.</li> </ul>"},{"location":"dev/arch/","title":"Architecture","text":"<pre><code>graph LR\n  A[Raw] --&gt; B[Harvesting];\n  B --&gt; C[Expose];\n  B -.-&gt; D[Processing];\n  B -.-&gt; E[Storage]\n  D -.-&gt; E[Storage]\n  E -.-&gt; C[Expose]\n  C --&gt; F[Meta Lake]\n  C -.-&gt; G[Mint]\n  F -.-&gt; G[Mint]</code></pre> <p>Nucleus proposes a sequence of steps (pipeline) for the processing and decentralization of multimedia:</p> <ol> <li>Harvesting: Collect metadata associated with the multimedia content.</li> <li>Processing: Performing media processing tasks.</li> <li>Storage:  Store the processed content in the IPFS network.</li> <li>Expose: Distribute metadata through the IPFS ecosystem.</li> <li>Mint: Create metadata as NFTs (Non-Fungible Tokens).</li> <li>Retrieval: Facilitates the retrieval and unmarshalling of metadata from IPFS ecosystem.</li> </ol> <p>The pipeline is modular and adheres to the decoupling principle, enabling flexible use cases. For instance, the storage component can be optional if data is already stored on the IPFS network. Similarly, the mint component can be skipped if there is no need to create NFTs for the metadata. The processing component may also be unnecessary if the media is already prepared for storage.</p> <p>Tip</p> <p>Harvesting and Expose are the sole essential components necessary for operating the pipeline.</p>"},{"location":"dev/arch/#transmissiondistribution","title":"Transmission/Distribution","text":"<p>As part of the metadata federation, Meta Lake emerges as a new concept in the Nucleus ecosystem, referring to the central communication point for metadata distribution. The serialization process of the metadata determines the transmission medium, with IPLD and Raw Blocks being among the means used by Nucleus eg:</p> <pre><code>graph LR\n  R[Expose] --&gt; A[DagJose]\n  A --&gt; B[IPLD];\n  D[Compact] --&gt; F[Raw Block]\n  R --&gt; D[Compact]</code></pre>"},{"location":"guide/harvest/","title":"Harvesting","text":"<p>The data harvesting stage involves obtaining \"raw\" information that is available to clean, structure, and validate it, and then distribute it on the network.</p>"},{"location":"guide/harvest/#metadata","title":"Metadata","text":"<p>Metadata collection is carried out using models created based on the requirements of each user and following the SEP001 specification (the standard on which Nucleus is based for metadata management), which provides flexibility for different use cases.</p> <p>Underneath the validation and schematization of the models is pydantic, so we can use python standard library types to define fields.</p> <p>Here's an example of how you can define models by extending the Model class as the base class: In this example, we define a model called Nucleus that extends the Model class from the nucleus.sdk.harvest module. The fields name, description, and contributors are defined with their respective types (str and List[str]).</p> <pre><code>from nucleus.sdk.harvest import Model\n\nclass Nucleus(Model):\n    name: str\n    description: str\n    contributors: List[str]\n</code></pre> <p>If you are function lovers you could step this using a partial function:</p> <pre><code>import nucleus.sdk.harvest as harvest\n\n# create a model using partial function\nnucleus_model = harvest.model(\n    name=(str, ...), \n    description=(str, ...), \n    contributors=(List[str], ...)\n)\n</code></pre> <p>To create an instance of the Nucleus model and populate it with data, you can do the following:</p> <pre><code># set our data in the model\nnucleus: Model = Nucleus(\n    name=\"Nucleus the SDK\",\n    description=\"Building block for multimedia decentralization\",\n    contributors=[\"Jacob\", \"Geo\", \"Dennis\", \"Mark\"],\n)\n</code></pre>"},{"location":"guide/harvest/#media","title":"Media","text":"<p>Let's discuss multimedia resources and their collection using the types defined or predetermined by the SDK.</p> <p>In order to properly handle multimedia resources such as images, videos, music, text, and more, it is important to collect and categorize them using the appropriate types defined or provided by the SDK. These types allow for easy identification and handling of the resources during subsequent stages or processes in the pipeline.</p> <p>For example, the SDK may provide builtin data types for each type of multimedia resource. This could include Image and Video types, each with their respective properties and methods for processing and manipulation.</p> <pre><code>from nucleus.sdk.harvest import Image, Video\n\n# Collecting an image using the Image type\nimage = Image(path=Path(\"/local/path/image.jpg\"))\n# Collecting a video using the Video type\nvideo = Video(path=URL(\"https://example.com/video.mp4\"))\n</code></pre> <p>Using partials:</p> <pre><code>import nucleus.sdk.harvest as harvest\n\n# Collecting an image using the Image type\nimage = harvest.image(path=Path(\"/local/path/image.jpg\"))\n# Collecting a video using the Video type\nvideo = harvest.video(path=URL(\"https://example.com/video.mp4\"))\n</code></pre> <p>Note</p> <p>It is also possible to create a generic multimedia type as long as it is accompanied by an engine that takes care of its processing. Please check builtin media types source to see media builtin-types and engine development guide.</p>"},{"location":"guide/processing/","title":"Processing","text":"<p>This step is responsible for processing multimedia resources by performing transformations, transcoding, or other necessary operations based on the required parameters for each specific use case. This prepares the resources for consumption over the network.</p>"},{"location":"guide/processing/#engines","title":"Engines","text":"<p>Engines are responsible for processing different types of media, providing configurations according to the nature of each multimedia type and its underlying library. These engines offer flexibility in modifying their behavior through their configurations and expose a standard output.</p> <p>In this example, we will invoke the image processing engine and its configuration process based on the <code>options</code>. Initializing an engine is straightforward with the functions offered by the processing package:</p> <pre><code>import nucleus.sdk.harvest as harvest\nimport nucleus.sdk.processing as processing\n\nfrom nucleus.core.types import Path\nfrom nucleus.sdk.harvest import Image\nfrom nucleus.sdk.processing import Engine\n\n# initialize an Image type to pass into engine function\nimage = harvest.image(path=Path(\"image.jpg\"))\n# retrieve an Image engine from the input image\nengine = processing.engine(image)\n\n# ... below engine configuration\n</code></pre> <p>Tip</p> <p>The <code>engine</code> function from the <code>processing</code> package is a polymorphic function that automatically selects the appropriate engine based on the type of multimedia passed as a parameter. Please see more about built-in engines.</p>"},{"location":"guide/processing/#options","title":"Options","text":"<p>Each engine provides a set of built-in configuration options that modify the engine's output and are tailored to the specific characteristics of each multimedia type.</p> <p>Configuring our engine is straightforward with the use of the <code>configure</code> method. Let's explore an example of how to configure the image engine:</p> <pre><code># import options from processing package\nfrom nucleus.sdk.processing import Thumbnail, Coord\n\n# we want to create a thumbnail from the image\n# new thumb size is 50x50 output\nengine.configure(Thumbnail(50,50))\n# save our new image to our preferred path\noutput_image = engine.save(path=Path(\"image2.jpg\"))\n</code></pre> <p>Info</p> <p>Given that the engines emulate the underlying libraries, the available options are based on the methods or configurations set within each respective library. Internally, the process entails preparing the library using the provided options during this stage. For further details on the available options, please refer to the video or image documentation.</p>"},{"location":"reference/harvest/media/","title":"Media","text":"<p>This section outlines the supported multimedia resource types. Each type is used for selecting the appropriate processing engine. If necessary, additional types can be easily incorporated.</p>"},{"location":"reference/harvest/media/#built-in-media-types","title":"Built-in media types","text":"<p>Tip</p> <p>Each media type specifies URLs and paths as the source types from which it can be collected.</p>"},{"location":"reference/harvest/media/#nucleus.sdk.harvest.media.Image","title":"<code>Image</code>","text":"<p>         Bases: <code>Media[Union[URL, Path]]</code></p> <p>Represents an image media type</p> Source code in <code>nucleus/sdk/harvest/media.py</code> <pre><code>class Image(Media[Union[URL, Path]]):\n\"\"\"Represents an image media type\"\"\"\n\n    ...\n</code></pre>"},{"location":"reference/harvest/media/#nucleus.sdk.harvest.media.Video","title":"<code>Video</code>","text":"<p>         Bases: <code>Media[Union[URL, Path]]</code></p> <p>Represents a video media type</p> Source code in <code>nucleus/sdk/harvest/media.py</code> <pre><code>class Video(Media[Union[URL, Path]]):\n\"\"\"Represents a video media type\"\"\"\n\n    ...\n</code></pre>"},{"location":"reference/harvest/models/","title":"Models","text":"<p>Models serve as the primary mechanism for metadata harvesting. By extending pydantic, defining data models and validating input data becomes effortless.</p>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Base","title":"<code>Base</code>","text":"<p>         Bases: <code>pydantic.BaseModel</code></p> <p>Base class for models that enables efficient model persistence and data validation.</p> <p>Usage:</p> <pre><code>class MyModel(BaseModel):\n    name: str\n\n# store a snapshot of the model\nstored_model = MyModel(name=\"Model\")\nstored_model.save()\n\n# we should be able to retrieve the same model\nassert MyModel.all() == [stored_model] # True\n</code></pre> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>class Base(pydantic.BaseModel, metaclass=_Manager):\n\"\"\"Base class for models that enables efficient model persistence and data validation.\n\n    Usage:\n\n        class MyModel(BaseModel):\n            name: str\n\n        # store a snapshot of the model\n        stored_model = MyModel(name=\"Model\")\n        stored_model.save()\n\n        # we should be able to retrieve the same model\n        assert MyModel.all() == [stored_model] # True\n\n    \"\"\"\n\n    _alias: str\n    _conn: Connection\n\n    class Config:\n        # Frozen model behavior\n        # ref: https://docs.pydantic.dev/usage/model_config/\n        frozen = True\n        smart_union = True\n        use_enum_values = True\n        arbitrary_types_allowed = True\n        anystr_strip_whitespace = True\n\n    def __init__(self, *args: Any, **kwargs: Any):\n        try:\n            super().__init__(*args, **kwargs)\n        except ValidationError as e:\n            raise ModelValidationError(f'raised exception during model initialization: {str(e)}')\n\n        sqlite3.register_converter(self._alias, pickle.loads)\n        sqlite3.register_adapter(type(self), pickle.dumps)\n\n    @classmethod\n    @decorators.proxy_exception(\n        expected=sqlite3.ProgrammingError,\n        target=ModelManagerError,\n    )\n    def get(cls) -&gt; Base:\n\"\"\"Exec query and fetch first entry from database.\n\n        :return: First registered snapshot\n        :raises ModelManagerError: If there is an error fetching entry\n        \"\"\"\n\n        response = cls._conn.execute(FETCH % cls._alias)\n        row = response.fetchone()\n        return row[0]\n\n    @classmethod\n    @decorators.proxy_exception(\n        expected=sqlite3.ProgrammingError,\n        target=ModelManagerError,\n    )\n    def all(cls) -&gt; Iterator[Base]:\n\"\"\"Exec query and fetch a list of data from database.\n\n        :return: all registered snapshots\n        :raises ModelManagerError: If there is an error fetching entries\n        \"\"\"\n        response = cls._conn.execute(FETCH % cls._alias)\n        rows = response.fetchall()\n        return map(lambda r: r[0], rows)\n\n    @decorators.proxy_exception(\n        expected=sqlite3.ProgrammingError,\n        target=ModelManagerError,\n    )\n    def save(self) -&gt; bool:\n\"\"\"Exec insertion query into database\n\n        :return: True if successful else False\n        :raises ModelManagerError: If there is an error saving entry\n        \"\"\"\n\n        # https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.lastrowid\n        cursor = self._conn.execute(INSERT % self._alias, (self,))\n        return cursor.rowcount &gt; 0\n</code></pre>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Base.all","title":"<code>all()</code>  <code>classmethod</code>","text":"<p>Exec query and fetch a list of data from database.</p> <p>Returns:</p> Type Description <code>Iterator[Base]</code> <p>all registered snapshots</p> <p>Raises:</p> Type Description <code>ModelManagerError</code> <p>If there is an error fetching entries</p> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>@classmethod\n@decorators.proxy_exception(\n    expected=sqlite3.ProgrammingError,\n    target=ModelManagerError,\n)\ndef all(cls) -&gt; Iterator[Base]:\n\"\"\"Exec query and fetch a list of data from database.\n\n    :return: all registered snapshots\n    :raises ModelManagerError: If there is an error fetching entries\n    \"\"\"\n    response = cls._conn.execute(FETCH % cls._alias)\n    rows = response.fetchall()\n    return map(lambda r: r[0], rows)\n</code></pre>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Base.get","title":"<code>get()</code>  <code>classmethod</code>","text":"<p>Exec query and fetch first entry from database.</p> <p>Returns:</p> Type Description <code>Base</code> <p>First registered snapshot</p> <p>Raises:</p> Type Description <code>ModelManagerError</code> <p>If there is an error fetching entry</p> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>@classmethod\n@decorators.proxy_exception(\n    expected=sqlite3.ProgrammingError,\n    target=ModelManagerError,\n)\ndef get(cls) -&gt; Base:\n\"\"\"Exec query and fetch first entry from database.\n\n    :return: First registered snapshot\n    :raises ModelManagerError: If there is an error fetching entry\n    \"\"\"\n\n    response = cls._conn.execute(FETCH % cls._alias)\n    row = response.fetchone()\n    return row[0]\n</code></pre>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Base.save","title":"<code>save()</code>","text":"<p>Exec insertion query into database</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful else False</p> <p>Raises:</p> Type Description <code>ModelManagerError</code> <p>If there is an error saving entry</p> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>@decorators.proxy_exception(\n    expected=sqlite3.ProgrammingError,\n    target=ModelManagerError,\n)\ndef save(self) -&gt; bool:\n\"\"\"Exec insertion query into database\n\n    :return: True if successful else False\n    :raises ModelManagerError: If there is an error saving entry\n    \"\"\"\n\n    # https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.lastrowid\n    cursor = self._conn.execute(INSERT % self._alias, (self,))\n    return cursor.rowcount &gt; 0\n</code></pre>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Media","title":"<code>Media</code>","text":"<p>         Bases: <code>Base</code>, <code>Generic[T]</code></p> <p>Generic media model to create media subtypes. Each subtype represents a specific media type and provides a generic specification of the sources from which it can be collected.</p> <p>Usage:</p> <pre><code>class Video(Media[Path]):\n    # Represents a video media resource with a file path\n    ...\n\nclass Image(Media[URL]):\n    # Represents an image media resource with a URL\n    ...\n</code></pre> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>class Media(Base, Generic[T]):\n\"\"\"\n    Generic media model to create media subtypes.\n    Each subtype represents a specific media type and provides a generic specification\n    of the sources from which it can be collected.\n\n    Usage:\n\n        class Video(Media[Path]):\n            # Represents a video media resource with a file path\n            ...\n\n        class Image(Media[URL]):\n            # Represents an image media resource with a URL\n            ...\n    \"\"\"\n\n    path: T\n</code></pre>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Model","title":"<code>Model</code>","text":"<p>         Bases: <code>Base</code></p> <p>Model class specifies by default the attributes needed for the metadata model and allows its extension to create metadata sub-models with custom attributes.</p> <p>Usage:</p> <pre><code>class Nucleus(Model):\n    # Represents a specific model for `Nucleus` metadata\n    name: str # default property\n    description: str # default property\n    address: str # my custom property\n</code></pre> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>class Model(Base):\n\"\"\"Model class specifies by default the attributes needed for the metadata model\n    and allows its extension to create metadata sub-models with custom attributes.\n\n    Usage:\n\n        class Nucleus(Model):\n            # Represents a specific model for `Nucleus` metadata\n            name: str # default property\n            description: str # default property\n            address: str # my custom property\n\n    \"\"\"\n\n    name: str  # the name of the resource\n    description: str  # the description of the resource\n</code></pre>"},{"location":"reference/harvest/types/","title":"Types","text":""},{"location":"reference/harvest/types/#nucleus.sdk.harvest.types.Collector","title":"<code>Collector</code>","text":"<p>         Bases: <code>ABC</code></p> <p>Abstract class for metadata collection. Collector define an abstraction with methods needed to handle metadata collection process. Subclasses should implement the iter method to collect metadata from various data inputs. Use this class to create collector subtypes.</p> Source code in <code>nucleus/sdk/harvest/types.py</code> <pre><code>class Collector(ABC):\n\"\"\"Abstract class for metadata collection.\n    Collector define an abstraction with methods needed to handle metadata collection process.\n    Subclasses should implement the __iter__ method to collect metadata from various data inputs.\n    Use this class to create collector subtypes.\n    \"\"\"\n\n    @abstractmethod\n    def __iter__(self) -&gt; Iterator[JSON]:\n\"\"\"Collect metadata from any kind of data input and return an iterator\"\"\"\n        ...\n</code></pre>"},{"location":"reference/harvest/types/#nucleus.sdk.harvest.types.Collector.__iter__","title":"<code>__iter__()</code>  <code>abstractmethod</code>","text":"<p>Collect metadata from any kind of data input and return an iterator</p> Source code in <code>nucleus/sdk/harvest/types.py</code> <pre><code>@abstractmethod\ndef __iter__(self) -&gt; Iterator[JSON]:\n\"\"\"Collect metadata from any kind of data input and return an iterator\"\"\"\n    ...\n</code></pre>"},{"location":"reference/harvest/utilities/","title":"Utilities","text":"<p>Partial functions allow us to derive specific functions from complex functions, making their usage simpler. They are particularly useful when creating specialized versions of existing functions, reducing the number of arguments required for each call.</p>"},{"location":"reference/harvest/utilities/#built-in-partials","title":"Built-in partials","text":"<pre><code>model = functools.partial(create_model, __base__=Model)\n</code></pre> <p>Info</p> <p>Enhance the <code>create_model</code> pydantic factory function by extending the default model as a base argument. This partial allows the fast creation of metadata models. For more information check here.</p> <pre><code>image = functools.partial(media_factory, base=Image)\nvideo = functools.partial(media_factory, base=Video)\n</code></pre> <p>Info</p> <p>These partial functions are used to create predefined models for different types of media.</p>"},{"location":"reference/harvest/utilities/#factories","title":"Factories","text":"<p>Tip</p> <p>We can extend the list of multimedia partials using <code>media_factory</code> and our own media type.</p>"},{"location":"reference/harvest/utilities/#nucleus.sdk.harvest.partials.media_factory","title":"<code>media_factory(*, base, **kwargs)</code>","text":"<p>Generic model factory.</p> <p>Parameters:</p> Name Type Description Default <code>base</code> <code>Type[T]</code> <p>The base type for model</p> required <p>Returns:</p> Type Description <code>T</code> <p>New media type instance</p> <p>Raises:</p> Type Description <code>ModelValidationError</code> <p>If model fails during schema validation</p> Source code in <code>nucleus/sdk/harvest/partials.py</code> <pre><code>def media_factory(*, base: Type[T], **kwargs: Any) -&gt; T:\n\"\"\"Generic model factory.\n\n    :param base: The base type for model\n    :return: New media type instance\n    :raises ModelValidationError: If model fails during schema validation\n    \"\"\"\n    try:\n        return parse_obj_as(base, kwargs)\n    except ValidationError as e:\n        raise ModelValidationError(f'exceptions raised during schema validation in partials factory: {str(e)}')\n</code></pre>"},{"location":"reference/processing/engines/","title":"Engines","text":"<p>The engines are adapter classes that facilitate the interaction with underlying libraries, simplifying the processing of multimedia resources. Each engine establishes a contract through an interface, which allows for the extension to new engines, as well as smooth uniform communication and collaboration.</p>"},{"location":"reference/processing/engines/#nucleus.sdk.processing.engines.ImageEngine","title":"<code>ImageEngine</code>","text":"<p>         Bases: <code>Engine</code></p> <p>Engine that adapts the Pillow library to support image processing.</p> Source code in <code>nucleus/sdk/processing/engines.py</code> <pre><code>class ImageEngine(Engine):\n\"\"\"Engine that adapts the Pillow library to support image processing.\"\"\"\n\n    def __init__(self, lib: Pillow):\n        # compile the pattern to avoid overhead in loop and bind underlying lib\n        self._pattern = re.compile(r'(?&lt;!^)(?=[A-Z])')\n        super().__init__(lib)\n\n    def _to_snake_case(self, class_name: str) -&gt; str:\n\"\"\"Transform PascalCase class definition to snake_case method name\n\n        :para name: The class name to parse\n        :return: The snake case version for class name\n        \"\"\"\n        return self._pattern.sub('_', class_name).lower()\n\n    def _setup_methods(self):\n\"\"\"Call and chain methods based on configured options\"\"\"\n        for class_name, params in self.compile():\n            # The method to call should be the same as the option name.\n            method = self._to_snake_case(class_name)\n            func = getattr(self._library, method)\n            # pillow chaining features\n            # all methods return a new instance of the Image class, holding the resulting image\n            # ref:\n            # https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image\n            self._library = func(**dict(params))\n\n    def introspect(self, path: Path) -&gt; Introspection:\n        # fet the mime type from file path\n        (mime_type, _) = mimetypes.guess_type(path)\n        # get attributes from PIL.Image object\n        members = inspect.getmembers(PIL.Image.open(path))\n        filter_private = filter(lambda x: not x[0].startswith('_'), members)\n        filter_method = filter(lambda x: not inspect.ismethod(x[1]), filter_private)\n        image_introspection = _to_object(dict(filter_method))\n        # patch to avoid size conflict keyword\n        delattr(image_introspection, 'size')\n\n        # extend introspection with custom PIL.Image attributes\n        return Introspection(\n            size=path.size(),\n            type=str(mime_type),\n            **vars(image_introspection),\n        )\n\n    def save(self, path: Path) -&gt; File:\n        # We generate the expected path after processing\n        try:\n            self._setup_methods()\n            self._library.save(path)\n\n            # after low level processing happen!!\n            i8t = self.introspect(path)\n            return File(path=path, meta=i8t)\n        except Exception as e:\n            # Standard exceptions raised\n            raise ProcessingEngineError(f'error while trying to save image output: {str(e)}')\n</code></pre>"},{"location":"reference/processing/engines/#nucleus.sdk.processing.engines.VideoEngine","title":"<code>VideoEngine</code>","text":"<p>         Bases: <code>Engine</code></p> <p>Engine that adapts the FFMPEG Python library to support low-level transcoding.</p> Source code in <code>nucleus/sdk/processing/engines.py</code> <pre><code>class VideoEngine(Engine):\n\"\"\"Engine that adapts the FFMPEG Python library to support low-level transcoding.\"\"\"\n\n    def __init__(self, lib: FFMPEG):\n        super().__init__(lib)\n\n    def _build_output_args(self) -&gt; ChainMap[Any, Any]:\n\"\"\"Join config as output arguments for ffmpeg\"\"\"\n        mapped_args = [y for _, y in self.compile()]\n        return ChainMap(*mapped_args)\n\n    def introspect(self, path: Path) -&gt; Introspection:\n        # process the arg path or use the current media file path\n        (mime_type, _) = mimetypes.guess_type(path)\n        video_introspection = _to_object(processing.probe(path))\n\n        # extend introspection with custom video ffprobe\n        return Introspection(\n            size=path.size(),\n            type=str(mime_type),\n            **vars(video_introspection),\n        )\n\n    def save(self, path: Path) -&gt; File:\n        # TODO allow see ffmpeg progress\n        # TODO pubsub? Observer: Keep reading on event?\n        try:\n            output_args = self._build_output_args()\n            # We generate the expected path after transcode\n            self._library.output(path, **output_args).run()\n\n            # after low level processing happen!!\n            i8t = self.introspect(path)\n            return File(path=path, meta=i8t)\n        except Exception as e:\n            # Standard exceptions raised\n            raise ProcessingEngineError(f'error while trying to save video output: {str(e)}')\n</code></pre>"},{"location":"reference/processing/image/","title":"Image","text":"<p>Warning</p> <p>All these setting options are defined by pillow library. During processing time the options classes are parsed as a method to dynamically call pillow image object. For more information please see all available options in pillow docs.</p>"},{"location":"reference/processing/image/#nucleus.sdk.processing.image.options.Crop","title":"<code>Crop</code>  <code>dataclass</code>","text":"<p>Crop a rectangular region from an image</p> Source code in <code>nucleus/sdk/processing/image/options.py</code> <pre><code>@dataclass(slots=True)\nclass Crop:\n\"\"\"Crop a rectangular region from an image\"\"\"\n\n    box: Coord\n\n    def __iter__(self):\n        yield 'box', (\n            self.box.left,\n            self.box.top,\n            self.box.right,\n            self.box.bottom,\n        )\n</code></pre>"},{"location":"reference/processing/image/#nucleus.sdk.processing.image.options.Thumbnail","title":"<code>Thumbnail</code>  <code>dataclass</code>","text":"<p>Resize the image into a thumbnail</p> Source code in <code>nucleus/sdk/processing/image/options.py</code> <pre><code>@dataclass(slots=True)\nclass Thumbnail:\n\"\"\"Resize the image into a thumbnail\"\"\"\n\n    _size: Tuple[int, int] = field(init=False)\n    _gap: float = field(init=False)\n    _resample: Resampling = field(init=False)\n\n    width: int\n    height: int\n\n    def __post_init__(self):\n        self._gap = 2.0\n        self._size = (self.width, self.height)\n        self._resample = Resampling.BICUBIC\n\n    def reducing_gap(self, gap: float):\n        self._gap = gap\n\n    def resample(self, resample: Resampling):\n        self._resample = resample\n\n    def __iter__(self):\n        yield 'size', self._size\n        yield 'resample', self._resample\n        yield 'reducing_gap', self._gap\n</code></pre>"},{"location":"reference/processing/image/#nucleus.sdk.processing.image.options.Resize","title":"<code>Resize</code>  <code>dataclass</code>","text":"<p>Resize the image to a given size</p> Source code in <code>nucleus/sdk/processing/image/options.py</code> <pre><code>@dataclass(slots=True)\nclass Resize:\n\"\"\"Resize the image to a given size\"\"\"\n\n    _size: Tuple[int, int] = field(init=False)\n    _box: Tuple[int, int, int, int] = field(init=False)\n    _resample: Resampling = field(init=False)\n\n    width: int\n    height: int\n\n    def __post_init__(self):\n        self._size = (self.width, self.height)\n        self._box = (0, 0, *self._size)\n        self._resample = Resampling.BICUBIC\n\n    def crop(self, box: Coord):\n        self._box = (box.left, box.top, box.right, box.bottom)\n\n    def resample(self, resample: Resampling):\n        self._resample = resample\n\n    def __iter__(self):\n        yield 'size', self._size\n        yield 'resample', self._resample\n        yield 'box', self._box\n</code></pre>"},{"location":"reference/processing/types/","title":"Types","text":""},{"location":"reference/processing/types/#nucleus.sdk.processing.types.Engine","title":"<code>Engine</code>","text":"<p>         Bases: <code>ABC</code></p> <p>Engine implements a media engine template/adapter. It uses an underlying library as an interface to process media files. It produce output based on the provided settings. Use this class to create engine subtypes.</p> Source code in <code>nucleus/sdk/processing/types.py</code> <pre><code>class Engine(ABC):\n\"\"\"Engine implements a media engine template/adapter.\n    It uses an underlying library as an interface to process media files.\n    It produce output based on the provided settings.\n    Use this class to create engine subtypes.\n    \"\"\"\n\n    _library: Any\n    _settings: List[Settings]\n\n    def __init__(self, lib: Any):\n\"\"\"Initialize a new instance with bound library\"\"\"\n        self._library = lib\n        self._settings = []\n\n    def compile(self) -&gt; Compilation:\n\"\"\"Compile engine settings into an map of arguments\n\n        :return: A new map of compiled arguments based on configured options\n        \"\"\"\n        for preset in self._settings:\n            yield type(preset).__name__, dict(preset)\n\n    def configure(self, setting: Settings) -&gt; Engine:\n\"\"\"Set the context for media processing\n\n        :param setting: The settings to apply to the engine output.\n        :return: Engine object\n        \"\"\"\n\n        self._settings.append(setting)\n        return self\n\n    @abstractmethod\n    def introspect(self, path: Path) -&gt; Introspection:\n\"\"\"Return technical information of the input media.\n\n        :param path: The media path\n        :return: Any technical information collected from media.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def save(self, path: Path) -&gt; File:\n\"\"\"Store the new media based on conf context and bound library.\n\n        :param path: The output path\n        :return: File object\n        :raises ProcessingEngineError: If any exception is captured during processing\n        \"\"\"\n        ...\n</code></pre>"},{"location":"reference/processing/types/#nucleus.sdk.processing.types.Engine.__init__","title":"<code>__init__(lib)</code>","text":"<p>Initialize a new instance with bound library</p> Source code in <code>nucleus/sdk/processing/types.py</code> <pre><code>def __init__(self, lib: Any):\n\"\"\"Initialize a new instance with bound library\"\"\"\n    self._library = lib\n    self._settings = []\n</code></pre>"},{"location":"reference/processing/types/#nucleus.sdk.processing.types.Engine.compile","title":"<code>compile()</code>","text":"<p>Compile engine settings into an map of arguments</p> <p>Returns:</p> Type Description <code>Compilation</code> <p>A new map of compiled arguments based on configured options</p> Source code in <code>nucleus/sdk/processing/types.py</code> <pre><code>def compile(self) -&gt; Compilation:\n\"\"\"Compile engine settings into an map of arguments\n\n    :return: A new map of compiled arguments based on configured options\n    \"\"\"\n    for preset in self._settings:\n        yield type(preset).__name__, dict(preset)\n</code></pre>"},{"location":"reference/processing/types/#nucleus.sdk.processing.types.Engine.configure","title":"<code>configure(setting)</code>","text":"<p>Set the context for media processing</p> <p>Parameters:</p> Name Type Description Default <code>setting</code> <code>Settings</code> <p>The settings to apply to the engine output.</p> required <p>Returns:</p> Type Description <code>Engine</code> <p>Engine object</p> Source code in <code>nucleus/sdk/processing/types.py</code> <pre><code>def configure(self, setting: Settings) -&gt; Engine:\n\"\"\"Set the context for media processing\n\n    :param setting: The settings to apply to the engine output.\n    :return: Engine object\n    \"\"\"\n\n    self._settings.append(setting)\n    return self\n</code></pre>"},{"location":"reference/processing/types/#nucleus.sdk.processing.types.Engine.introspect","title":"<code>introspect(path)</code>  <code>abstractmethod</code>","text":"<p>Return technical information of the input media.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The media path</p> required <p>Returns:</p> Type Description <code>Introspection</code> <p>Any technical information collected from media.</p> Source code in <code>nucleus/sdk/processing/types.py</code> <pre><code>@abstractmethod\ndef introspect(self, path: Path) -&gt; Introspection:\n\"\"\"Return technical information of the input media.\n\n    :param path: The media path\n    :return: Any technical information collected from media.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/processing/types/#nucleus.sdk.processing.types.Engine.save","title":"<code>save(path)</code>  <code>abstractmethod</code>","text":"<p>Store the new media based on conf context and bound library.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The output path</p> required <p>Returns:</p> Type Description <code>File</code> <p>File object</p> <p>Raises:</p> Type Description <code>ProcessingEngineError</code> <p>If any exception is captured during processing</p> Source code in <code>nucleus/sdk/processing/types.py</code> <pre><code>@abstractmethod\ndef save(self, path: Path) -&gt; File:\n\"\"\"Store the new media based on conf context and bound library.\n\n    :param path: The output path\n    :return: File object\n    :raises ProcessingEngineError: If any exception is captured during processing\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/processing/types/#nucleus.sdk.processing.types.File","title":"<code>File</code>","text":"<p>         Bases: <code>Media[Path]</code></p> <p>Local media file representation. This class is used to represent any media stored in local host.</p> Source code in <code>nucleus/sdk/processing/types.py</code> <pre><code>class File(Media[Path]):\n\"\"\"Local media file representation.\n    This class is used to represent any media stored in local host.\n    \"\"\"\n\n    # associated file introspection\n    meta: Introspection\n    ...\n</code></pre>"},{"location":"reference/processing/types/#nucleus.sdk.processing.types.Introspection","title":"<code>Introspection</code>","text":"<p>         Bases: <code>Dynamic</code></p> <p>Introspection holds internal media information and metadata. For each result, the media metadata is associated with the <code>meta</code> attribute, and it could change based on the media type and underlying library.</p> <p>Usage:</p> <pre><code># Introspect from ffprobe video info or PIL.Image, etc.\nvideo = Introspection(**ffprobe)\nimage = Introspection(**PIL.Image)\n\n# Introspection dynamically receives all the metadata from the underlying library output.\n# The \"WARNING\" here is that based on the media type,\n# the introspection content could change and requires an extra review.\n</code></pre> Source code in <code>nucleus/sdk/processing/types.py</code> <pre><code>class Introspection(Dynamic):\n\"\"\"Introspection holds internal media information and metadata.\n    For each result, the media metadata is associated with the `meta` attribute, and it could change\n    based on the media type and underlying library.\n\n    Usage:\n\n        # Introspect from ffprobe video info or PIL.Image, etc.\n        video = Introspection(**ffprobe)\n        image = Introspection(**PIL.Image)\n\n        # Introspection dynamically receives all the metadata from the underlying library output.\n        # The \"WARNING\" here is that based on the media type,\n        # the introspection content could change and requires an extra review.\n    \"\"\"\n\n    size: int\n    # We expect to fill this field with IANA Media types\n    # https://www.iana.org/assignments/media-types/media-types.xhtml\n    type: str\n</code></pre>"},{"location":"reference/processing/utilities/","title":"Utilities","text":""},{"location":"reference/processing/video/","title":"Video","text":"<p>Warning</p> <p>During processing time the options classes are parsed as configuration arguments for FFMPEG python library. To know more about the options implemented in this reference please see FFMPEG main options.</p>"},{"location":"reference/processing/video/#nucleus.sdk.processing.video.options.FPS","title":"<code>FPS</code>  <code>dataclass</code>","text":"<p>Set the frame rate (Hz value, fraction or abbreviation)</p> Source code in <code>nucleus/sdk/processing/video/options.py</code> <pre><code>@dataclass(slots=True)\nclass FPS:\n\"\"\"Set the frame rate (Hz value, fraction or abbreviation)\"\"\"\n\n    fps: float\n\n    def __iter__(self):\n        yield 'r', self.fps\n</code></pre>"},{"location":"reference/processing/video/#nucleus.sdk.processing.video.options.BR","title":"<code>BR</code>  <code>dataclass</code>","text":"<p>Set the Video/Audio bitrate</p> Source code in <code>nucleus/sdk/processing/video/options.py</code> <pre><code>@dataclass(slots=True)\nclass BR:\n\"\"\"Set the Video/Audio bitrate\"\"\"\n\n    video: int\n    audio: int = 0\n\n    def __iter__(self):\n        # if we only receive video bitrate, we consider it as overall bitrate\n        if self.video and not self.audio:\n            yield 'b', f'{self.video}k'\n            return\n\n        yield 'b:v', f'{self.video}k'\n        yield 'b:a', f'{self.audio}k'\n</code></pre>"},{"location":"reference/processing/video/#nucleus.sdk.processing.video.options.Custom","title":"<code>Custom</code>  <code>dataclass</code>","text":"<p>Special class for directly specifying custom settings to the ffmpeg command</p> Source code in <code>nucleus/sdk/processing/video/options.py</code> <pre><code>@dataclass(slots=True)\nclass Custom:\n\"\"\"Special class for directly specifying custom settings to the ffmpeg command\"\"\"\n\n    _custom: Mapping[str, Any]\n\n    def __init__(self, **kwargs: Any):\n        self._custom = kwargs\n\n    def __iter__(self):\n        yield from self._custom.items()\n</code></pre>"},{"location":"reference/processing/video/#nucleus.sdk.processing.video.options.FrameSize","title":"<code>FrameSize</code>  <code>dataclass</code>","text":"<p>Set the frame size</p> Source code in <code>nucleus/sdk/processing/video/options.py</code> <pre><code>@dataclass(slots=True)\nclass FrameSize:\n\"\"\"Set the frame size\"\"\"\n\n    width: int\n    height: int\n\n    def __str__(self) -&gt; str:\n        return f'{self.width}x{self.height}'\n\n    def __iter__(self):\n        yield 's', str(self)\n</code></pre>"},{"location":"reference/processing/video/#defaults","title":"Defaults","text":""},{"location":"reference/processing/video/#nucleus.sdk.processing.video.options.Bitrate","title":"<code>Bitrate</code>  <code>dataclass</code>","text":"<p>Default standard bitrate options</p> Source code in <code>nucleus/sdk/processing/video/options.py</code> <pre><code>@dataclass(frozen=True)\nclass Bitrate:\n\"\"\"Default standard bitrate options\"\"\"\n\n    B240 = BR(150, 94)\n    B360 = BR(276, 128)\n    B480 = BR(750, 192)\n    B720 = BR(2048, 320)\n    B1080 = BR(4096, 320)\n    B2k = BR(6144, 320)\n    B4k = BR(17408, 320)\n</code></pre>"},{"location":"reference/processing/video/#nucleus.sdk.processing.video.options.Screen","title":"<code>Screen</code>  <code>dataclass</code>","text":"<p>Default standard screen size options</p> Source code in <code>nucleus/sdk/processing/video/options.py</code> <pre><code>@dataclass(frozen=True)\nclass Screen:\n\"\"\"Default standard screen size options\"\"\"\n\n    Q240 = FrameSize(416, 234)\n    Q360 = FrameSize(640, 360)\n    Q480 = FrameSize(854, 480)\n    Q720 = FrameSize(1280, 720)\n    Q1080 = FrameSize(1920, 1080)\n    Q2k = FrameSize(2560, 1440)\n    Q4k = FrameSize(3840, 2160)\n</code></pre>"}]}