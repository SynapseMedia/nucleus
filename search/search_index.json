{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started","text":""},{"location":"#nucleus","title":"Nucleus","text":"<p>NOTE! Nucleus is alpha-stage software. It means nucleus hasn't been security audited and programming APIs and data formats can still change.</p> <p>Nucleus is a collection of low-level tools for media decentralization. It offers functionalities to make it easier to process, store, and distribute multimedia in a decentralized way.</p> <p>The key features of Nucleus include:</p> <ul> <li>Metadata harvesting</li> <li>Multimedia processing</li> <li>Multimedia storage</li> <li>Metadata distribution</li> <li>Web3 instruments</li> </ul>"},{"location":"#installing","title":"Installing","text":"<p>Try nucleus! Install is simple using pip: <code>pip install nucleus-sdk</code></p> <p>Before using <code>nucleus</code>, FFmpeg and IPFS must be installed:</p> <ul> <li>Check the official docs to install IPFS.</li> <li>There are a variety of ways to install FFmpeg, such as the official download links, or using your package manager of choice (e.g. <code>sudo apt install ffmpeg</code> on Debian/Ubuntu, <code>brew install ffmpeg</code> on OS X, etc.).</li> </ul>"},{"location":"example/","title":"Example","text":""},{"location":"example/#full-pipeline-flow","title":"Full pipeline flow","text":"<pre><code>import nucleus.core.logger as logger\nimport nucleus.sdk.harvest as harvest\nimport nucleus.sdk.processing as processing\nimport nucleus.sdk.storage as storage\nimport nucleus.sdk.expose as expose\n\nfrom nucleus.core.types import List, Path\nfrom nucleus.sdk.harvest import Image, Model\nfrom nucleus.sdk.storage import Store, Service, Client, Object\nfrom nucleus.sdk.processing import Resize, Engine, File\nfrom nucleus.sdk.expose import (\n    Structural,\n    Descriptive,\n    Technical,\n    DagJose,\n    Sign,\n    # Compact\n)\n\n\ndef main():\n\n    LOCAL_ENDPOINT = \"http://localhost:5001\"\n    FAKE_KEY = \"ESTbb693fa8-d758-48ce-9843-a8acadb98a53ARY\"\n\n    # 1. prepare our model schema to collect/validate/clean data\n    with logger.console.status(\"Harvesting\"):\n\n        class Nucleus(Model):\n            name: str\n            description: str\n            contributors: List[str]\n\n        # set our data in the model\n        nucleus: Model = Nucleus(\n            name=\"Nucleus the SDK\",\n            description=\"Building block for multimedia decentralization\",\n            contributors=[\"Jacob\", \"Geo\", \"Dennis\", \"Mark\"],\n        )\n\n    # 2. init our processing engine based on our media model\n    with logger.console.status(\"Processing\"):\n        # \"infer\" engine based on input media type\n        image: Image = harvest.image(path=Path(\"arch.png\"))\n        image_engine: Engine = processing.engine(image)\n        image_engine.configure(Resize(50, 50))\n        # finally save the processed image to our custom dir\n        output_file: File = image_engine.save(Path(\"arch2.png\"))\n\n    # 3. store our processed image in local IPFS node and pin it in estuary\n    with logger.console.status(\"Storage\"):\n        local_storage: Store = storage.ipfs(LOCAL_ENDPOINT)\n        stored_file_object: Object = local_storage(output_file)\n        # choose and connect an edge service to pin our resources. eg. estuary\n        estuary: Service = storage.estuary(FAKE_KEY)\n        edge_client: Client = storage.client(estuary)\n        edge_client.pin(stored_file_object)\n\n    # 4. expose our media through the standard\n    with logger.console.status(\"Expose\"):\n        # technical information about image\n        size = output_file.meta.size\n        width = output_file.meta.width\n        height = output_file.meta.height\n        media_type = output_file.meta.type\n\n        # standard implementation\n        # https://github.com/SynapseMedia/sep/blob/main/SEP/SEP-001.md\n        sep001 = expose.standard(media_type)  # image/png\n        # Prepare serialization\n        sep001.set_operation(Sign)\n        sep001.set_serialization(DagJose)\n        # Add signature/recipient key\n        sep001.add_key(expose.es256())\n        # add metadata into payload\n        sep001.add_metadata(Descriptive(**dict(nucleus)))\n        sep001.add_metadata(Structural(cid=stored_file_object.hash))\n        sep001.add_metadata(Technical(size=size, width=width, height=height))\n        # we get signed dag-jose serialization.. let's store it\n        obj: Object = sep001.serialize().save_to(local_storage)\n        # what we do with our new and cool CID?\n        logger.console.print(obj.hash)\n\n\"\"\"\n        Lets try:\n\n            ipfs dag get bagcqceraajwo66kumbcrxf2todw7wjrmayh7tjwaegwigcgpzk745my4qa5a\n\n        \"\"\"\n</code></pre>"},{"location":"dev/","title":"Overview","text":"<p>Nucleus follows a modular and layered design approach:</p> <ol> <li> <p>The Core: This layer contains the building block packages that have minimal or no external dependencies. Any dependencies within the core layer will be limited to other internal packages.</p> </li> <li> <p>The SDK: The SDK exposes the programming-level API to interact with the core functions in a safe and conformant way.</p> </li> <li> <p>The CLI and HTTP API: These components utilize the SDK to provide services through command-line interfaces (CLI) and HTTP API endpoints.</p> </li> </ol>"},{"location":"dev/#development-tools","title":"Development tools","text":"<p>Some available capabilities for dev support:</p> <ul> <li>Install: <code>make install</code></li> <li>Tests: <code>make test</code></li> <li>Debug: <code>make debug</code></li> <li>Lint: <code>make lint</code></li> <li>Lint Fix: <code>make format</code></li> </ul> <p>Note: Run <code>make help</code> to check for more capabilities.  </p>"},{"location":"dev/arch/","title":"Architecture","text":"<pre><code>graph LR\n  A[Raw] --&gt; B[Harvesting];\n  B --&gt; C[Expose];\n  B -.-&gt; D[Processing];\n  B -.-&gt; E[Storage]\n  D -.-&gt; E[Storage]\n  E -.-&gt; C[Expose]\n  C --&gt; F[Meta Lake]\n  C -.-&gt; G[Mint]\n  F -.-&gt; G[Mint]</code></pre> <p>Nucleus proposes a sequence of steps (pipeline) for the processing and decentralization of multimedia:</p> <ol> <li>Harvesting: Collect metadata associated with the multimedia content.</li> <li>Processing: Performing media processing tasks.</li> <li>Storage:  Store the processed content in the IPFS network.</li> <li>Expose: Distribute metadata through the IPFS ecosystem.</li> <li>Mint: Create metadata as NFTs (Non-Fungible Tokens).</li> <li>Retrieval: Facilitates the retrieval and unmarshalling of metadata from IPFS ecosystem.</li> </ol> <p>The pipeline is modular and adheres to the decoupling principle, enabling flexible use cases. For instance, the storage component can be optional if data is already stored on the IPFS network. Similarly, the mint component can be skipped if there is no need to create NFTs for the metadata. The processing component may also be unnecessary if the media is already prepared for storage.</p> <p>Tip</p> <p>Harvesting and Expose are the only essential components required for the functioning of the pipeline.</p>"},{"location":"dev/arch/#transmissiondistribution","title":"Transmission/Distribution","text":"<p>As part of the metadata federation, Meta Lake emerges as a new concept in the Nucleus ecosystem, referring to the central communication point for metadata distribution. The serialization process of the metadata determines the transmission medium, with IPLD and Raw Blocks being among the means used by Nucleus eg:</p> <pre><code>graph LR\n  R[Expose] --&gt; A[DagJose]\n  A --&gt; B[IPLD];\n  D[Compact] --&gt; F[Raw Block]\n  R --&gt; D[Compact]</code></pre>"},{"location":"guide/harvest/","title":"Harvesting","text":"<p>The data harvesting stage involves obtaining \"raw\" information that is available to clean, structure, and validate it, and then distribute it on the network.</p>"},{"location":"guide/harvest/#metadata","title":"Metadata","text":"<p>Metadata collection is carried out using models created based on the requirements of each user and following the SEP001 specification (the standard on which Nucleus is based for metadata management), which provides flexibility for different use cases.</p> <p>Underneath the validation and schematization of the models is pydantic, so we can use python standard library types to define fields.</p> <p>Here's an example of how you can define models by extending the Model class as the base class: In this example, we define a model called Nucleus that extends the Model class from the nucleus.sdk.harvest module. The fields name, description, and contributors are defined with their respective types (str and List[str]).</p> <pre><code>from nucleus.sdk.harvest import Model\n\nclass Nucleus(Model):\n    name: str\n    description: str\n    contributors: List[str]\n</code></pre> <p>If you are function lovers you could step this using a partial function:</p> <pre><code>import nucleus.sdk.harvest as harvest\n\n# create a model using partial function\nnucleus_model = harvest.model(\n    name=(str, ...), \n    description=(str, ...), \n    contributors=(List[str], ...)\n)\n</code></pre> <p>To create an instance of the Nucleus model and populate it with data, you can do the following:</p> <pre><code># set our data in the model\nnucleus: Model = Nucleus(\n    name=\"Nucleus the SDK\",\n    description=\"Building block for multimedia decentralization\",\n    contributors=[\"Jacob\", \"Geo\", \"Dennis\", \"Mark\"],\n)\n</code></pre>"},{"location":"guide/harvest/#media","title":"Media","text":"<p>Let's discuss multimedia resources and their collection using the types defined or predetermined by the SDK.</p> <p>In order to properly handle multimedia resources such as images, videos, music, text, and more, it is important to collect and categorize them using the appropriate types defined or provided by the SDK. These types allow for easy identification and handling of the resources during subsequent stages or processes in the pipeline.</p> <p>For example, the SDK may provide builtin data types for each type of multimedia resource. This could include Image and Video types, each with their respective properties and methods for processing and manipulation.</p> <pre><code>from nucleus.sdk.harvest import Image, Video\n\n# Collecting an image using the Image type\nimage = Image(path=Path(\"/local/path/image.jpg\"))\n# Collecting a video using the Video type\nvideo = Video(path=URL(\"https://example.com/video.mp4\"))\n</code></pre> <p>Using partials:</p> <pre><code>import nucleus.sdk.harvest as harvest\n\n# Collecting an image using the Image type\nimage = harvest.image(path=Path(\"/local/path/image.jpg\"))\n# Collecting a video using the Video type\nvideo = harvest.video(path=URL(\"https://example.com/video.mp4\"))\n</code></pre> <p>Note</p> <p>It is also possible to create a generic multimedia type as long as it is accompanied by an engine that takes care of its processing. Please check builtin media types source to see media builtin-types and engine development guide.</p>"},{"location":"guide/processing/","title":"Processing","text":"<p>This step is responsible for processing multimedia resources by performing transformations, transcoding, or other necessary operations based on the required parameters for each specific use case. This prepares the resources for consumption over the network.</p>"},{"location":"guide/processing/#engines","title":"Engines","text":"<p>Engines are responsible for processing different types of media, providing configurations according to the nature of each multimedia type and its underlying library. These engines offer flexibility in modifying their behavior through their configurations and expose a standard output.</p> <p>In this example, we will invoke the image processing engine and its configuration process based on the 'options'. Initializing an engine is straightforward with the functions offered by the processing package:</p> <pre><code>import nucleus.sdk.harvest as harvest\nimport nucleus.sdk.processing as processing\n\nfrom nucleus.core.types import Path\nfrom nucleus.sdk.harvest import Image\nfrom nucleus.sdk.processing import Engine\n\n# initialize an Image type to pass into engine function\nimage = harvest.image(path=Path(\"image.jpg\"))\n# retrieve an Image engine from the input image\nengine = processing.engine(image)\n\n# ... below engine configuration\n</code></pre> <p>Tip</p> <p>The <code>engine</code> function from the <code>processing</code> package is a polymorphic function that automatically selects the appropriate engine based on the type of multimedia passed as a parameter. Please see more about built-in engines.</p>"},{"location":"guide/processing/#options","title":"Options","text":"<p>Each engine provides a set of built-in configuration options that modify the engine's output and are tailored to the specific characteristics of each multimedia type.</p> <p>Configuring our engine is straightforward with the use of the <code>configure</code> method. Let's explore an example of how to configure the image engine:</p> <pre><code># import options from processing package\nfrom nucleus.sdk.processing import Thumbnail, Coord\n\n# we want to create a thumbnail from the image\n# new thumb size is 50x50 output\nengine.configure(Thumbnail(50,50))\n# save our new image to our preferred path\noutput_image = engine.save(path=Path(\"image2.jpg\"))\n</code></pre> <p>Info</p> <p>Given that the engines emulate the underlying libraries, the available options are based on the methods or configurations set within each respective library. Internally, the process entails preparing the library using the provided options during this stage. For further details on the available options, please refer to the documentation options.</p>"},{"location":"reference/harvest/media/","title":"Media","text":""},{"location":"reference/harvest/media/#built-in-media-types","title":"Built-in media types","text":"<p>This section outlines the supported multimedia resource types. Each type is used for selecting the appropriate processing engine. If necessary, additional types can be easily incorporated.</p> <p>Tip</p> <p>Each media type specifies URLs and paths as the source types from which it can be collected.</p>"},{"location":"reference/harvest/media/#nucleus.sdk.harvest.media.Video","title":"<code>nucleus.sdk.harvest.media.Video</code>","text":"<p>         Bases: <code>Media[Union[URL, Path]]</code></p> <p>Represents a video media type</p> Source code in <code>nucleus/sdk/harvest/media.py</code> <pre><code>class Video(Media[Union[URL, Path]]):\n\"\"\"Represents a video media type\"\"\"\n\n    ...\n</code></pre>"},{"location":"reference/harvest/media/#nucleus.sdk.harvest.media.Image","title":"<code>nucleus.sdk.harvest.media.Image</code>","text":"<p>         Bases: <code>Media[Union[URL, Path]]</code></p> <p>Represents an image media type</p> Source code in <code>nucleus/sdk/harvest/media.py</code> <pre><code>class Image(Media[Union[URL, Path]]):\n\"\"\"Represents an image media type\"\"\"\n\n    ...\n</code></pre>"},{"location":"reference/harvest/models/","title":"Models","text":"<p>Models serve as the primary mechanism for metadata harvesting. By extending pydantic, defining data models and validating input data becomes effortless.</p>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Base","title":"<code>nucleus.sdk.harvest.models.Base</code>","text":"<p>         Bases: <code>pydantic.BaseModel</code></p> <p>Base class for models that enables efficient model persistence and data validation.</p> <p>Usage::</p> <pre><code>class MyModel(BaseModel):\n    name: str\n\n# store a snapshot of the model\nstored_model = MyModel(name=\"Model\")\nstored_model.save()\n\n# we should be able to retrieve the same model\nassert MyModel.all() == [stored_model] # True\n</code></pre> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>class Base(pydantic.BaseModel, metaclass=_Manager):\n\"\"\"Base class for models that enables efficient model persistence and data validation.\n\n    Usage::\n\n        class MyModel(BaseModel):\n            name: str\n\n        # store a snapshot of the model\n        stored_model = MyModel(name=\"Model\")\n        stored_model.save()\n\n        # we should be able to retrieve the same model\n        assert MyModel.all() == [stored_model] # True\n\n    \"\"\"\n\n    _alias: str\n    _conn: Connection\n\n    class Config:\n        # Frozen model behavior\n        # ref: https://docs.pydantic.dev/usage/model_config/\n        frozen = True\n        smart_union = True\n        use_enum_values = True\n        arbitrary_types_allowed = True\n        anystr_strip_whitespace = True\n\n    def __init__(self, *args: Any, **kwargs: Any):\n        try:\n            super().__init__(*args, **kwargs)\n        except ValidationError as e:\n            raise ModelValidationError(f'raised exception during model initialization: {str(e)}')\n\n        sqlite3.register_converter(self._alias, pickle.loads)\n        sqlite3.register_adapter(type(self), pickle.dumps)\n\n    @classmethod\n    @decorators.proxy_exception(\n        expected=sqlite3.ProgrammingError,\n        target=ModelManagerError,\n    )\n    def get(cls) -&gt; Base:\n\"\"\"Exec query and fetch first entry from database.\n\n        :return: first registered snapshot\n        :rtype: BaseModel\n        :raises ModelManagerError: if there is an error fetching entry\n        \"\"\"\n\n        response = cls._conn.execute(FETCH % cls._alias)\n        row = response.fetchone()\n        return row[0]\n\n    @classmethod\n    @decorators.proxy_exception(\n        expected=sqlite3.ProgrammingError,\n        target=ModelManagerError,\n    )\n    def all(cls) -&gt; Iterator[Base]:\n\"\"\"Exec query and fetch a list of data from database.\n\n        :return: all registered snapshots\n        :rtype: Iterator[BaseModel]\n        :raises ModelManagerError: if there is an error fetching entries\n        \"\"\"\n        response = cls._conn.execute(FETCH % cls._alias)\n        rows = response.fetchall()\n        return map(lambda r: r[0], rows)\n\n    @decorators.proxy_exception(\n        expected=sqlite3.ProgrammingError,\n        target=ModelManagerError,\n    )\n    def save(self) -&gt; bool:\n\"\"\"Exec insertion query into database\n\n        :return: True if successful else False\n        :rtype: bool\n        :raises ModelManagerError: if there is an error saving entry\n        \"\"\"\n\n        # https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.lastrowid\n        cursor = self._conn.execute(INSERT % self._alias, (self,))\n        return cursor.rowcount &gt; 0\n</code></pre>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Base.all","title":"<code>all()</code>  <code>classmethod</code>","text":"<p>Exec query and fetch a list of data from database.</p> <p>Returns:</p> Type Description <code>Iterator[BaseModel]</code> <p>all registered snapshots</p> <p>Raises:</p> Type Description <code>ModelManagerError</code> <p>if there is an error fetching entries</p> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>@classmethod\n@decorators.proxy_exception(\n    expected=sqlite3.ProgrammingError,\n    target=ModelManagerError,\n)\ndef all(cls) -&gt; Iterator[Base]:\n\"\"\"Exec query and fetch a list of data from database.\n\n    :return: all registered snapshots\n    :rtype: Iterator[BaseModel]\n    :raises ModelManagerError: if there is an error fetching entries\n    \"\"\"\n    response = cls._conn.execute(FETCH % cls._alias)\n    rows = response.fetchall()\n    return map(lambda r: r[0], rows)\n</code></pre>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Base.get","title":"<code>get()</code>  <code>classmethod</code>","text":"<p>Exec query and fetch first entry from database.</p> <p>Returns:</p> Type Description <code>BaseModel</code> <p>first registered snapshot</p> <p>Raises:</p> Type Description <code>ModelManagerError</code> <p>if there is an error fetching entry</p> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>@classmethod\n@decorators.proxy_exception(\n    expected=sqlite3.ProgrammingError,\n    target=ModelManagerError,\n)\ndef get(cls) -&gt; Base:\n\"\"\"Exec query and fetch first entry from database.\n\n    :return: first registered snapshot\n    :rtype: BaseModel\n    :raises ModelManagerError: if there is an error fetching entry\n    \"\"\"\n\n    response = cls._conn.execute(FETCH % cls._alias)\n    row = response.fetchone()\n    return row[0]\n</code></pre>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Base.save","title":"<code>save()</code>","text":"<p>Exec insertion query into database</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful else False</p> <p>Raises:</p> Type Description <code>ModelManagerError</code> <p>if there is an error saving entry</p> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>@decorators.proxy_exception(\n    expected=sqlite3.ProgrammingError,\n    target=ModelManagerError,\n)\ndef save(self) -&gt; bool:\n\"\"\"Exec insertion query into database\n\n    :return: True if successful else False\n    :rtype: bool\n    :raises ModelManagerError: if there is an error saving entry\n    \"\"\"\n\n    # https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.lastrowid\n    cursor = self._conn.execute(INSERT % self._alias, (self,))\n    return cursor.rowcount &gt; 0\n</code></pre>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.Model","title":"<code>nucleus.sdk.harvest.Model</code>","text":"<p>         Bases: <code>Base</code></p> <p>Model class specifies by default the attributes needed for the metadata model and allows its extension to create metadata sub-models with custom attributes.</p> <p>Usage::</p> <pre><code>class Nucleus(Model):\n    # Represents a specific model for `Nucleus` metadata\n    name: str # default property\n    description: str # default property\n    address: str # my custom property\n</code></pre> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>class Model(Base):\n\"\"\"Model class specifies by default the attributes needed for the metadata model\n    and allows its extension to create metadata sub-models with custom attributes.\n\n    Usage::\n\n        class Nucleus(Model):\n            # Represents a specific model for `Nucleus` metadata\n            name: str # default property\n            description: str # default property\n            address: str # my custom property\n\n    \"\"\"\n\n    name: str  # the name of the resource\n    description: str  # the description of the resource\n</code></pre>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.Media","title":"<code>nucleus.sdk.harvest.Media</code>","text":"<p>         Bases: <code>Base</code>, <code>Generic[T]</code></p> <p>Generic media model to create media subtypes. Each subtype represents a specific media type and provides a generic specification of the sources from which it can be collected.</p> <p>Usage::</p> <pre><code>class Video(Media[Path]):\n    # Represents a video media resource with a file path\n    ...\n\nclass Image(Media[URL]):\n    # Represents an image media resource with a URL\n    ...\n</code></pre> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>class Media(Base, Generic[T]):\n\"\"\"\n    Generic media model to create media subtypes.\n    Each subtype represents a specific media type and provides a generic specification of the sources from which it can be collected.\n\n    Usage::\n\n        class Video(Media[Path]):\n            # Represents a video media resource with a file path\n            ...\n\n        class Image(Media[URL]):\n            # Represents an image media resource with a URL\n            ...\n    \"\"\"\n\n    path: T\n</code></pre>"},{"location":"reference/harvest/partials/","title":"Partials","text":"<p>Partial functions allow us to derive specific functions from complex functions, making their usage simpler. They are particularly useful when creating specialized versions of existing functions, reducing the number of arguments required for each call.</p>"},{"location":"reference/harvest/partials/#built-in-partials","title":"Built-in partials","text":"<p>In the context of this document, partial functions are used to facilitate the quick creation of multimedia types or data models.</p> <p>Note</p> <p>Extend the default Model base and use <code>create_model</code> from pydantic to create ready-to-use models. Learn more about <code>create_model</code> function here</p> <p>Note</p> <p>We use utility media_factory to create ready-to-use media models derived from media types.</p>"},{"location":"reference/harvest/partials/#nucleus.sdk.harvest.partials.model","title":"<code>model = functools.partial(create_model, __base__=Model)</code>  <code>module-attribute</code>","text":""},{"location":"reference/harvest/partials/#nucleus.sdk.harvest.partials.image","title":"<code>image = functools.partial(media_factory, base=Image)</code>  <code>module-attribute</code>","text":""},{"location":"reference/harvest/partials/#nucleus.sdk.harvest.partials.video","title":"<code>video = functools.partial(media_factory, base=Video)</code>  <code>module-attribute</code>","text":""},{"location":"reference/harvest/types/","title":"Types","text":""},{"location":"reference/harvest/types/#nucleus.sdk.harvest.types","title":"<code>nucleus.sdk.harvest.types</code>","text":""},{"location":"reference/harvest/types/#nucleus.sdk.harvest.types.Collector","title":"<code>Collector</code>","text":"<p>         Bases: <code>ABC</code></p> <p>Abstract class for metadata collection. Collector define an abstraction with methods needed to handle metadata collection process. Subclasses should implement the iter method to collect metadata from various data inputs. Use this class to create collector subtypes.</p> Source code in <code>nucleus/sdk/harvest/types.py</code> <pre><code>class Collector(ABC):\n\"\"\"Abstract class for metadata collection.\n    Collector define an abstraction with methods needed to handle metadata collection process.\n    Subclasses should implement the __iter__ method to collect metadata from various data inputs.\n    Use this class to create collector subtypes.\n    \"\"\"\n\n    @abstractmethod\n    def __iter__(self) -&gt; Iterator[JSON]:\n\"\"\"Collect metadata from any kind of data input and return an iterator\"\"\"\n        ...\n</code></pre>"},{"location":"reference/harvest/types/#nucleus.sdk.harvest.types.Collector.__iter__","title":"<code>__iter__()</code>  <code>abstractmethod</code>","text":"<p>Collect metadata from any kind of data input and return an iterator</p> Source code in <code>nucleus/sdk/harvest/types.py</code> <pre><code>@abstractmethod\ndef __iter__(self) -&gt; Iterator[JSON]:\n\"\"\"Collect metadata from any kind of data input and return an iterator\"\"\"\n    ...\n</code></pre>"},{"location":"reference/harvest/utilities/","title":"Utilities","text":""},{"location":"reference/harvest/utilities/#nucleus.sdk.harvest.partials","title":"<code>nucleus.sdk.harvest.partials</code>","text":""},{"location":"reference/harvest/utilities/#nucleus.sdk.harvest.partials.media_factory","title":"<code>media_factory(*, base, **kwargs)</code>","text":"<p>Generic model factory.</p> <p>Example::</p> <pre><code># define our partials types\nimage = functools.partial(media_factory, base=Image)\nvideo = functools.partial(media_factory, base=Video)\n\n# then we can use them to create a new type instance \nmy_img_type = image(path=\"image.jpg)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>base</code> <code>Type[T]</code> <p>the base type for model</p> required <p>Returns:</p> Type Description <code>T</code> <p>new media type instance</p> <p>Raises:</p> Type Description <code>ModelValidationError</code> <p>if model fails during schema validation</p> Source code in <code>nucleus/sdk/harvest/partials.py</code> <pre><code>def media_factory(*, base: Type[T], **kwargs: Any) -&gt; T:\n\"\"\"Generic model factory.\n\n    Example::\n\n        # define our partials types\n        image = functools.partial(media_factory, base=Image)\n        video = functools.partial(media_factory, base=Video)\n\n        # then we can use them to create a new type instance \n        my_img_type = image(path=\"image.jpg)\n\n\n    :param base: the base type for model\n    :return: new media type instance\n    :rtype: T\n    :raises ModelValidationError: if model fails during schema validation\n    \"\"\"\n    try:\n        return parse_obj_as(base, kwargs)\n    except ValidationError as e:\n        raise ModelValidationError(f'exceptions raised during schema validation in partials factory: {str(e)}')\n</code></pre>"},{"location":"reference/processing/engines/","title":"Engines","text":"<p>The engines are adapter classes that facilitate the interaction with underlying libraries, simplifying the processing of multimedia resources. Each engine establishes a contract through an interface, which allows for the extension to new engines, as well as smooth uniform communication and collaboration among the different components of the pipeline.</p>"}]}