{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started","text":""},{"location":"#nucleus","title":"Nucleus","text":"<p>NOTE! Nucleus is alpha-stage software. It means nucleus hasn't been security audited and programming APIs and data formats can still change.</p> <p>Nucleus is a collection of low-level tools for decentralized media management, that simplifies the processing, storage, and distribution of multimedia. Its key features include:</p> <ol> <li>Metadata harvesting: Simplify the extraction and collection of metadata associated with multimedia resources.</li> <li>Multimedia processing: Robust tools for processing multimedia content, including transcoding and image manipulation.</li> <li>Multimedia storage: Enables secure and efficient storage of multimedia files within the IPFS ecosystem.</li> <li>Metadata distribution: Facilitates seamless distribution of metadata across federated networks.</li> <li>Web3 instruments: Integrates with Web3 technologies, leveraging blockchain and smart contracts.</li> </ol>"},{"location":"#installing","title":"Installing","text":"<p>Try nucleus! Install is simple using pip: <code>pip install nucleus-sdk</code></p> <p>Before using <code>nucleus</code>, FFmpeg and IPFS must be installed:</p> <ul> <li>Check the official docs to install IPFS.</li> <li>There are a variety of ways to install FFmpeg, such as the official download links, or using your package manager of choice (e.g. <code>sudo apt install ffmpeg</code> on Debian/Ubuntu, <code>brew install ffmpeg</code> on OS X, etc.).</li> </ul>"},{"location":"#more-info","title":"More info","text":"<ul> <li>Check our roadmap at synapsemedia.io</li> <li>Follow us on twitter | reddit</li> <li>Get in touch with us on slack | discord</li> <li>For help or reporting bugs, please create an issue.</li> </ul>"},{"location":"dev/","title":"Overview","text":"<p>Nucleus follows a modular and layered design approach:</p> <ol> <li> <p>The Core: This layer contains the building block packages that have minimal or no external dependencies. Any dependencies within the core layer will be limited to other internal packages.</p> </li> <li> <p>The SDK: The SDK exposes the programming-level API to interact with the core functions in a safe and conformant way.</p> </li> <li> <p>The CLI and HTTP API: These components utilize the SDK to provide services through command-line interfaces (CLI) and HTTP API endpoints.</p> </li> </ol>"},{"location":"dev/#development-tools","title":"Development tools","text":"<p>Some available capabilities for dev support:</p> <ul> <li>Install: <code>make install</code></li> <li>Tests: <code>make test</code></li> <li>Debug: <code>make debug</code></li> <li>Lint: <code>make lint</code></li> <li>Lint Fix: <code>make format</code></li> </ul> <p>Note: Run <code>make help</code> to check for more capabilities.  </p>"},{"location":"dev/#more-info","title":"More info","text":"<ul> <li>Check our roadmap at synapsemedia.io</li> <li>Follow us on twitter | reddit</li> <li>Get in touch with us on slack | discord</li> <li>For help or reporting bugs, please create an issue.</li> </ul>"},{"location":"dev/arch/","title":"Architecture","text":"<pre><code>graph LR\n  A[Raw] --&gt; B[Harvesting];\n  B --&gt; C[Expose];\n  B -.-&gt; D[Processing];\n  B -.-&gt; E[Storage]\n  D -.-&gt; E[Storage]\n  E -.-&gt; C[Expose]\n  C --&gt; F[Meta Lake]\n  C -.-&gt; G[Mint]\n  F -.-&gt; G[Mint]</code></pre> <p>Nucleus proposes a sequence of steps (pipeline) for the processing and decentralization of multimedia:</p> <ol> <li>Harvesting: Collect metadata associated with the multimedia content.</li> <li>Processing: Performing media processing tasks.</li> <li>Storage:  Store the processed content in the IPFS network.</li> <li>Expose: Distribute metadata through the IPFS ecosystem.</li> <li>Mint: Create metadata as NFTs (Non-Fungible Tokens).</li> <li>Retrieval: Facilitates the retrieval and unmarshalling of metadata from IPFS ecosystem.</li> </ol> <p>The pipeline is modular and adheres to the decoupling principle, enabling flexible use cases. For instance, the storage component can be optional if data is already stored on the IPFS network. Similarly, the mint component can be skipped if there is no need to create NFTs for the metadata. The processing component may also be unnecessary if the media is already prepared for storage.</p> <p>Tip</p> <p>Harvesting and Expose are the sole essential components necessary for operating the pipeline.</p>"},{"location":"dev/arch/#transmissiondistribution","title":"Transmission/Distribution","text":"<p>As part of the metadata federation, Meta Lake emerges as a new concept in the Nucleus ecosystem, referring to the central communication point for metadata distribution. The serialization process of the metadata determines the transmission medium, with IPLD and Raw Blocks being among the means used by Nucleus eg:</p> <pre><code>graph LR\n  R[Expose] --&gt; A[DagJose]\n  A --&gt; B[IPLD];\n  D[Compact] --&gt; F[Raw Block]\n  R --&gt; D[Compact]</code></pre>"},{"location":"guide/example/","title":"Example","text":""},{"location":"guide/example/#full-pipeline-flow","title":"Full pipeline flow","text":"<pre><code>import nucleus.core.logger as logger\nimport nucleus.sdk.harvest as harvest\nimport nucleus.sdk.processing as processing\nimport nucleus.sdk.storage as storage\nimport nucleus.sdk.expose as expose\n\nfrom nucleus.core.types import List, Path\nfrom nucleus.sdk.harvest import Image, Model\nfrom nucleus.sdk.storage import Store, Client, Object\nfrom nucleus.sdk.processing import Resize, Engine, File\nfrom nucleus.sdk.expose import (\n    Structural,\n    Descriptive,\n    Technical,\n    DagJose,\n    Sign,\n    # Compact\n)\n\n\ndef main():\n\n    LOCAL_ENDPOINT = \"http://localhost:5001\"\n    FAKE_KEY = \"ESTbb693fa8-d758-48ce-9843-a8acadb98a53ARY\"\n\n    # 1. prepare our model schema to collect/validate/clean data\n    with logger.console.status(\"Harvesting\"):\n\n        class Nucleus(Model):\n            name: str\n            description: str\n            contributors: List[str]\n\n        # set our data in the model\n        nucleus: Model = Nucleus(\n            name=\"Nucleus the SDK\",\n            description=\"Building block for multimedia decentralization\",\n            contributors=[\"Jacob\", \"Geo\", \"Dennis\", \"Mark\"],\n        )\n\n    # 2. init our processing engine based on our media model\n    with logger.console.status(\"Processing\"):\n        # \"infer\" engine based on input media type\n        image: Image = harvest.image(path=Path(\"arch.png\"))\n        image_engine: Engine = processing.engine(image)\n        image_engine.configure(Resize(50, 50))\n        # finally save the processed image to our custom dir\n        output_file: File = image_engine.save(Path(\"arch2.png\"))\n\n    # 3. store our processed image in local IPFS node and pin it in estuary\n    with logger.console.status(\"Storage\"):\n        local_storage: Store = storage.ipfs(LOCAL_ENDPOINT)\n        stored_file_object: Object = local_storage(output_file)\n        # choose and connect an edge service to pin our resources. eg. estuary\n        estuary: Client = storage.estuary(FAKE_KEY)\n        estuary.pin(stored_file_object)\n\n    # 4. expose our media through the standard\n    with logger.console.status(\"Expose\"):\n        # technical information about image\n        size = output_file.meta.size\n        width = output_file.meta.width\n        height = output_file.meta.height\n        media_type = output_file.meta.type\n\n        # standard implementation\n        # https://github.com/SynapseMedia/sep/blob/main/SEP/SEP-001.md\n        sep001 = expose.standard(media_type)  # image/png\n        # Prepare serialization\n        sep001.set_operation(Sign)\n        sep001.set_serialization(DagJose)\n        # Add signature/recipient key\n        sep001.add_key(expose.es256())\n        # add metadata into payload\n        sep001.add_metadata(Descriptive(**dict(nucleus)))\n        sep001.add_metadata(Structural(cid=stored_file_object.hash))\n        sep001.add_metadata(Technical(size=size, width=width, height=height))\n        # we get signed dag-jose serialization.. let's store it\n        obj: Object = sep001.serialize().save_to(local_storage)\n        # what we do with our new and cool CID?\n        logger.console.print(obj.hash)\n\n\"\"\"\n        Lets try:\n\n            ipfs dag get bagcqceraajwo66kumbcrxf2todw7wjrmayh7tjwaegwigcgpzk745my4qa5a\n\n        \"\"\"\n</code></pre>"},{"location":"guide/expose/","title":"Expose","text":"<p>After learning how to collect, process, and store our media, it's time to understand how to distribute our metadata to reach our target audience. In this guide, we will explore the necessary steps to process the metadata standard and its corresponding distribution through the federated network.</p>"},{"location":"guide/expose/#sep-001-standard","title":"SEP-001 Standard","text":"<p>Assuming you are already familiar with the anatomy of the standard, let's now examine its implementation. The adoption of the standard is crucial in ensuring smooth integration and compatibility across the federated network. By adhering to the standard defined in SEP001, metadata is effectively handled through an interface that facilitates signing, payload assignment, and the necessary headers.</p> <p>If you need more details about the specific requirements and guidelines of the standard, please refer to the specification document.</p> <p>Now, let's delve into the implementation of the standard in Nucleus.</p> <p>First, let's define the type of media to distribute in the standard header:</p> <pre><code>import nucleus.sdk.expose as expose\n\n# create a standard instance for \"image/jpeg\" media resource\nsep001 = expose.standard(media_type)  \n</code></pre>"},{"location":"guide/expose/#cryptography-serialization","title":"Cryptography &amp; Serialization","text":"<p>Note</p> <p>In Nucleus, it is possible to extend the signature/encryption algorithms using the Keyring protocol. You can see the JWA standard specification for more.</p> <p>Now we can start establishing the cryptographic operations and serialization method we want for our metadata. Let's see an example following the same definition as the previous standard:</p> <pre><code># serialization and sign operation\nsep001.set_operation(Sign)\nsep001.set_serialization(DagJose)\n</code></pre> <p>An important part of the metadata distribution process is the \"signature,\" which allows us to establish the origin of the data and verify the ownership or authorship of our multimedia resources. This process adds the public key and signature to the metadata header.</p> <p>Signing is simple using some \"built-in\" algorithms in the SDK:</p> <pre><code>key = expose.es256()\nsep001.add_key(key)\n</code></pre> <p>Example</p> <p>We can export/import our key using the methods defined in the KeyRing protocol. Let's see a simple example of how to do it:</p> <pre><code># Export the key to later import it\nexported_key = key.as_dict()\n# Restore key to original state\nkey.from_dict(exported_key)\n</code></pre>"},{"location":"guide/expose/#metadata-storage","title":"Metadata &amp; Storage","text":"<p>Now it's time to associate our data with the payload of the metadata. In this step, we add information related to the \"harvesting,\" \"storage,\" and \"processing\" steps. Let's see how all this information is consolidated in the exported metadata:</p> <pre><code># using nucleus model from harvesting guide\nsep001.add_metadata(Descriptive(**dict(nucleus)))\n# using stored file object from storage guide\nsep001.add_metadata(Structural(cid=stored_image_object.hash))\n# using introspection from processing guide\nsep001.add_metadata(Technical(size=size, width=width, height=height))\n</code></pre> <p>Warning</p> <p>When considering structural metadata, specifically in the context of storing processed videos according to the multimedia storage guide, it's crucial to understand that the hash obtained from <code>local storage</code> represents the stored directory's hash for files associated with the HLS protocol. Hence, it is essential to specify the supplementary path within the Structural type. For instance:</p> <pre><code># using stored directory object from storage guide\nsep001.add_metadata(Structural(cid=stored_directory_object.hash), path=\"index.m3u8\")\n</code></pre> <p>Tip</p> <p>In this code snippet, we use <code>**nucleus</code> to unpack the <code>nucleus</code> model as <code>**kwargs</code> and populate the <code>Descriptive</code> metadata model.</p> <p>To store the standard, we can use the local store function, which automatically determines the appropriate storage location based on the selected serialization type. If the serialization is set to DagJose, the metadata will be sent to the IPLD environment through the IPFS DAG service. If it is a compact version, it will be stored directly in a Raw Block. Let's see the example:</p> <pre><code># we get signed dag-jose serialization.. let's store it\nobj = sep001.serialize().save_to(local_storage)\n# What should we do with our new and cool CID?\nlogger.console.print(obj.hash)\n</code></pre> <p>Example</p> <p>It is easy to retrieve our metadata using the tools provided by IPFS. In this case, we can use DAG to traverse DagJose or retrieve the compact version using Block:</p> <pre><code>ipfs dag get bagcqceraajwo66kumbcrxf2todw7wjrmayh7tjwaegwigcgpzk745my4qa5a\nipfs block get bagcqceraajwo66kumbcrxf2todw7wjrmayh7tjwaegwigcgpzk745my4qa5a\n</code></pre>"},{"location":"guide/harvest/","title":"Harvesting","text":"<p>The data harvesting stage involves obtaining \"raw\" information that is available to clean, structure, and validate it, and then distribute it on the network.</p>"},{"location":"guide/harvest/#metadata","title":"Metadata","text":"<p>Metadata collection is carried out using models created based on the requirements of each user and following the SEP-001 specification (the standard on which Nucleus is based for metadata management), which provides flexibility for different use cases.</p> <p>Underneath the validation and schematization of the models is pydantic, so we can use python standard library types to define fields.</p> <p>In the example below, we have a model called Nucleus that extends the Model class. It includes fields such as name, description, and contributors, each defined with their respective types (str and List[str]).</p> <pre><code>from nucleus.sdk.harvest import Model\n\nclass Nucleus(Model):\n    name: str\n    description: str\n    contributors: List[str]\n</code></pre> <p>To create an instance of the Nucleus model and populate it with data, you can do the following:</p> <pre><code>nucleus = Nucleus(\n    name=\"Nucleus the SDK\",\n    description=\"Building block for multimedia decentralization\",\n    contributors=[\"Jacob\", \"Geo\", \"Dennis\", \"Mark\"],\n)\n</code></pre>"},{"location":"guide/harvest/#media","title":"Media","text":"<p>Let's explore multimedia resources and how to collect them using the SDK's built-in types.</p> <p>In order to properly handle multimedia resources such as images, videos, music, text, and more, it is important to collect and categorize them using the appropriate types defined or provided by the SDK. These types allow for easy identification and handling of the resources during subsequent stages or processes in the pipeline.</p> <p>Here's an example of how to collect media using the built-in media types:</p> <pre><code>import nucleus.sdk.harvest as harvest\n\n# harvest image and video using built-in types \nimage = harvest.image(path=Path(\"/local/path/image.jpg\"))\nvideo = harvest.video(path=Path(\"/local/path/video.mp4\"))\n</code></pre> <p>Note</p> <p>It is also possible to create our own multimedia type as long as it is accompanied by an engine that takes care of its processing. Please check built-in media types and built-in engines.</p>"},{"location":"guide/processing/","title":"Processing","text":"<p>This step involves processing multimedia resources by performing transformations, transcoding, or other necessary operations based on the required parameters for each specific use case. These operations prepare the resources for consumption over the network.</p>"},{"location":"guide/processing/#engines","title":"Engines","text":"<p>Engines are responsible for processing different types of media, providing configurations according to the nature of each multimedia type and its underlying library. These engines offer flexibility in modifying their behavior through their configurations and expose a standard output.</p> <p>In this example, we will invoke the image processing engine and its configuration process based on the <code>settings</code>. Initializing an engine is straightforward with the functions offered by the processing package:</p> <pre><code>import nucleus.sdk.harvest as harvest\nimport nucleus.sdk.processing as processing\n\nfrom nucleus.core.types import Path\n\n# harvest media using media types\nimage = harvest.image(path=Path(\"image.jpg\"))\nvideo = harvest.video(path=Path(\"video.mp4\"))\n\n# get engines based on media type\nimage_engine = processing.engine(image)\nvideo_engine = processing.engine(video)\n</code></pre> <p>Tip</p> <p>The <code>engine</code> function from the <code>processing</code> package automatically selects the appropriate engine based on the type of multimedia passed as a parameter. Please see more about built-in engines and utilities reference.</p>"},{"location":"guide/processing/#settings","title":"Settings","text":"<p>Each engine provides a set of built-in settings that modify the engine's output and are tailored to the specific characteristics of each multimedia type.</p> <p>Configuring our engine is straightforward with the use of the <code>configure</code> method. Let's explore an example of how to configure the image engine:</p> <pre><code>from nucleus.sdk.processing import Thumbnail\n\n# let's define how the output of our image should be.\nimage_engine.configure(Thumbnail(50,50)) # 50x50 px\noutput_image = engine.save(Path(\"image2.jpg\"))\n</code></pre> <p>Example processing a video to HLS/VP9:</p> <pre><code>from nucleus.sdk.processing import HLS, VP9, Screen, Bitrate\n\n# let's define how the output of our video should be.\nvideo_engine.configure(HLS(VP9()))\n# set the screen quality to 1080p (Full HD).\nvideo_engine.configure(Screen.Q1080)\n# set the bitrate to 1080p (Full HD).\nvideo_engine.configure(Bitrate.B1080)\n\noutput_file_name = 'index.m3u8'\noutput_directory = Path('my/output/dir')\n\n# create the output directory if it doesn't already exist.\nif not output_directory.exists():\n    output_directory.mkdir()\n\n# save HLS files to the new output path\noutput_path = Path(f'{output_directory}/{output_file_name}')\noutput_file = video_engine.save(output_path)\n</code></pre> <p>Info</p> <p>Given that the engines emulate the underlying libraries, the available settings are based on the methods or configurations set within each respective library. For further details on the available settings, please refer to the video or image documentation.</p>"},{"location":"guide/processing/#introspection","title":"Introspection","text":"<p>In the context of multimedia, introspection refers to the ability to obtain detailed and descriptive information about the elements and characteristics of a multimedia file. In the following example, we can see how to access the introspection obtained by the video engine:</p> <pre><code>size = output_file.meta.size\nwidth = output_file.meta.width\nheight = output_file.meta.height\nmedia_type = output_file.meta.type\n</code></pre> <p>Tip</p> <p>The output of the engine returns a File type object that contains an attribute called meta, which is essentially the result of introspecting the output multimedia file.</p> <p>Another way we can use introspection is by using the engine with the <code>introspect</code> method. Let's also see an example:</p> <pre><code># get technical details from \"video.mp4`\nintrospection = video_engine.introspect(Path(\"video.mp4\"))\n</code></pre> <p>Warning</p> <p>Introspection holds internal media information and technical details from media resources. Media introspection may vary based on the media type and underlying library. In the code snippet, introspection is obtained from <code>ffprobe</code>.</p>"},{"location":"guide/storage/","title":"Storage","text":"<p>In this guide, we will explore how to store processed media on the IPFS network using the storage package. We'll cover local storage, services, and clients. We have already learned how to collect multimedia resources and metadata, as well as basic aspects of multimedia processing.</p>"},{"location":"guide/storage/#local-storage","title":"Local Storage","text":"<p>To store our media in the local IPFS node, we can use the <code>local storage</code> feature provided by the storage package. Initializing the local node is straightforward using the <code>ipfs</code> function.</p> <p>Here's an example of how to store our processed image:</p> <pre><code>import nucleus.sdk.storage as storage\n\nlocal_storage = storage.ipfs(\"http://localhost:5001\")\n# in this case que are storing a File instance, we can obtain it from a processing output.\n# if we have an already processed media we can create a custom File instance\nstored_image_object = local_storage(output_image) \n</code></pre> <p>In the example of video processing, HLS generates multiple files in the output directory. To ensure we capture all the files, including the entire directory, we have a solution for you (Don't worry, we've got your back).</p> <p>Let's take a look at an example that shows how to handle this use case using the video processing example:</p> <pre><code>import nucleus.sdk.storage as storage\n\nlocal_storage = storage.ipfs(\"http://localhost:5001\")\n# we are not storing the File instance in this case since the File instance refers to the \"index.m3u8\" file only.\n# instead, the output_directory is a Path instance that points to a directory containing the HLS files.\nstored_directory_object = local_storage(output_directory) \n</code></pre> <p>After storing the file locally, we can proceed to pin it or perform further actions.</p> <p>Tip</p> <p>The <code>local_storage</code> is a repository of storage options in the form of a function that automatically selects the appropriate storage strategy based on the type of the parameter. Please see more about in utilities reference.</p>"},{"location":"guide/storage/#services","title":"Services","text":"<p>Services are storage providers within the IPFS ecosystem. Currently, the SDK supports Estuary, a service that provides storage through the IPFS and Filecoin network. Here are some examples of how to configure the service and use it to store multimedia resources.</p> <pre><code>from nucleus.sdk.storage import Estuary\n\nestuary_endpoint = \"https://api.estuary.tech\"\nestuary_key =  \"ESTbb693fa8-d758-48ce-9843-a8acadb98a53ARY\" # fake key\nestuary = Estuary(estuary_endpoint, estuary_key)\n</code></pre> <p>Alternatively, we can use the partial function to make it easier:</p> <pre><code>import nucleus.sdk.storage as storage\n\n# by default the endpoint is bundled inside the factory\nestuary = storage.estuary(estuary_key)\n</code></pre> <p>Since our storage primarily takes place on our local node, we only need to pin our CID on the edge service. Here's an example of how to pin the CID for our stored image:</p> <pre><code># ...\nestuary.pin(stored_image_object)\n</code></pre> <p>Tip</p> <p>Any storage service that exposes an API is compatible and can be integrated into the SDK by implementing the service protocol. See more about built-in services reference.</p>"},{"location":"reference/exceptions/","title":"Exceptions","text":""},{"location":"reference/exceptions/#nucleus.sdk.exceptions.HarvestingError","title":"<code>HarvestingError</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Exception raised for errors related to harvesting tasks.</p> Source code in <code>nucleus/sdk/exceptions.py</code> <pre><code>class HarvestingError(Exception):\n\"\"\"Exception raised for errors related to harvesting tasks.\"\"\"\n\n    def __init__(self, message: str, *args: Any, **kwargs: Any):\n        self.message = f'SDK :: Harvesting -&gt; {message}'\n        super().__init__(self.message, *args, **kwargs)\n</code></pre>"},{"location":"reference/exceptions/#nucleus.sdk.exceptions.ProcessingError","title":"<code>ProcessingError</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Exception raised for errors related to processing tasks.</p> Source code in <code>nucleus/sdk/exceptions.py</code> <pre><code>class ProcessingError(Exception):\n\"\"\"Exception raised for errors related to processing tasks.\"\"\"\n\n    def __init__(self, message: str, *args: Any, **kwargs: Any):\n        self.message = f'SDK :: Processing -&gt; {message}'\n        super().__init__(self.message, *args, **kwargs)\n</code></pre>"},{"location":"reference/exceptions/#nucleus.sdk.exceptions.StorageError","title":"<code>StorageError</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Exception raised for errors related to storage tasks.</p> Source code in <code>nucleus/sdk/exceptions.py</code> <pre><code>class StorageError(Exception):\n\"\"\"Exception raised for errors related to storage tasks.\"\"\"\n\n    def __init__(self, message: str, *args: Any, **kwargs: Any):\n        self.message = f'SDK :: Storage -&gt; {message}'\n        super().__init__(self.message, *args, **kwargs)\n</code></pre>"},{"location":"reference/exceptions/#nucleus.sdk.exceptions.ModelManagerError","title":"<code>ModelManagerError</code>","text":"<p>         Bases: <code>HarvestingError</code></p> <p>Raised when a model fails to persist or interact with the underlying cache. ModelManagerError error is a subclass from HarvestingError.</p> Source code in <code>nucleus/sdk/exceptions.py</code> <pre><code>class ModelManagerError(HarvestingError):\n\"\"\"Raised when a model fails to persist or interact with the underlying cache.\n    ModelManagerError error is a subclass from HarvestingError.\n    \"\"\"\n\n    ...\n</code></pre>"},{"location":"reference/exceptions/#nucleus.sdk.exceptions.ModelValidationError","title":"<code>ModelValidationError</code>","text":"<p>         Bases: <code>HarvestingError</code></p> <p>Raised when a model fails during schema validation. ModelValidationError error is a subclass from HarvestingError.</p> Source code in <code>nucleus/sdk/exceptions.py</code> <pre><code>class ModelValidationError(HarvestingError):\n\"\"\"Raised when a model fails during schema validation.\n    ModelValidationError error is a subclass from HarvestingError.\n    \"\"\"\n\n    ...\n</code></pre>"},{"location":"reference/exceptions/#nucleus.sdk.exceptions.StorageServiceError","title":"<code>StorageServiceError</code>","text":"<p>         Bases: <code>StorageError</code></p> <p>Raised when something fails when trying to operate on the edge services. StorageServiceError error is a subclass from StorageError.</p> Source code in <code>nucleus/sdk/exceptions.py</code> <pre><code>class StorageServiceError(StorageError):\n\"\"\"Raised when something fails when trying to operate on the edge services.\n    StorageServiceError error is a subclass from StorageError.\n    \"\"\"\n\n    ...\n</code></pre>"},{"location":"reference/exceptions/#nucleus.sdk.exceptions.ProcessingEngineError","title":"<code>ProcessingEngineError</code>","text":"<p>         Bases: <code>ProcessingError</code></p> <p>Raised when something fail during media processing. ProcessingEngineError error is a subclass from ProcessingError.</p> Source code in <code>nucleus/sdk/exceptions.py</code> <pre><code>class ProcessingEngineError(ProcessingError):\n\"\"\"Raised when something fail during media processing.\n    ProcessingEngineError error is a subclass from ProcessingError.\n    \"\"\"\n\n    ...\n</code></pre>"},{"location":"reference/exceptions/#nucleus.sdk.exceptions.FFProbeError","title":"<code>FFProbeError</code>","text":"<p>         Bases: <code>ProcessingError</code></p> <p>Raised when something fail during ffprobe call. FFProbeError error is a subclass from ProcessingError.</p> Source code in <code>nucleus/sdk/exceptions.py</code> <pre><code>class FFProbeError(ProcessingError):\n\"\"\"Raised when something fail during ffprobe call.\n    FFProbeError error is a subclass from ProcessingError.\n    \"\"\"\n\n    ...\n</code></pre>"},{"location":"reference/expose/keys/","title":"Keys","text":"<p>Info</p> <p>This reference provides a detailed implementation of the keyring types included in the SDK. All of these keyrings are based on the JWK (JSON Web Key) standard defined in RFC 7517. For more information about the keyring specification, please refer to the keyring spec.</p>"},{"location":"reference/expose/keys/#nucleus.sdk.expose.key.SignKeyRing","title":"<code>SignKeyRing</code>  <code>dataclass</code>","text":""},{"location":"reference/expose/keys/#nucleus.sdk.expose.key.SignKeyRing.__iter__","title":"<code>__iter__()</code>","text":"<p>Yield <code>alg</code> and <code>jwk</code> headers specified in RFC 7517-7516 standard.</p> <p>Returns:</p> Type Description <code>Setting</code> <p>The iterable header settings to associate</p> Source code in <code>nucleus/sdk/expose/key.py</code> <pre><code>def __iter__(self) -&gt; Setting:\n\"\"\"Yield `alg` and `jwk` headers specified in RFC 7517-7516 standard.\n\n    :return: The iterable header settings to associate\n    \"\"\"\n    yield 'alg', self.alg.value\n    yield 'jwk', self._jwk.export_public(True)\n</code></pre>"},{"location":"reference/expose/keys/#nucleus.sdk.expose.key.SignKeyRing.as_dict","title":"<code>as_dict()</code>","text":"<p>Export Keyring as JWK JSON format</p> <p>Returns:</p> Type Description <code>Raw</code> <p>Keyring as dict</p> Source code in <code>nucleus/sdk/expose/key.py</code> <pre><code>def as_dict(self) -&gt; Raw:\n\"\"\"Export Keyring as JWK JSON format\n\n    :return: Keyring as dict\n    \"\"\"\n    return self._jwk.export(True, True)  # type: ignore\n</code></pre>"},{"location":"reference/expose/keys/#nucleus.sdk.expose.key.SignKeyRing.fingerprint","title":"<code>fingerprint()</code>","text":"<p>Return the base64 decoded thumbprint as specified by RFC 7638.</p> <p>Returns:</p> Type Description <code>str</code> <p>The decoded sha256 thumbprint.</p> Source code in <code>nucleus/sdk/expose/key.py</code> <pre><code>def fingerprint(self) -&gt; str:\n\"\"\"Return the base64 decoded thumbprint as specified by RFC 7638.\n\n    :return: The decoded sha256 thumbprint.\n    \"\"\"\n    b64_thumbprint = self._jwk.thumbprint()\n    decoded_thumbprint = base64url_decode(b64_thumbprint)\n    return decoded_thumbprint.hex()\n</code></pre>"},{"location":"reference/expose/keys/#nucleus.sdk.expose.key.SignKeyRing.from_dict","title":"<code>from_dict(raw_key)</code>","text":"<p>Initialize Keyring using JWK JSON format</p> <p>Parameters:</p> Name Type Description Default <code>raw_key</code> <code>Raw</code> <p>Keyring to import as dict (JSON format)</p> required <p>Returns:</p> Type Description <code>SignKeyRing</code> <p>KeyRing object</p> Source code in <code>nucleus/sdk/expose/key.py</code> <pre><code>def from_dict(self, raw_key: Raw) -&gt; SignKeyRing:\n\"\"\"Initialize Keyring using JWK JSON format\n\n    :param raw_key: Keyring to import as dict (JSON format)\n    :return: KeyRing object\n    \"\"\"\n    json_string = str(JSON(raw_key))\n    self._jwk = JWK.from_json(json_string)\n    return self\n</code></pre>"},{"location":"reference/expose/keys/#nucleus.sdk.expose.key.SignKeyRing.jwk","title":"<code>jwk()</code>","text":"<p>Return the internal JWK (JSON Web Key) instance</p> <p>Returns:</p> Type Description <code>JWK</code> <p>The JWK (JSON Web Key) instance</p> Source code in <code>nucleus/sdk/expose/key.py</code> <pre><code>def jwk(self) -&gt; JWK:\n\"\"\"Return the internal JWK (JSON Web Key) instance\n\n    :return: The JWK (JSON Web Key) instance\n    \"\"\"\n    return self._jwk\n</code></pre>"},{"location":"reference/expose/metadata/","title":"Metadata","text":"<p>Info</p> <p>The types of metadata listed in this reference comply with the specification provided by the SEP-001 standard, based on the claims established within it.</p>"},{"location":"reference/expose/metadata/#nucleus.sdk.expose.metadata.Descriptive","title":"<code>Descriptive</code>","text":"<p>         Bases: <code>Dynamic</code></p> <p>Descriptive \"d\" claim metadata implementation.</p> <p>Usage:</p> <pre><code># example of populating \"d\" claim\nd = Descriptive(\n    name=\"Example\",\n    description=\"Example description\",\n    language=\"English\",\n    author=\"NASA\",\n)\n</code></pre>"},{"location":"reference/expose/metadata/#nucleus.sdk.expose.metadata.Structural","title":"<code>Structural</code>","text":"<p>         Bases: <code>Dynamic</code></p> <p>Structural \"s\" claim metadata implementation.</p> <p>Usage:</p> <pre><code># example of populating \"s\" claim\ns = Structural(cid=\"QmZG1jK2zYyzdHZtkZb9f9Uu3qQ2Ru6yvLjWFRV8ZuM6aM\")\ns_with_path = Structural(cid=\"QmZG1jK2zYyzdHZtkZb9f9Uu3qQ2Ru6yvLjWFRV8ZuM6aM\", path=\"/videos/example_video.mp4\")\n</code></pre>"},{"location":"reference/expose/metadata/#nucleus.sdk.expose.metadata.Technical","title":"<code>Technical</code>","text":"<p>         Bases: <code>Dynamic</code></p> <p>Technical \"t\" claim metadata implementation.</p> <p>Usage:</p> <pre><code># example of populating \"t\" claim\nt = Technical(\n    size=1024,\n    width=256,\n    height=256,\n    length=90\n)\n</code></pre>"},{"location":"reference/expose/operations/","title":"Operations","text":"<p>Info</p> <p>Cryptographic operations refer to the signing and encryption specified in the JWS (JSON Web Signature) and JWE (JSON Web Encryption) standards, respectively.</p> <p>!!! </p>"},{"location":"reference/expose/operations/#nucleus.sdk.expose.crypto.Sign","title":"<code>Sign</code>  <code>dataclass</code>","text":"<p>JWS serialization implementation.</p>"},{"location":"reference/expose/operations/#nucleus.sdk.expose.crypto.Sign.add_key","title":"<code>add_key(kr)</code>","text":"<p>Bind signature keys to JWS serialization.</p> <p>Parameters:</p> Name Type Description Default <code>kr</code> <code>Keyring</code> <p>Keyring to assoc with signature</p> required <p>Returns:</p> Type Description <code>Sign</code> <p>Sign object</p> Source code in <code>nucleus/sdk/expose/crypto.py</code> <pre><code>def add_key(self, kr: Keyring) -&gt; Sign:\n\"\"\"Bind signature keys to JWS serialization.\n\n    :param kr: Keyring to assoc with signature\n    :return: Sign object\n    \"\"\"\n\n    header = {**dict(kr), **dict(self._s8r)}\n    self._jws.add_signature(kr.jwk(), None, json_encode(header))\n    return self\n</code></pre>"},{"location":"reference/expose/operations/#nucleus.sdk.expose.crypto.Sign.serialize","title":"<code>serialize()</code>","text":"<p>Trigger and notify to underneath serializer for JWS post-processing . In this step additional data could be added/modified into JWS.</p> <p>Returns:</p> Type Description <code>Serializer</code> <p>The ready to use serializer object</p> Source code in <code>nucleus/sdk/expose/crypto.py</code> <pre><code>def serialize(self) -&gt; Serializer:\n\"\"\"Trigger and notify to underneath serializer for JWS post-processing .\n    In this step additional data could be added/modified into JWS.\n\n    :return: The ready to use serializer object\n    \"\"\"\n    return self._s8r.update(self._jws)\n</code></pre>"},{"location":"reference/expose/serializers/","title":"Serializers","text":"<p>Info</p> <p>This reference defines the necessary types required to handle SEP-001 serialization. It provides the implementation details for handling serialization based on the specification's guidelines for each strategy. Please see more about serializers spec.</p>"},{"location":"reference/expose/serializers/#nucleus.sdk.expose.marshall.Compact","title":"<code>Compact(standard)</code>","text":"<p>JWS Compact serializer implementation.</p> <p>Initialize a new instance with the standard implementation.</p> <p>Parameters:</p> Name Type Description Default <code>standard</code> <code>Standard</code> <p>Standard object</p> required Source code in <code>nucleus/sdk/expose/marshall.py</code> <pre><code>def __init__(self, standard: Standard):\n\"\"\"Initialize a new instance with the standard implementation.\n\n    :param standard: Standard object\n    \"\"\"\n\n    raw_payload = standard.payload()\n    self._header = standard.header()\n    self._claims = list(map(bytes, map(JSON, raw_payload.values())))\n    self._payload = self._payload_cid_values(raw_payload)\n</code></pre>"},{"location":"reference/expose/serializers/#nucleus.sdk.expose.marshall.Compact.__bytes__","title":"<code>__bytes__()</code>","text":"<p>Return compact serialization as bytes.</p> <p>Returns:</p> Type Description <code>bytes</code> Source code in <code>nucleus/sdk/expose/marshall.py</code> <pre><code>def __bytes__(self) -&gt; bytes:\n\"\"\"Return compact serialization as bytes.\n\n    :return:\n    \"\"\"\n    return bytes(self._payload)\n</code></pre>"},{"location":"reference/expose/serializers/#nucleus.sdk.expose.marshall.Compact.__iter__","title":"<code>__iter__()</code>","text":"<p>Yield <code>typ</code> headers specified in SEP-001 standard.</p> <p>Returns:</p> Type Description <code>Setting</code> <p>The iterable media type settings</p> Source code in <code>nucleus/sdk/expose/marshall.py</code> <pre><code>def __iter__(self) -&gt; Setting:\n\"\"\"Yield `typ` headers specified in SEP-001 standard.\n\n    :return: The iterable media type settings\n    \"\"\"\n    return iter(self._header.items())\n</code></pre>"},{"location":"reference/expose/serializers/#nucleus.sdk.expose.marshall.Compact.__str__","title":"<code>__str__()</code>","text":"<p>Return compact serialization as string.</p> <p>Returns:</p> Type Description <code>str</code> Source code in <code>nucleus/sdk/expose/marshall.py</code> <pre><code>def __str__(self) -&gt; str:\n\"\"\"Return compact serialization as string.\n\n    :return:\n    \"\"\"\n    return self._s11n\n</code></pre>"},{"location":"reference/expose/serializers/#nucleus.sdk.expose.marshall.Compact.save_to","title":"<code>save_to(store)</code>","text":"<p>Publishes Compact serialization into the local store.</p> <p>Parameters:</p> Name Type Description Default <code>store</code> <code>Store</code> <p>The Store function</p> required <p>Returns:</p> Type Description <code>Object</code> Source code in <code>nucleus/sdk/expose/marshall.py</code> <pre><code>def save_to(self, store: Store) -&gt; Object:\n\"\"\"Publishes Compact serialization into the local store.\n\n    :param store: The Store function\n    :return:\n    \"\"\"\n\n    # 1. store claims in blocks\n    for claim in self._claims:\n        store(claim)\n\n    # 2. store serialization and return\n    return store(self._s11n)\n</code></pre>"},{"location":"reference/expose/serializers/#nucleus.sdk.expose.marshall.Compact.update","title":"<code>update(jwt)</code>","text":"<p>Acts as an observer, waiting for events triggered by any cryptographic operation. Encodes JWS/JWE to compact serialization when a cryptographic operation notifies.</p> <p>Parameters:</p> Name Type Description Default <code>jwt</code> <code>JWT</code> <p>The JWT implementation passed by the cryptographic operation.</p> required <p>Returns:</p> Type Description <code>Compact</code> <p>The compact serialization string.</p> Source code in <code>nucleus/sdk/expose/marshall.py</code> <pre><code>def update(self, jwt: JWT) -&gt; Compact:\n\"\"\"Acts as an observer, waiting for events triggered by any cryptographic operation.\n    Encodes JWS/JWE to compact serialization when a cryptographic operation notifies.\n\n    :param jwt: The JWT implementation passed by the cryptographic operation.\n    :return: The compact serialization string.\n    \"\"\"\n    # set new state for serialization attribute\n    self._s11n = jwt.serialize(True)\n    return self\n</code></pre>"},{"location":"reference/expose/serializers/#nucleus.sdk.expose.marshall.DagJose","title":"<code>DagJose(standard)</code>","text":"<p>Dag-JOSE serializer implementation.</p> <p>Initialize a new instance with the standard implementation.</p> <p>Parameters:</p> Name Type Description Default <code>standard</code> <code>Standard</code> <p>Standard object</p> required Source code in <code>nucleus/sdk/expose/marshall.py</code> <pre><code>def __init__(self, standard: Standard):\n\"\"\"Initialize a new instance with the standard implementation.\n\n    :param standard: Standard object\n    \"\"\"\n    self._header = standard.header()\n    self._cbor = dag_cbor.encode(standard.payload())\n    self._cid = _cid_from_bytes(self._cbor, 'dag-cbor')\n</code></pre>"},{"location":"reference/expose/serializers/#nucleus.sdk.expose.marshall.DagJose.__bytes__","title":"<code>__bytes__()</code>","text":"<p>Return DAG-JOSE serialization as bytes.</p> <p>Returns:</p> Type Description <code>bytes</code> Source code in <code>nucleus/sdk/expose/marshall.py</code> <pre><code>def __bytes__(self) -&gt; bytes:\n\"\"\"Return DAG-JOSE serialization as bytes.\n\n    :return:\n    \"\"\"\n    return bytes(self._cid)\n</code></pre>"},{"location":"reference/expose/serializers/#nucleus.sdk.expose.marshall.DagJose.__iter__","title":"<code>__iter__()</code>","text":"<p>Yield <code>typ</code> headers specified in SEP-001 standard.</p> <p>Returns:</p> Type Description <code>Setting</code> <p>The iterable media type settings</p> Source code in <code>nucleus/sdk/expose/marshall.py</code> <pre><code>def __iter__(self) -&gt; Setting:\n\"\"\"Yield `typ` headers specified in SEP-001 standard.\n\n    :return: The iterable media type settings\n    \"\"\"\n    return iter(self._header.items())\n</code></pre>"},{"location":"reference/expose/serializers/#nucleus.sdk.expose.marshall.DagJose.__str__","title":"<code>__str__()</code>","text":"<p>Return DAG-JOSE serialization as string.</p> <p>Returns:</p> Type Description <code>str</code> Source code in <code>nucleus/sdk/expose/marshall.py</code> <pre><code>def __str__(self) -&gt; str:\n\"\"\"Return DAG-JOSE serialization as string.\n\n    :return:\n    \"\"\"\n    return str(self._s11n)\n</code></pre>"},{"location":"reference/expose/serializers/#nucleus.sdk.expose.marshall.DagJose.save_to","title":"<code>save_to(store)</code>","text":"<p>Publishes DAG-JOSE into the local store.</p> <p>Parameters:</p> Name Type Description Default <code>store</code> <code>Store</code> <p>The Store function</p> required <p>Returns:</p> Type Description <code>Object</code> Source code in <code>nucleus/sdk/expose/marshall.py</code> <pre><code>def save_to(self, store: Store) -&gt; Object:\n\"\"\"Publishes DAG-JOSE into the local store.\n\n    :param store: The Store function\n    :return:\n    \"\"\"\n\n    # 1. store cbor in blocks\n    # 2. store serialization and return\n    store(self._cbor)\n    return store(self._s11n)\n</code></pre>"},{"location":"reference/expose/serializers/#nucleus.sdk.expose.marshall.DagJose.update","title":"<code>update(jwt)</code>","text":"<p>Acts as an observer, waiting for events triggered by any cryptographic operation. Encodes JWS/JWE to DAG-JOSE serialization when a cryptographic operation notifies.</p> <p>Parameters:</p> Name Type Description Default <code>jwt</code> <code>JWT</code> <p>The JWT implementation passed by the cryptographic operation.</p> required <p>Returns:</p> Type Description <code>DagJose</code> <p>The DAG-JOSE serialization format.</p> Source code in <code>nucleus/sdk/expose/marshall.py</code> <pre><code>def update(self, jwt: JWT) -&gt; DagJose:\n\"\"\"Acts as an observer, waiting for events triggered by any cryptographic operation.\n    Encodes JWS/JWE to DAG-JOSE serialization when a cryptographic operation notifies.\n\n    :param jwt: The JWT implementation passed by the cryptographic operation.\n    :return: The DAG-JOSE serialization format.\n    \"\"\"\n    general_json = json_decode(jwt.serialize(False))\n    # set new state for serialization attribute\n    self._s11n = JSON({'link': self._cid, **general_json})\n    return self\n</code></pre>"},{"location":"reference/expose/standard/","title":"Standard","text":"<p>SEP-001 standard interface.</p> Source code in <code>nucleus/sdk/expose/sep.py</code> <pre><code>@dataclass(slots=True)\nclass SEP001:\n\"\"\"SEP-001 standard interface.\"\"\"\n\n    _header: Header\n    _payload: Payload\n\n    _keys: List[Keyring] = field(init=False)\n    # serialization method eg. DagJose, Compact, etc\n    _serializer: Type[Serializer] = field(init=False)\n    # crypto operation type eg. Sign, Cypher\n    _crypto: Type[Crypto] = field(init=False)\n\n    def __post_init__(self):\n        self._keys = []\n        self._serializer = DagJose  # default\n        self._crypto = Sign  # default\n\n    def header(self) -&gt; Raw:\n        return vars(self._header)\n\n    def payload(self) -&gt; Raw:\n        return vars(self._payload)\n\n    def add_key(self, kr: Keyring) -&gt; None:\n\"\"\"Add signature/recipient keyring.\n\n        :param kr: Keyring implementation\n        :return: None\n        \"\"\"\n        self._keys.append(kr)\n\n    def add_metadata(self, meta: Metadata) -&gt; None:\n\"\"\"Add metadata to payload.\n\n        :param meta: The metadata type to store in payload\n        :return: None\n        \"\"\"\n        self._payload.add(meta)\n\n    def set_operation(self, crypto: Type[Crypto]) -&gt; None:\n\"\"\"Set cryptography operation type to use during serialization.\n\n        :param crypto: The crypto operation type\n        :return: None\n        \"\"\"\n        self._crypto = crypto\n\n    def set_serialization(self, serializer: Type[Serializer]) -&gt; None:\n\"\"\"Set the serializer to use during serialization.\n\n        :param serializer: The serializer type\n        :return: None\n        \"\"\"\n        self._serializer = serializer\n\n    def serialize(self) -&gt; Serializer:\n\"\"\"Serialize the standard according to the defined serialization method and crypto operation.\n\n        :return: the ready-state serializer\n        \"\"\"\n        serializer = self._serializer(self)\n        crypto = self._crypto(serializer)\n\n        # associate keys\n        for k in self._keys:\n            crypto.add_key(k)\n\n        return crypto.serialize()\n</code></pre>"},{"location":"reference/expose/standard/#nucleus.sdk.expose.sep.SEP001.add_key","title":"<code>add_key(kr)</code>","text":"<p>Add signature/recipient keyring.</p> <p>Parameters:</p> Name Type Description Default <code>kr</code> <code>Keyring</code> <p>Keyring implementation</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>nucleus/sdk/expose/sep.py</code> <pre><code>def add_key(self, kr: Keyring) -&gt; None:\n\"\"\"Add signature/recipient keyring.\n\n    :param kr: Keyring implementation\n    :return: None\n    \"\"\"\n    self._keys.append(kr)\n</code></pre>"},{"location":"reference/expose/standard/#nucleus.sdk.expose.sep.SEP001.add_metadata","title":"<code>add_metadata(meta)</code>","text":"<p>Add metadata to payload.</p> <p>Parameters:</p> Name Type Description Default <code>meta</code> <code>Metadata</code> <p>The metadata type to store in payload</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>nucleus/sdk/expose/sep.py</code> <pre><code>def add_metadata(self, meta: Metadata) -&gt; None:\n\"\"\"Add metadata to payload.\n\n    :param meta: The metadata type to store in payload\n    :return: None\n    \"\"\"\n    self._payload.add(meta)\n</code></pre>"},{"location":"reference/expose/standard/#nucleus.sdk.expose.sep.SEP001.serialize","title":"<code>serialize()</code>","text":"<p>Serialize the standard according to the defined serialization method and crypto operation.</p> <p>Returns:</p> Type Description <code>Serializer</code> <p>the ready-state serializer</p> Source code in <code>nucleus/sdk/expose/sep.py</code> <pre><code>def serialize(self) -&gt; Serializer:\n\"\"\"Serialize the standard according to the defined serialization method and crypto operation.\n\n    :return: the ready-state serializer\n    \"\"\"\n    serializer = self._serializer(self)\n    crypto = self._crypto(serializer)\n\n    # associate keys\n    for k in self._keys:\n        crypto.add_key(k)\n\n    return crypto.serialize()\n</code></pre>"},{"location":"reference/expose/standard/#nucleus.sdk.expose.sep.SEP001.set_operation","title":"<code>set_operation(crypto)</code>","text":"<p>Set cryptography operation type to use during serialization.</p> <p>Parameters:</p> Name Type Description Default <code>crypto</code> <code>Type[Crypto]</code> <p>The crypto operation type</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>nucleus/sdk/expose/sep.py</code> <pre><code>def set_operation(self, crypto: Type[Crypto]) -&gt; None:\n\"\"\"Set cryptography operation type to use during serialization.\n\n    :param crypto: The crypto operation type\n    :return: None\n    \"\"\"\n    self._crypto = crypto\n</code></pre>"},{"location":"reference/expose/standard/#nucleus.sdk.expose.sep.SEP001.set_serialization","title":"<code>set_serialization(serializer)</code>","text":"<p>Set the serializer to use during serialization.</p> <p>Parameters:</p> Name Type Description Default <code>serializer</code> <code>Type[Serializer]</code> <p>The serializer type</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>nucleus/sdk/expose/sep.py</code> <pre><code>def set_serialization(self, serializer: Type[Serializer]) -&gt; None:\n\"\"\"Set the serializer to use during serialization.\n\n    :param serializer: The serializer type\n    :return: None\n    \"\"\"\n    self._serializer = serializer\n</code></pre>"},{"location":"reference/expose/types/","title":"Types","text":""},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Keyring","title":"<code>Keyring</code>","text":"<p>         Bases: <code>Protocol</code></p> <p>Keyring specifies the required methods for handling keys based on the JWK (JSON Web Key) RFC 7517 standard.</p>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Keyring.__iter__","title":"<code>__iter__()</code>","text":"<p>Yield <code>alg</code> and <code>jwk</code> headers specified in RFC 7517-7516 standard.</p> <p>Returns:</p> Type Description <code>Setting</code> <p>The iterable header settings to associate</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def __iter__(self) -&gt; Setting:\n\"\"\"Yield `alg` and `jwk` headers specified in RFC 7517-7516 standard.\n\n    :return: The iterable header settings to associate\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Keyring.as_dict","title":"<code>as_dict()</code>","text":"<p>Export Keyring as JWK JSON format</p> <p>Returns:</p> Type Description <code>Raw</code> <p>Keyring as dict</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def as_dict(self) -&gt; Raw:\n\"\"\"Export Keyring as JWK JSON format\n\n    :return: Keyring as dict\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Keyring.fingerprint","title":"<code>fingerprint()</code>","text":"<p>Return the base64 decoded thumbprint as specified by RFC 7638</p> <p>Returns:</p> Type Description <code>str</code> <p>The decoded thumbprint as string. eg: sha256, blake, etc..</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def fingerprint(self) -&gt; str:\n\"\"\"Return the base64 decoded thumbprint as specified by RFC 7638\n\n    :return: The decoded thumbprint as string. eg: sha256, blake, etc..\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Keyring.from_dict","title":"<code>from_dict(raw_key)</code>","text":"<p>Initialize Keyring using JWK JSON format</p> <p>Parameters:</p> Name Type Description Default <code>raw_key</code> <code>Raw</code> <p>Keyring to import as dict (JSON format)</p> required <p>Returns:</p> Type Description <code>Keyring</code> <p>KeyRing object</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def from_dict(self, raw_key: Raw) -&gt; Keyring:\n\"\"\"Initialize Keyring using JWK JSON format\n\n    :param raw_key: Keyring to import as dict (JSON format)\n    :return: KeyRing object\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Keyring.jwk","title":"<code>jwk()</code>","text":"<p>Return the internal JWK (JSON Web Key) instance</p> <p>Returns:</p> Type Description <code>JWK</code> <p>The JWK (JSON Web Key) instance</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def jwk(self) -&gt; JWK:\n\"\"\"Return the internal JWK (JSON Web Key) instance\n\n    :return: The JWK (JSON Web Key) instance\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Serializer","title":"<code>Serializer(standard)</code>","text":"<p>         Bases: <code>Protocol</code></p> <p>Serializer specifies an observer with the necessary methods to handle SEP-001 serialization. It defines how to handle serialization for each strategy according to the SEP-001 serialization spec.</p> <p>Serializer must be initialized with the SEP-001 standard implementation.</p> <p>Parameters:</p> Name Type Description Default <code>standard</code> <code>Standard</code> <p>The standard implementation</p> required Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def __init__(self, standard: Standard):\n\"\"\"Serializer must be initialized with the SEP-001 standard implementation.\n\n    :param standard: The standard implementation\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Serializer.__bytes__","title":"<code>__bytes__()</code>","text":"<p>Serialization as bytes.</p> <p>Returns:</p> Type Description <code>bytes</code> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def __bytes__(self) -&gt; bytes:\n\"\"\"Serialization as bytes.\n\n    :return:\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Serializer.__iter__","title":"<code>__iter__()</code>","text":"<p>Yield <code>typ</code> headers specified in SEP-001 standard.</p> <p>Returns:</p> Type Description <code>Setting</code> <p>The iterable media type settings</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def __iter__(self) -&gt; Setting:\n\"\"\"Yield `typ` headers specified in SEP-001 standard.\n\n    :return: The iterable media type settings\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Serializer.__str__","title":"<code>__str__()</code>","text":"<p>Serialization as string.</p> <p>Returns:</p> Type Description <code>str</code> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def __str__(self) -&gt; str:\n\"\"\"Serialization as string.\n\n    :return:\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Serializer.save_to","title":"<code>save_to(store)</code>","text":"<p>Publishes serialization into the local store.</p> <p>Parameters:</p> Name Type Description Default <code>store</code> <code>Store</code> <p>The local store function</p> required <p>Returns:</p> Type Description <code>Object</code> <p>Object instance</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def save_to(self, store: Store) -&gt; Object:\n\"\"\"Publishes serialization into the local store.\n\n    :param store: The local store function\n    :return: Object instance\n    \"\"\"\n\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Serializer.update","title":"<code>update(jwt)</code>","text":"<p>Receive updates when cryptographic operations are ready to be used. This step allows for adding a new state or performing operations on JWS/JWE to handle additional encoding.</p> <p>Parameters:</p> Name Type Description Default <code>jwt</code> <code>JWT</code> <p>The type of JWT implementation to handle.</p> required <p>Returns:</p> Type Description <code>Serializer</code> <p>Self serializer</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def update(self, jwt: JWT) -&gt; Serializer:\n\"\"\"Receive updates when cryptographic operations are ready to be used.\n    This step allows for adding a new state or performing operations on JWS/JWE to handle additional encoding.\n\n    :param jwt: The type of JWT implementation to handle.\n    :return: Self serializer\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Crypto","title":"<code>Crypto(serializer)</code>","text":"<p>         Bases: <code>Protocol</code></p> <p>Crypto specifies a pub/sub middleware that handles cryptographic operations on serializers. It notifies serializers when crypto operations are ready to be used.</p> <p>Initialize with the serializer on which we will operate.</p> <p>Parameters:</p> Name Type Description Default <code>serializer</code> <code>Serializer</code> <p>The serializer implementation</p> required Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def __init__(self, serializer: Serializer):\n\"\"\"Initialize with the serializer on which we will operate.\n\n    :param serializer: The serializer implementation\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Crypto.add_key","title":"<code>add_key(kr)</code>","text":"<p>Bind keys to the serialization process.</p> <p>Parameters:</p> Name Type Description Default <code>kr</code> <code>Keyring</code> <p>Keyring to associate with operation</p> required <p>Returns:</p> Type Description <code>Crypto</code> <p>Crypto object</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def add_key(self, kr: Keyring) -&gt; Crypto:\n\"\"\"Bind keys to the serialization process.\n\n    :param kr: Keyring to associate with operation\n    :return: Crypto object\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Crypto.serialize","title":"<code>serialize()</code>","text":"<p>Notify the underlying serializer of the current state of the cryptographic operation. During this process, the serializer may modify its state or store the results of the cryptographic operations.</p> <p>Returns:</p> Type Description <code>Serializer</code> <p>The input Serializer with a new ready to use state</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def serialize(self) -&gt; Serializer:\n\"\"\"Notify the underlying serializer of the current state of the cryptographic operation.\n    During this process, the serializer may modify its state or store the results of the cryptographic operations.\n\n    :return: The input Serializer with a new ready to use state\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Metadata","title":"<code>Metadata</code>","text":"<p>         Bases: <code>Protocol</code></p> <p>Metadata defines the expected behavior of metadata types. Examples of metadata types include:</p> <ul> <li>Descriptive</li> <li>Structural</li> <li>Technical</li> </ul>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Metadata.__str__","title":"<code>__str__()</code>","text":"<p>Metadata types MUST return the specified claims as a string. Examples of valid claims include:     s, t, d</p> <p>Returns:</p> Type Description <code>Claims</code> <p>The claim type specified in SEP-001</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def __str__(self) -&gt; Claims:\n\"\"\"Metadata types MUST return the specified claims as a string.\n    Examples of valid claims include:\n        s, t, d\n\n    :return: The claim type specified in SEP-001\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Standard","title":"<code>Standard</code>","text":"<p>         Bases: <code>Protocol</code></p> <p>Standard defines the expected behavior of the standard implementations according to SEP-001.</p>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Standard.header","title":"<code>header()</code>","text":"<p>Return the standard header</p> <p>Returns:</p> Type Description <code>Raw</code> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def header(self) -&gt; Raw:\n\"\"\"Return the standard header\n\n    :return:\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Standard.payload","title":"<code>payload()</code>","text":"<p>Return the standard payload</p> <p>Returns:</p> Type Description <code>Raw</code> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def payload(self) -&gt; Raw:\n\"\"\"Return the standard payload\n\n    :return:\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/utilities/","title":"Utilities","text":"<p>Note</p> <p>The types of media to be exposed are defined in the SEP-001 standard and MUST be included to establish the format of the associated multimedia resource, as specified by the IANA MediaTypes.</p>"},{"location":"reference/expose/utilities/#nucleus.sdk.expose.factory.es256","title":"<code>es256(**kwargs)</code>","text":"<p>Return a KeyRing with ECDSA settings based on JWA RFC7518 spec.</p> <p>Usage:</p> <pre><code># create a KeyRing with ECDSA settings\nsign_algorithm = expose.es256()\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>Any</code> <p>Any extra settings could be passed as keyword arguments</p> <code>{}</code> <p>Returns:</p> Type Description <code>SignKeyRing</code> <p>Ready to use ecdsa signature keyring</p> Source code in <code>nucleus/sdk/expose/factory.py</code> <pre><code>def es256(**kwargs: Any) -&gt; SignKeyRing:\n\"\"\"Return a KeyRing with ECDSA settings based on JWA RFC7518 spec.\n\n    Usage:\n\n        # create a KeyRing with ECDSA settings\n        sign_algorithm = expose.es256()\n\n    :param **kwargs: Any extra settings could be passed as keyword arguments\n    :return: Ready to use ecdsa signature keyring\n    \"\"\"\n\n    return SignKeyRing(\n        alg=Algorithm.ES256,\n        key_type=KeyType.EllipticCurve,\n        curve=Curve.P256,\n        use=Use.SIG,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/expose/utilities/#nucleus.sdk.expose.factory.standard","title":"<code>standard(type)</code>","text":"<p>SEP-001 factory function.</p> <p>Usage:</p> <pre><code># create a new sep-001-video/mp4 instance\nmedia_type = \"video/mp4\"\nsep001 = expose.standard(media_type)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>str</code> <p>The type of media to expose</p> required <p>Returns:</p> Type Description <code>SEP001</code> <p>New standard implementation sep-001 object</p> Source code in <code>nucleus/sdk/expose/factory.py</code> <pre><code>def standard(type: str) -&gt; SEP001:\n\"\"\"SEP-001 factory function.\n\n    Usage:\n\n        # create a new sep-001-video/mp4 instance\n        media_type = \"video/mp4\"\n        sep001 = expose.standard(media_type)\n\n    :param type: The type of media to expose\n    :return: New standard implementation sep-001 object\n    \"\"\"\n\n    return SEP001(\n        Header(type),\n        Payload(),\n    )\n</code></pre>"},{"location":"reference/harvest/media/","title":"Media","text":"<p>Info</p> <p>This section outlines the supported multimedia resource types. Each type is used for selecting the appropriate processing engine. If necessary, additional types can be easily incorporated. Please see model reference for more.</p> <p>Tip</p> <p>Each media type specifies \"Path\" as the source types from which it can be collected.</p>"},{"location":"reference/harvest/media/#nucleus.sdk.harvest.media.Image","title":"<code>Image</code>","text":"<p>         Bases: <code>Media[Path]</code></p> <p>Represents an image media type.</p> <p>Usage:</p> <pre><code># create a new image type\nimage = Image(path=Path(\"image.jpg\"))\n</code></pre> Source code in <code>nucleus/sdk/harvest/media.py</code> <pre><code>class Image(Media[Path]):\n\"\"\"Represents an image media type.\n\n    Usage:\n\n        # create a new image type\n        image = Image(path=Path(\"image.jpg\"))\n\n\n    \"\"\"\n\n    ...\n</code></pre>"},{"location":"reference/harvest/media/#nucleus.sdk.harvest.media.Video","title":"<code>Video</code>","text":"<p>         Bases: <code>Media[Path]</code></p> <p>Represents a video media type.</p> <p>Usage:</p> <pre><code># create a new video type\nvideo = Video(path=Path(\"video.mp4\"))\n</code></pre> Source code in <code>nucleus/sdk/harvest/media.py</code> <pre><code>class Video(Media[Path]):\n\"\"\"Represents a video media type.\n\n    Usage:\n\n        # create a new video type\n        video = Video(path=Path(\"video.mp4\"))\n\n    \"\"\"\n\n    ...\n</code></pre>"},{"location":"reference/harvest/models/","title":"Models","text":"<p>Info</p> <p>Models serve as the primary mechanism for metadata harvesting. By extending pydantic, defining data models and validating input data becomes effortless.</p>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Base","title":"<code>Base</code>","text":"<p>         Bases: <code>pydantic.BaseModel</code></p> <p>Base model provides efficient model persistence and data validation capabilities. The persistence mechanism relies on sqlite and pickle, allowing the entire model to be stored as a snapshot</p> <p>Usage:</p> <pre><code>class MyModel(BaseModel):\n    name: str\n\n# store a snapshot of the model\nstored_model = MyModel(name=\"Model\")\nstored_model.save()\n\n# we should be able to retrieve the same model\nassert MyModel.all() == [stored_model] # True\n</code></pre> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>class Base(pydantic.BaseModel, metaclass=_Manager):\n\"\"\"Base model provides efficient model persistence and data validation capabilities.\n    The persistence mechanism relies on sqlite and pickle, allowing the entire model to be stored as a snapshot\n\n    Usage:\n\n        class MyModel(BaseModel):\n            name: str\n\n        # store a snapshot of the model\n        stored_model = MyModel(name=\"Model\")\n        stored_model.save()\n\n        # we should be able to retrieve the same model\n        assert MyModel.all() == [stored_model] # True\n    \"\"\"\n\n    _alias: str\n    _conn: Connection\n\n    class Config:\n        # Frozen model behavior\n        # ref: https://docs.pydantic.dev/usage/model_config/\n        frozen = True\n        smart_union = True\n        use_enum_values = True\n        arbitrary_types_allowed = True\n        anystr_strip_whitespace = True\n\n    def __init__(self, *args: Any, **kwargs: Any):\n        try:\n            super().__init__(*args, **kwargs)\n        except ValidationError as e:\n            raise ModelValidationError(f'raised exception during model initialization: {str(e)}')\n\n        sqlite3.register_converter(self._alias, pickle.loads)\n        sqlite3.register_adapter(type(self), pickle.dumps)\n\n    @classmethod\n    @decorators.proxy_exception(\n        expected=sqlite3.ProgrammingError,\n        target=ModelManagerError,\n    )\n    def get(cls) -&gt; Base:\n\"\"\"Exec query and fetch first entry from local database.\n\n        :return: First registered snapshot\n        :raises ModelManagerError: If there is an error fetching entry\n        \"\"\"\n\n        response = cls._conn.execute(FETCH % cls._alias)\n        row = response.fetchone()\n        return row[0]\n\n    @classmethod\n    @decorators.proxy_exception(\n        expected=sqlite3.ProgrammingError,\n        target=ModelManagerError,\n    )\n    def all(cls) -&gt; Iterator[Base]:\n\"\"\"Exec query and fetch a list of data from local database.\n\n        :return: all registered snapshots\n        :raises ModelManagerError: If there is an error fetching entries\n        \"\"\"\n        response = cls._conn.execute(FETCH % cls._alias)\n        rows = response.fetchall()\n        return map(lambda r: r[0], rows)\n\n    @decorators.proxy_exception(\n        expected=sqlite3.ProgrammingError,\n        target=ModelManagerError,\n    )\n    def save(self) -&gt; bool:\n\"\"\"Exec insertion query into local database\n\n        :return: True if successful else False\n        :raises ModelManagerError: If there is an error saving entry\n        \"\"\"\n\n        # https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.lastrowid\n        cursor = self._conn.execute(INSERT % self._alias, (self,))\n        return cursor.rowcount &gt; 0\n</code></pre>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Base.all","title":"<code>all()</code>  <code>classmethod</code>","text":"<p>Exec query and fetch a list of data from local database.</p> <p>Returns:</p> Type Description <code>Iterator[Base]</code> <p>all registered snapshots</p> <p>Raises:</p> Type Description <code>ModelManagerError</code> <p>If there is an error fetching entries</p> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>@classmethod\n@decorators.proxy_exception(\n    expected=sqlite3.ProgrammingError,\n    target=ModelManagerError,\n)\ndef all(cls) -&gt; Iterator[Base]:\n\"\"\"Exec query and fetch a list of data from local database.\n\n    :return: all registered snapshots\n    :raises ModelManagerError: If there is an error fetching entries\n    \"\"\"\n    response = cls._conn.execute(FETCH % cls._alias)\n    rows = response.fetchall()\n    return map(lambda r: r[0], rows)\n</code></pre>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Base.get","title":"<code>get()</code>  <code>classmethod</code>","text":"<p>Exec query and fetch first entry from local database.</p> <p>Returns:</p> Type Description <code>Base</code> <p>First registered snapshot</p> <p>Raises:</p> Type Description <code>ModelManagerError</code> <p>If there is an error fetching entry</p> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>@classmethod\n@decorators.proxy_exception(\n    expected=sqlite3.ProgrammingError,\n    target=ModelManagerError,\n)\ndef get(cls) -&gt; Base:\n\"\"\"Exec query and fetch first entry from local database.\n\n    :return: First registered snapshot\n    :raises ModelManagerError: If there is an error fetching entry\n    \"\"\"\n\n    response = cls._conn.execute(FETCH % cls._alias)\n    row = response.fetchone()\n    return row[0]\n</code></pre>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Base.save","title":"<code>save()</code>","text":"<p>Exec insertion query into local database</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful else False</p> <p>Raises:</p> Type Description <code>ModelManagerError</code> <p>If there is an error saving entry</p> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>@decorators.proxy_exception(\n    expected=sqlite3.ProgrammingError,\n    target=ModelManagerError,\n)\ndef save(self) -&gt; bool:\n\"\"\"Exec insertion query into local database\n\n    :return: True if successful else False\n    :raises ModelManagerError: If there is an error saving entry\n    \"\"\"\n\n    # https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.lastrowid\n    cursor = self._conn.execute(INSERT % self._alias, (self,))\n    return cursor.rowcount &gt; 0\n</code></pre>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Media","title":"<code>Media</code>","text":"<p>         Bases: <code>Base</code>, <code>Generic[T]</code></p> <p>Generic media model to create media subtypes. Each subtype represents a specific media type and provides a generic specification of the sources from which it can be collected.</p> <p>Usage:</p> <pre><code>class Video(Media[Path]):\n    # represents a video file type .\n    ...\n\nclass Image(Media[URL]):\n    # represents an image url type.\n    ...\n</code></pre> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>class Media(Base, Generic[T]):\n\"\"\"Generic media model to create media subtypes.\n    Each subtype represents a specific media type and provides a generic specification\n    of the sources from which it can be collected.\n\n    Usage:\n\n        class Video(Media[Path]):\n            # represents a video file type .\n            ...\n\n        class Image(Media[URL]):\n            # represents an image url type.\n            ...\n    \"\"\"\n\n    path: T\n</code></pre>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Model","title":"<code>Model</code>","text":"<p>         Bases: <code>Base</code></p> <p>Model class specifies by default the attributes needed for the metadata model and allows its extension to create metadata sub-models with custom attributes.</p> <p>Usage:</p> <pre><code>class Nucleus(Model):\n    name: str # default property\n    description: str # default property\n    address: str # my custom property\n</code></pre> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>class Model(Base):\n\"\"\"Model class specifies by default the attributes needed for the metadata model\n    and allows its extension to create metadata sub-models with custom attributes.\n\n    Usage:\n\n        class Nucleus(Model):\n            name: str # default property\n            description: str # default property\n            address: str # my custom property\n    \"\"\"\n\n    name: str  # the name of the resource\n    description: str  # the description of the resource\n</code></pre>"},{"location":"reference/harvest/types/","title":"Types","text":""},{"location":"reference/harvest/types/#nucleus.sdk.harvest.types.Collector","title":"<code>Collector</code>","text":"<p>         Bases: <code>ABC</code></p> <p>Collector define an abstraction with methods needed to handle metadata collection process. Subclasses should implement the iter method to collect metadata from various data inputs. Use this class to create collector subtypes.</p> <p>Usage:</p> <pre><code>class File(Collector):\n\n    def __iter__(self):\n        # read our file and yield the content\n        with open('dummy.json') as file:\n            for data in json.load(file):\n                yield JSON(data)\n</code></pre> Source code in <code>nucleus/sdk/harvest/types.py</code> <pre><code>class Collector(ABC):\n\"\"\"Collector define an abstraction with methods needed to handle metadata collection process.\n    Subclasses should implement the __iter__ method to collect metadata from various data inputs.\n    Use this class to create collector subtypes.\n\n    Usage:\n\n        class File(Collector):\n\n            def __iter__(self):\n                # read our file and yield the content\n                with open('dummy.json') as file:\n                    for data in json.load(file):\n                        yield JSON(data)\n\n    \"\"\"\n\n    @abstractmethod\n    def __iter__(self) -&gt; Iterator[JSON]:\n\"\"\"Collect metadata from any kind of data input and return an iterator.\n\n        :return: The iterable JSON with data to process.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"reference/harvest/types/#nucleus.sdk.harvest.types.Collector.__iter__","title":"<code>__iter__()</code>  <code>abstractmethod</code>","text":"<p>Collect metadata from any kind of data input and return an iterator.</p> <p>Returns:</p> Type Description <code>Iterator[JSON]</code> <p>The iterable JSON with data to process.</p> Source code in <code>nucleus/sdk/harvest/types.py</code> <pre><code>@abstractmethod\ndef __iter__(self) -&gt; Iterator[JSON]:\n\"\"\"Collect metadata from any kind of data input and return an iterator.\n\n    :return: The iterable JSON with data to process.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/harvest/utilities/","title":"Utilities","text":""},{"location":"reference/harvest/utilities/#nucleus.sdk.harvest.partials.media_factory","title":"<code>media_factory(*, base, **kwargs)</code>","text":"<p>Generic model factory. Creates a new model based on the provided <code>base</code> model.</p> <p>Usage:</p> <pre><code># create our own media partial\nmusic = functools.partial(media_factory, base=Music)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>base</code> <code>Type[T]</code> <p>The base type for model</p> required <code>**kwargs</code> <code>Any</code> <p>The fields to declare into media model</p> <code>{}</code> <p>Returns:</p> Type Description <code>T</code> <p>New media type instance</p> <p>Raises:</p> Type Description <code>ModelValidationError</code> <p>If model fails during schema validation</p> Source code in <code>nucleus/sdk/harvest/partials.py</code> <pre><code>def media_factory(*, base: Type[T], **kwargs: Any) -&gt; T:\n\"\"\"Generic model factory.\n    Creates a new model based on the provided `base` model.\n\n    Usage:\n\n        # create our own media partial\n        music = functools.partial(media_factory, base=Music)\n\n    :param base: The base type for model\n    :param **kwargs: The fields to declare into media model\n    :return: New media type instance\n    :raises ModelValidationError: If model fails during schema validation\n    \"\"\"\n    try:\n        return parse_obj_as(base, kwargs)\n    except ValidationError as e:\n        raise ModelValidationError(f'exceptions raised during schema validation in partials factory: {str(e)}')\n</code></pre>"},{"location":"reference/harvest/utilities/#built-in-partials","title":"Built-in partials","text":"<pre><code>model = functools.partial(create_model, __base__=Model)\n</code></pre> <p>Note</p> <p>The partial <code>model</code> enhance the <code>create_model</code> pydantic factory function by extending the default model as a base argument. This partial allows the fast creation of metadata models. For more information check here.</p> <pre><code>image = functools.partial(media_factory, base=Image)\nvideo = functools.partial(media_factory, base=Video)\n</code></pre> <p>Tip</p> <p>We can extend the list of multimedia partials using <code>media_factory</code> and our own media type.</p>"},{"location":"reference/processing/engines/","title":"Engines","text":"<p>Info</p> <p>The engines are adapter classes that facilitate the interaction with underlying libraries, simplifying the processing of multimedia resources. Each engine establishes a contract through a protocol, which allows for the extension to new engines, as well as smooth uniform communication and collaboration.</p>"},{"location":"reference/processing/engines/#nucleus.sdk.processing.engines.ImageEngine","title":"<code>ImageEngine</code>","text":"<p>         Bases: <code>Engine</code></p> <p>Engine that adapts the Pillow library to support image processing.</p> <p>Usage:</p> <pre><code># adapt pillow Image\nlibrary = PIL.open(media.path)\nreturn ImageEngine(library)\n</code></pre> Source code in <code>nucleus/sdk/processing/engines.py</code> <pre><code>class ImageEngine(Engine):\n\"\"\"Engine that adapts the Pillow library to support image processing.\n\n    Usage:\n\n        # adapt pillow Image\n        library = PIL.open(media.path)\n        return ImageEngine(library)\n    \"\"\"\n\n    def __init__(self, lib: Pillow):\n        # compile the pattern to avoid overhead in loop and bind underlying lib\n        self._pattern = re.compile(r'(?&lt;!^)(?=[A-Z])')\n        super().__init__(lib)\n\n    def _to_snake_case(self, class_name: str) -&gt; str:\n\"\"\"Transform PascalCase class definition to snake_case method name\n\n        :para name: The class name to parse\n        :return: The snake case version for class name\n        \"\"\"\n        return self._pattern.sub('_', class_name).lower()\n\n    def _setup_methods(self):\n\"\"\"Call and chain methods based on settings\"\"\"\n        for class_name, params in self.compile():\n            # The method to call should be the same as the option name.\n            method = self._to_snake_case(class_name)\n            func = getattr(self._library, method)\n            # pillow chaining features\n            # all methods return a new instance of the Image class, holding the resulting image\n            # ref:\n            # https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image\n            self._library = func(**dict(params))\n\n    def introspect(self, path: Path) -&gt; Introspection:\n        # fet the mime type from file path\n        (mime_type, _) = mimetypes.guess_type(path)\n        # get attributes from PIL.Image object\n        members = inspect.getmembers(PIL.Image.open(path))\n        filter_private = filter(lambda x: not x[0].startswith('_'), members)\n        filter_method = filter(lambda x: not inspect.ismethod(x[1]), filter_private)\n        image_introspection = _to_object(dict(filter_method))\n        # patch to avoid size conflict keyword\n        delattr(image_introspection, 'size')\n\n        # extend introspection with custom PIL.Image attributes\n        return Introspection(\n            size=path.size(),\n            type=str(mime_type),\n            **vars(image_introspection),\n        )\n\n    def save(self, path: Path) -&gt; File:\n        # We generate the expected path after processing\n        try:\n            self._setup_methods()\n            self._library.save(path)\n\n            # after low level processing happen!!\n            i8t = self.introspect(path)\n            return File(path=path, meta=i8t)\n        except Exception as e:\n            # Standard exceptions raised\n            raise ProcessingEngineError(f'error while trying to save image output: {str(e)}')\n</code></pre>"},{"location":"reference/processing/engines/#nucleus.sdk.processing.engines.VideoEngine","title":"<code>VideoEngine</code>","text":"<p>         Bases: <code>Engine</code></p> <p>Engine that adapts the FFMPEG Python library to support low-level transcoding.</p> <p>Usage:</p> <pre><code># adapt ffmpeg lib\nlibrary = ffmpeg.input(media.path)\nreturn VideoEngine(library)\n</code></pre> Source code in <code>nucleus/sdk/processing/engines.py</code> <pre><code>class VideoEngine(Engine):\n\"\"\"Engine that adapts the FFMPEG Python library to support low-level transcoding.\n\n    Usage:\n\n        # adapt ffmpeg lib\n        library = ffmpeg.input(media.path)\n        return VideoEngine(library)\n    \"\"\"\n\n    def __init__(self, lib: FFMPEG):\n        super().__init__(lib)\n\n    def _build_output_args(self) -&gt; ChainMap[Any, Any]:\n\"\"\"Join config as output arguments for ffmpeg\"\"\"\n        mapped_args = [y for _, y in self.compile()]\n        return ChainMap(*mapped_args)\n\n    def introspect(self, path: Path) -&gt; Introspection:\n        # process the arg path or use the current media file path\n        (mime_type, _) = mimetypes.guess_type(path)\n        video_introspection = _to_object(processing.probe(path))\n\n        # extend introspection with custom video ffprobe\n        return Introspection(\n            size=path.size(),\n            type=str(mime_type),\n            **vars(video_introspection),\n        )\n\n    def save(self, path: Path) -&gt; File:\n        # TODO allow see ffmpeg progress\n        # TODO pubsub? Observer: Keep reading on event?\n        try:\n            output_args = self._build_output_args()\n            # We generate the expected path after transcode\n            self._library.output(path, **output_args).run()\n\n            # after low level processing happen!!\n            i8t = self.introspect(path)\n            return File(path=path, meta=i8t)\n        except Exception as e:\n            # Standard exceptions raised\n            raise ProcessingEngineError(f'error while trying to save video output: {str(e)}')\n</code></pre>"},{"location":"reference/processing/types/","title":"Types","text":""},{"location":"reference/processing/types/#nucleus.sdk.processing.types.Introspection","title":"<code>Introspection</code>","text":"<p>         Bases: <code>Dynamic</code></p> <p>Introspection holds internal media information and technical details from media resources. The media introspection may vary based on the media type and underlying library.</p> <p>Usage:</p> <pre><code># Introspect from ffprobe video info or PIL.Image, etc.\nvideo = Introspection(**ffprobe)\nimage = Introspection(**PIL.Image)\n\n# Introspection dynamically receives all the metadata from the underlying library output.\n# The \"WARNING\" here is that based on the media type,\n# the introspection content could change and requires an extra review.\n</code></pre>"},{"location":"reference/processing/types/#nucleus.sdk.processing.types.File","title":"<code>File</code>","text":"<p>         Bases: <code>Media[Path]</code></p> <p>Local media file representation. This class is used to represent any media stored in local host.</p> <p>Usage:</p> <pre><code># Introspect from ffprobe video info or PIL.Image, etc.\nvideo_meta = Introspection(**ffprobe)\n\n# create a local file with metadata information\nfile = File(Path(\"local_video.mp4\"), video_meta)\n</code></pre>"},{"location":"reference/processing/types/#nucleus.sdk.processing.types.Engine","title":"<code>Engine(lib)</code>","text":"<p>         Bases: <code>ABC</code></p> <p>Engine implements a media engine abstract adapter. It uses an underlying library as an interface to process media files. It produce output based on the provided settings.</p> <p>Initialize a new instance with bound library</p> <p>Parameters:</p> Name Type Description Default <code>lib</code> <code>Any</code> <p>Any underlying lib</p> required Source code in <code>nucleus/sdk/processing/types.py</code> <pre><code>def __init__(self, lib: Any):\n\"\"\"Initialize a new instance with bound library\n\n    :param lib: Any underlying lib\n    \"\"\"\n    self._library = lib\n    self._settings = []\n</code></pre>"},{"location":"reference/processing/types/#nucleus.sdk.processing.types.Engine.compile","title":"<code>compile()</code>","text":"<p>Compile engine settings into an map of arguments</p> <p>Returns:</p> Type Description <code>Iterator[Tuple[str, Any]]</code> <p>A new map of compiled arguments based on settings</p> Source code in <code>nucleus/sdk/processing/types.py</code> <pre><code>def compile(self) -&gt; Iterator[Tuple[str, Any]]:\n\"\"\"Compile engine settings into an map of arguments\n\n    :return: A new map of compiled arguments based on settings\n    \"\"\"\n    for preset in self._settings:\n        yield type(preset).__name__, dict(preset)\n</code></pre>"},{"location":"reference/processing/types/#nucleus.sdk.processing.types.Engine.configure","title":"<code>configure(setting)</code>","text":"<p>Add setting to media processing context</p> <p>Parameters:</p> Name Type Description Default <code>setting</code> <code>Settings</code> <p>The setting to apply to the engine output.</p> required <p>Returns:</p> Type Description <code>Engine</code> <p>Engine object</p> Source code in <code>nucleus/sdk/processing/types.py</code> <pre><code>def configure(self, setting: Settings) -&gt; Engine:\n\"\"\"Add setting to media processing context\n\n    :param setting: The setting to apply to the engine output.\n    :return: Engine object\n    \"\"\"\n\n    self._settings.append(setting)\n    return self\n</code></pre>"},{"location":"reference/processing/types/#nucleus.sdk.processing.types.Engine.introspect","title":"<code>introspect(path)</code>  <code>abstractmethod</code>","text":"<p>Return technical information of the input media.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The media path</p> required <p>Returns:</p> Type Description <code>Introspection</code> <p>Any technical information collected from media.</p> Source code in <code>nucleus/sdk/processing/types.py</code> <pre><code>@abstractmethod\ndef introspect(self, path: Path) -&gt; Introspection:\n\"\"\"Return technical information of the input media.\n\n    :param path: The media path\n    :return: Any technical information collected from media.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/processing/types/#nucleus.sdk.processing.types.Engine.save","title":"<code>save(path)</code>  <code>abstractmethod</code>","text":"<p>Store the new media based on settings and bound library.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The output path</p> required <p>Returns:</p> Type Description <code>File</code> <p>File object</p> <p>Raises:</p> Type Description <code>ProcessingEngineError</code> <p>If any exception is captured during processing</p> Source code in <code>nucleus/sdk/processing/types.py</code> <pre><code>@abstractmethod\ndef save(self, path: Path) -&gt; File:\n\"\"\"Store the new media based on settings and bound library.\n\n    :param path: The output path\n    :return: File object\n    :raises ProcessingEngineError: If any exception is captured during processing\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/processing/utilities/","title":"Utilities","text":"<p>Info</p> <p>For the inference of engines based on multimedia types, we use the singledispatch decorator to simplify the selection process of the appropriate engines. The decorator transforms a function into a generic function that can have different engine implementations depending on the type of the input media.</p>"},{"location":"reference/processing/utilities/#nucleus.sdk.processing.process.engine","title":"<code>engine(media)</code>","text":"<p>Engine singledispatch factory. Use the media input to infer the right engine.</p> <p>Usage:</p> <pre><code># create an image type to pass into engine function\nimage = harvest.image(path=Path(\"image.jpg\"))\nengine = processing.engine(image)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>media</code> <code>Media[Path]</code> <p>The media type to dispatch</p> required <p>Returns:</p> Type Description <code>Engine</code> <p>The appropriate engine implementation for the type of media</p> <p>Raises:</p> Type Description <code>ProcessingEngineError</code> <p>If any error occurs during engine initialization</p> Source code in <code>nucleus/sdk/processing/process.py</code> <pre><code>@functools.singledispatch\ndef engine(media: Media[Path]) -&gt; Engine:\n\"\"\"Engine singledispatch factory.\n    Use the media input to infer the right engine.\n\n    Usage:\n\n        # create an image type to pass into engine function\n        image = harvest.image(path=Path(\"image.jpg\"))\n        engine = processing.engine(image)\n\n    :param media: The media type to dispatch\n    :return: The appropriate engine implementation for the type of media\n    :raises ProcessingEngineError:  If any error occurs during engine initialization\n\n\n    \"\"\"\n    raise NotImplementedError(f'cannot process not registered media `{media}')\n</code></pre>"},{"location":"reference/processing/image/settings/","title":"Settings","text":""},{"location":"reference/processing/image/settings/#nucleus.sdk.processing.image.settings.Crop","title":"<code>Crop</code>  <code>dataclass</code>","text":"<p>Crop a rectangular region from an image.</p> <p>Usage:</p> <pre><code># crop an image using coords\ncrop = Crop(Coord(10, 10, 50, 50))\n</code></pre> Source code in <code>nucleus/sdk/processing/image/settings.py</code> <pre><code>@dataclass(slots=True)\nclass Crop:\n\"\"\"Crop a rectangular region from an image.\n\n    Usage:\n\n        # crop an image using coords\n        crop = Crop(Coord(10, 10, 50, 50))\n    \"\"\"\n\n    box: Coord\n\n    def __iter__(self):\n        yield 'box', (\n            self.box.left,\n            self.box.top,\n            self.box.right,\n            self.box.bottom,\n        )\n</code></pre>"},{"location":"reference/processing/image/settings/#nucleus.sdk.processing.image.settings.Thumbnail","title":"<code>Thumbnail</code>  <code>dataclass</code>","text":"<p>Resize the image into a thumbnail.</p> <p>Usage:</p> <pre><code># thumbnail size 50x50 pixels\nthumb = Thumbnail(50, 50)\n</code></pre> Source code in <code>nucleus/sdk/processing/image/settings.py</code> <pre><code>@dataclass(slots=True)\nclass Thumbnail:\n\"\"\"Resize the image into a thumbnail.\n\n    Usage:\n\n        # thumbnail size 50x50 pixels\n        thumb = Thumbnail(50, 50)\n    \"\"\"\n\n    _size: Tuple[int, int] = field(init=False)\n    _gap: float = field(init=False)\n    _resample: Resampling = field(init=False)\n\n    width: int\n    height: int\n\n    def __post_init__(self):\n        self._gap = 2.0\n        self._size = (self.width, self.height)\n        self._resample = Resampling.BICUBIC\n\n    def reducing_gap(self, gap: float):\n        self._gap = gap\n\n    def resample(self, resample: Resampling):\n        self._resample = resample\n\n    def __iter__(self):\n        yield 'size', self._size\n        yield 'resample', self._resample\n        yield 'reducing_gap', self._gap\n</code></pre>"},{"location":"reference/processing/image/settings/#nucleus.sdk.processing.image.settings.Resize","title":"<code>Resize</code>  <code>dataclass</code>","text":"<p>Resize the image to a given size.</p> <p>Usage:</p> <pre><code># new image size 100x100\nresize = Resize(100, 100)\n</code></pre> Source code in <code>nucleus/sdk/processing/image/settings.py</code> <pre><code>@dataclass(slots=True)\nclass Resize:\n\"\"\"Resize the image to a given size.\n\n    Usage:\n\n        # new image size 100x100\n        resize = Resize(100, 100)\n    \"\"\"\n\n    _size: Tuple[int, int] = field(init=False)\n    _box: Tuple[int, int, int, int] = field(init=False)\n    _resample: Resampling = field(init=False)\n\n    width: int\n    height: int\n\n    def __post_init__(self):\n        self._size = (self.width, self.height)\n        self._box = (0, 0, *self._size)\n        self._resample = Resampling.BICUBIC\n\n    def crop(self, box: Coord):\n        self._box = (box.left, box.top, box.right, box.bottom)\n\n    def resample(self, resample: Resampling):\n        self._resample = resample\n\n    def __iter__(self):\n        yield 'size', self._size\n        yield 'resample', self._resample\n        yield 'box', self._box\n</code></pre>"},{"location":"reference/processing/image/settings/#coordinate-system","title":"Coordinate System","text":"<p>\"The Python Imaging Library uses a Cartesian pixel coordinate system, with (0,0) in the upper left corner. Note that the coordinates refer to the implied pixel corners; the centre of a pixel addressed as (0, 0) actually lies at (0.5, 0.5).\" - pillow</p> <p>Note</p> <p>During processing time, the setting classes are parsed as a method to dynamically call pillow image object. To know more about the settings implemented in this reference please see pillow docs.</p>"},{"location":"reference/processing/image/settings/#nucleus.sdk.processing.image.settings.Coord","title":"<code>Coord</code>  <code>dataclass</code>","text":"<p>Represents a cartesian pixel coordinate.</p> <p>Usage:</p> <pre><code># two points in the cartesian plane: top + left, right + bottom\ncoord = Coord(10, 10, 50, 50) # left, top, right, bottom coordinates\n</code></pre> Source code in <code>nucleus/sdk/processing/image/settings.py</code> <pre><code>@dataclass(slots=True)\nclass Coord:\n\"\"\"Represents a cartesian pixel coordinate.\n\n    Usage:\n\n        # two points in the cartesian plane: top + left, right + bottom\n        coord = Coord(10, 10, 50, 50) # left, top, right, bottom coordinates\n    \"\"\"\n\n    left: int\n    top: int\n    right: int\n    bottom: int\n</code></pre>"},{"location":"reference/processing/video/codecs/","title":"Codecs","text":"<p>Info</p> <p>Most of the parameters set for the codecs are those established by default in ffmpeg official docs. However, some parameters have been modified in order to achieve an improvement in performance. </p> <pre><code># HLS default constants\n# https://developer.apple.com/documentation/http-live-streaming/hls-authoring-specification-for-apple-devices\nHLS_TIME = 10\nHLS_LIST_SIZE = 0\nHLS_TAG_VIDEO_FORMAT = 'hvc1'\nHLS_PLAYLIST_TYPE = 'vod'\n\n\nDEFAULT_AUDIO_CODEC = 'aac'\n# The range of the CRF scale is 0\u201351, where 0 is lossless (higher quality)\nDEFAULT_CRF = 0\n# The preset determines compression efficiency and therefore affects encoding speed\n# This option itemizes a range of choices from veryfast (best speed) to\n# veryslow (best quality).\nDEFAULT_PRESET = 'medium'\n# keyframes minimum every 100 frames\nDEFAULT_KEY_MIN = 100\n# maximum amount of GOP size, maximum every 100 frames there will be a\n# keyframe, together with -keyint_min this gives a keyframe every 100\n# frames\nDEFAULT_GOP = 100\n# ffmpeg has scene detection. 0 (stands for false)\nDEFAULT_SC_THRESHOLD = 0\n</code></pre>"},{"location":"reference/processing/video/codecs/#nucleus.sdk.processing.video.codecs.Copy","title":"<code>Copy</code>","text":"<p>Used to <code>copy</code> the codec from the source to the output. Special value copy (output only) to indicate that the stream is not to be re-encoded.</p> <p>Usage:</p> <pre><code>copy_audio_stream = Copy(\"a\")\ncopy_video_stream = Copy(\"v\")\n</code></pre> Source code in <code>nucleus/sdk/processing/video/codecs.py</code> <pre><code>class Copy:\n\"\"\"Used to `copy` the codec from the source to the output.\n    Special value copy (output only) to indicate that the stream is not to be re-encoded.\n\n    Usage:\n\n        copy_audio_stream = Copy(\"a\")\n        copy_video_stream = Copy(\"v\")\n    \"\"\"\n\n    _stream_specifier: str\n\n    def __init__(self, stream: Literal['v', 'a'] = 'v'):  # noqa: F821\n        self._stream_specifier = stream\n\n    def __contains__(self, codec: str) -&gt; bool:\n        ...\n\n    def __iter__(self):\n        yield f'c:{self._stream_specifier}', 'copy'\n</code></pre>"},{"location":"reference/processing/video/codecs/#nucleus.sdk.processing.video.codecs.H264","title":"<code>H264</code>","text":"<p>Represents a H264 codec.</p> <p>Usage:</p> <pre><code>h264 = H264()\n</code></pre> Source code in <code>nucleus/sdk/processing/video/codecs.py</code> <pre><code>class H264:\n\"\"\"Represents a H264 codec.\n\n    Usage:\n\n        h264 = H264()\n\n    \"\"\"\n\n    def __contains__(self, codec: str) -&gt; bool:\n        videos = ['libx264', 'h264', 'h264_afm', 'h264_nvenc']\n        audios = ['aac', 'libvo_aacenc', 'libfaac', 'libmp3lame', 'libfdk_aac']\n        allowed_codecs = videos + audios\n        return codec in allowed_codecs\n\n    def __iter__(self):\n        yield 'bf', 1\n        yield 'g', DEFAULT_GOP\n        yield 'crf', DEFAULT_CRF\n        yield 'keyint_min', DEFAULT_KEY_MIN\n        yield 'sc_threshold', DEFAULT_SC_THRESHOLD\n        yield 'c:a', DEFAULT_AUDIO_CODEC\n        yield 'c:v', 'libx264'\n</code></pre>"},{"location":"reference/processing/video/codecs/#nucleus.sdk.processing.video.codecs.HEVC","title":"<code>HEVC</code>","text":"<p>Represents a HEVC codec.</p> <p>Usage:</p> <pre><code>hevc = HEVC()\n</code></pre> Source code in <code>nucleus/sdk/processing/video/codecs.py</code> <pre><code>class HEVC:\n\"\"\"Represents a HEVC codec.\n\n    Usage:\n\n        hevc = HEVC()\n\n    \"\"\"\n\n    def __contains__(self, codec: str) -&gt; bool:\n        videos = ['libx265', 'h265']\n        audios = ['aac', 'libvo_aacenc', 'libfaac', 'libmp3lame', 'libfdk_aac']\n        allowed_codecs = videos + audios\n        return codec in allowed_codecs\n\n    def __iter__(self):\n        yield 'g', DEFAULT_GOP\n        yield 'crf', DEFAULT_CRF\n        yield 'keyint_min', DEFAULT_KEY_MIN\n        yield 'sc_threshold', DEFAULT_SC_THRESHOLD\n        yield 'c:a', DEFAULT_AUDIO_CODEC\n        yield 'c:v', 'libx265'\n        yield 'x265-params', 'lossless=1'\n</code></pre>"},{"location":"reference/processing/video/codecs/#nucleus.sdk.processing.video.codecs.VP9","title":"<code>VP9</code>","text":"<p>Represents a VP9 codec.</p> <p>Usage:</p> <pre><code>vp9 = VP9()\n</code></pre> Source code in <code>nucleus/sdk/processing/video/codecs.py</code> <pre><code>class VP9:\n\"\"\"Represents a VP9 codec.\n\n    Usage:\n\n        vp9 = VP9()\n\n    \"\"\"\n\n    def __contains__(self, codec: str) -&gt; bool:\n        videos = ['libvpx', 'libvpx-vp9']\n        audios = ['aac', 'libvo_aacenc', 'libfaac', 'libmp3lame', 'libfdk_aac']\n        allowed_codecs = videos + audios\n        return codec in allowed_codecs\n\n    def __iter__(self):\n        yield 'c:a', DEFAULT_AUDIO_CODEC\n        yield 'c:v', 'libvpx-vp9'\n</code></pre>"},{"location":"reference/processing/video/protocols/","title":"Protocols","text":""},{"location":"reference/processing/video/protocols/#nucleus.sdk.processing.video.protocols.HLS","title":"<code>HLS</code>  <code>dataclass</code>","text":"<p>Represents a HLS streaming protocol.</p> <p>Usage:</p> <pre><code># use h264 as codec\nhls = HLS(H264())\n</code></pre> Source code in <code>nucleus/sdk/processing/video/protocols.py</code> <pre><code>@dataclass(slots=True)\nclass HLS:\n\"\"\"Represents a HLS streaming protocol.\n\n    Usage:\n\n        # use h264 as codec\n        hls = HLS(H264())\n\n    \"\"\"\n\n    # default h264 codec\n    codec: Codec = H264()\n\n    def __iter__(self):\n        yield 'hls_time', HLS_TIME\n        yield 'hls_list_size', HLS_LIST_SIZE\n        yield 'hls_playlist_type', HLS_PLAYLIST_TYPE,\n        yield 'tag:v', HLS_TAG_VIDEO_FORMAT,\n        yield from self.codec\n</code></pre>"},{"location":"reference/processing/video/settings/","title":"Settings","text":""},{"location":"reference/processing/video/settings/#nucleus.sdk.processing.video.settings.FPS","title":"<code>FPS</code>  <code>dataclass</code>","text":"<p>Set the frame rate (Hz value, fraction or abbreviation).</p> <p>Usage:</p> <pre><code># frame per seconds\nfps = FPS(fs=60)\n</code></pre> Source code in <code>nucleus/sdk/processing/video/settings.py</code> <pre><code>@dataclass(slots=True)\nclass FPS:\n\"\"\"Set the frame rate (Hz value, fraction or abbreviation).\n\n    Usage:\n\n        # frame per seconds\n        fps = FPS(fs=60)\n    \"\"\"\n\n    fps: float\n\n    def __iter__(self):\n        yield 'r', self.fps\n</code></pre>"},{"location":"reference/processing/video/settings/#nucleus.sdk.processing.video.settings.BR","title":"<code>BR</code>  <code>dataclass</code>","text":"<p>Set the Video/Audio bitrate.</p> <p>Usage:</p> <pre><code># set bitrate for both streams or independent\nbr = BR(100) # audio/video\nbr = BR(150, 94) # video b:v 150, audio b:a 94\n</code></pre> Source code in <code>nucleus/sdk/processing/video/settings.py</code> <pre><code>@dataclass(slots=True)\nclass BR:\n\"\"\"Set the Video/Audio bitrate.\n\n    Usage:\n\n        # set bitrate for both streams or independent\n        br = BR(100) # audio/video\n        br = BR(150, 94) # video b:v 150, audio b:a 94\n\n    \"\"\"\n\n    video: int\n    audio: int = 0\n\n    def __iter__(self):\n        # if we only receive video bitrate, we consider it as overall bitrate\n        if self.video and not self.audio:\n            yield 'b', f'{self.video}k'\n            return\n\n        yield 'b:v', f'{self.video}k'\n        yield 'b:a', f'{self.audio}k'\n</code></pre>"},{"location":"reference/processing/video/settings/#nucleus.sdk.processing.video.settings.Custom","title":"<code>Custom</code>  <code>dataclass</code>","text":"<p>Special class for directly specifying custom settings to the ffmpeg command.</p> <p>Usage:</p> <pre><code># create a custom command based on ffmpeg option -fs\n# No further chunk of bytes is written after the limit is exceeded.\ncustom = Custom(fs=100)\n</code></pre> Source code in <code>nucleus/sdk/processing/video/settings.py</code> <pre><code>@dataclass(slots=True)\nclass Custom:\n\"\"\"Special class for directly specifying custom settings to the ffmpeg command.\n\n    Usage:\n\n        # create a custom command based on ffmpeg option -fs\n        # No further chunk of bytes is written after the limit is exceeded.\n        custom = Custom(fs=100)\n    \"\"\"\n\n    _custom: Mapping[str, Any]\n\n    def __init__(self, **kwargs: Any):\n        self._custom = kwargs\n\n    def __iter__(self):\n        yield from self._custom.items()\n</code></pre>"},{"location":"reference/processing/video/settings/#nucleus.sdk.processing.video.settings.FrameSize","title":"<code>FrameSize</code>  <code>dataclass</code>","text":"<p>Set the frame size.</p> <p>Usage:</p> <pre><code># the output screen size\nsize = FrameSize(200, 200)\n</code></pre> Source code in <code>nucleus/sdk/processing/video/settings.py</code> <pre><code>@dataclass(slots=True)\nclass FrameSize:\n\"\"\"Set the frame size.\n\n    Usage:\n\n        # the output screen size\n        size = FrameSize(200, 200)\n    \"\"\"\n\n    width: int\n    height: int\n\n    def __str__(self) -&gt; str:\n        return f'{self.width}x{self.height}'\n\n    def __iter__(self):\n        yield 's', str(self)\n</code></pre>"},{"location":"reference/processing/video/settings/#defaults","title":"Defaults","text":"<p>Note</p> <p>During processing time, the setting classes are parsed as configuration arguments for FFMPEG python library. To know more about the settings implemented in this reference please see FFMPEG main options.</p>"},{"location":"reference/processing/video/settings/#nucleus.sdk.processing.video.settings.Screen","title":"<code>Screen</code>  <code>dataclass</code>","text":"<p>Default standard screen size settings.</p> <p>Usage:</p> <pre><code># using default screen sizes\nbr = Screen.Q720 # appropriate size 720p\n</code></pre> Source code in <code>nucleus/sdk/processing/video/settings.py</code> <pre><code>@dataclass(frozen=True)\nclass Screen:\n\"\"\"Default standard screen size settings.\n\n    Usage:\n\n        # using default screen sizes\n        br = Screen.Q720 # appropriate size 720p\n\n    \"\"\"\n\n    Q240 = FrameSize(416, 234)\n    Q360 = FrameSize(640, 360)\n    Q480 = FrameSize(854, 480)\n    Q720 = FrameSize(1280, 720)\n    Q1080 = FrameSize(1920, 1080)\n    Q2k = FrameSize(2560, 1440)\n    Q4k = FrameSize(3840, 2160)\n</code></pre>"},{"location":"reference/processing/video/settings/#nucleus.sdk.processing.video.settings.Bitrate","title":"<code>Bitrate</code>  <code>dataclass</code>","text":"<p>Default standard bitrate settings.</p> <p>Usage:</p> <pre><code># using default standard bitrate\nbr = Bitrate.B720 # appropriate bitrate for 720p\n</code></pre> Source code in <code>nucleus/sdk/processing/video/settings.py</code> <pre><code>@dataclass(frozen=True)\nclass Bitrate:\n\"\"\"Default standard bitrate settings.\n\n    Usage:\n\n        # using default standard bitrate\n        br = Bitrate.B720 # appropriate bitrate for 720p\n    \"\"\"\n\n    B240 = BR(150, 94)\n    B360 = BR(276, 128)\n    B480 = BR(750, 192)\n    B720 = BR(2048, 320)\n    B1080 = BR(4096, 320)\n    B2k = BR(6144, 320)\n    B4k = BR(17408, 320)\n</code></pre>"},{"location":"reference/processing/video/types/","title":"Types","text":""},{"location":"reference/processing/video/types/#nucleus.sdk.processing.video.types.Codec","title":"<code>Codec</code>","text":"<p>         Bases: <code>Settings</code>, <code>Protocol</code></p> <p>Codec specify the behavior of video compression formats.</p>"},{"location":"reference/processing/video/types/#nucleus.sdk.processing.video.types.Codec.__contains__","title":"<code>__contains__(codec)</code>","text":"<p>Check if the available codecs contain the specified codec. This method can be useful to avoid re-encoding by checking if a codec match exists allowing for a direct copy operation.</p> <p>Parameters:</p> Name Type Description Default <code>codec</code> <code>str</code> <p>The name of the codec to match</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if match else False</p> Source code in <code>nucleus/sdk/processing/video/types.py</code> <pre><code>def __contains__(self, codec: str) -&gt; bool:\n\"\"\"Check if the available codecs contain the specified codec.\n    This method can be useful to avoid re-encoding by checking if a codec match exists\n    allowing for a direct copy operation.\n\n    :param codec: The name of the codec to match\n    :returns: True if match else False\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/storage/services/","title":"Services","text":"<p>Info</p> <p>Services are storage providers within the IPFS ecosystem. Any storage service that exposes an API is compatible and can be integrated into the SDK by implementing the service protocol.</p>"},{"location":"reference/storage/services/#nucleus.sdk.storage.services.Estuary","title":"<code>Estuary</code>  <code>dataclass</code>","text":"<p>Estuary API service client.</p> <p>Usage:</p> <pre><code>estuary_endpoint = \"https://api.estuary.tech\"\nestuary_key =  \"ESTbb693fa8-d758-48ce-9843-a8acadb98a53ARY\" # fake key\nestuary = EstuaryClient(estuary_endpoint, estuary_key)\n\npin = estuary.pin(stored_object)\nremoved_cid = estuary.unpin(pin.cid)\n</code></pre> Source code in <code>nucleus/sdk/storage/services.py</code> <pre><code>@dataclass\nclass Estuary:\n\"\"\"Estuary API service client.\n\n    Usage:\n\n        estuary_endpoint = \"https://api.estuary.tech\"\n        estuary_key =  \"ESTbb693fa8-d758-48ce-9843-a8acadb98a53ARY\" # fake key\n        estuary = EstuaryClient(estuary_endpoint, estuary_key)\n\n        pin = estuary.pin(stored_object)\n        removed_cid = estuary.unpin(pin.cid)\n\n\n    \"\"\"\n\n    endpoint: URL\n    key: str\n\n    def __post_init__(self):\n        self._http = http_client.live_session(self.endpoint)\n        self._http.headers.update({'Authorization': f'Bearer {self.key}'})\n        self._http.headers.update({'Content-Type': 'application/json'})\n\n    def _safe_request(self, res: Response) -&gt; JSON:\n\"\"\"Amplifier helper method to handle response from Estuary API\n\n        :param res: Expected response\n        :return: Json response\n        :raises StorageServiceError: If an error occurs during request\n        \"\"\"\n\n        # expected response as json\n        response = res.json()\n\n        # if response fail\n        if not res.ok:\n\"\"\"\n            Observable behavior:\n                {\n                    \"code\": 0,\n                    \"details\": \"string\",\n                    \"reason\": \"string\"\n                }\n            \"\"\"\n\n            error_description = response['error']['details']\n            raise StorageServiceError(f'exception raised during request: {error_description}')\n\n        return JSON(response)\n\n    def _content_by_cid(self, cid: CID) -&gt; JSON:\n\"\"\"Collect details from estuary based on CID\n\n        :param cid: Cid to retrieve content details\n        :return: Cid content details\n        :raises EdgePinException: If pin request fails\n        \"\"\"\n\n        content_uri = f'{ESTUARY_API_PUBLIC}/by-cid/{cid}'\n        req = self._http.get(content_uri)\n\n        # expected response as json\n        response = self._safe_request(req)\n        return response.get('content', {})\n\n    def pin(self, obj: Object) -&gt; Pin:\n\"\"\"Pin cid into estuary\n\n        :param obj: Object to pin\n        :return: Pin object\n        :raises StorageServiceError: If pin request fails\n        \"\"\"\n\n        # https://docs.estuary.tech/Reference/SwaggerUI#/pinning/post_pinning_pins\n        data = str(JSON({'cid': obj.hash, 'name': obj.name, 'meta': {}, 'origins': []}))\n\n        req = self._http.post(ESTUARY_API_PIN, data=data)\n        json_response = self._safe_request(req)\n\n        return Pin(\n            cid=json_response['cid'],\n            name=json_response['name'],\n            status='pending',\n        )\n\n    def unpin(self, cid: CID) -&gt; CID:\n\"\"\"Remove pin from estuary\n\n        :param cid: The cid to remove from service\n        :return: The recently removed CID\n        :raises StorageServiceError: if an error occurs during request\n        \"\"\"\n\n        # content id is same as pin id\n        pin_id = self._content_by_cid(cid).get('id')\n        response = self._http.delete(f'{ESTUARY_API_PIN}/{pin_id}')\n        # If error happens then raise standard exception.\n        self._safe_request(response)\n        return cid\n</code></pre>"},{"location":"reference/storage/services/#nucleus.sdk.storage.services.Estuary.pin","title":"<code>pin(obj)</code>","text":"<p>Pin cid into estuary</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Object</code> <p>Object to pin</p> required <p>Returns:</p> Type Description <code>Pin</code> <p>Pin object</p> <p>Raises:</p> Type Description <code>StorageServiceError</code> <p>If pin request fails</p> Source code in <code>nucleus/sdk/storage/services.py</code> <pre><code>def pin(self, obj: Object) -&gt; Pin:\n\"\"\"Pin cid into estuary\n\n    :param obj: Object to pin\n    :return: Pin object\n    :raises StorageServiceError: If pin request fails\n    \"\"\"\n\n    # https://docs.estuary.tech/Reference/SwaggerUI#/pinning/post_pinning_pins\n    data = str(JSON({'cid': obj.hash, 'name': obj.name, 'meta': {}, 'origins': []}))\n\n    req = self._http.post(ESTUARY_API_PIN, data=data)\n    json_response = self._safe_request(req)\n\n    return Pin(\n        cid=json_response['cid'],\n        name=json_response['name'],\n        status='pending',\n    )\n</code></pre>"},{"location":"reference/storage/services/#nucleus.sdk.storage.services.Estuary.unpin","title":"<code>unpin(cid)</code>","text":"<p>Remove pin from estuary</p> <p>Parameters:</p> Name Type Description Default <code>cid</code> <code>CID</code> <p>The cid to remove from service</p> required <p>Returns:</p> Type Description <code>CID</code> <p>The recently removed CID</p> <p>Raises:</p> Type Description <code>StorageServiceError</code> <p>if an error occurs during request</p> Source code in <code>nucleus/sdk/storage/services.py</code> <pre><code>def unpin(self, cid: CID) -&gt; CID:\n\"\"\"Remove pin from estuary\n\n    :param cid: The cid to remove from service\n    :return: The recently removed CID\n    :raises StorageServiceError: if an error occurs during request\n    \"\"\"\n\n    # content id is same as pin id\n    pin_id = self._content_by_cid(cid).get('id')\n    response = self._http.delete(f'{ESTUARY_API_PIN}/{pin_id}')\n    # If error happens then raise standard exception.\n    self._safe_request(response)\n    return cid\n</code></pre>"},{"location":"reference/storage/types/","title":"Types","text":""},{"location":"reference/storage/types/#nucleus.sdk.storage.types.Object","title":"<code>Object</code>  <code>dataclass</code>","text":"<p>Distributed/Stored media representation. This class is used to represent any media decentralized and already stored in IPFS.</p> <p>Usage:</p> <pre><code># generally, these objects are returned by storage operations\nstored_object = Object(\"bafyjvzacdjrk37kqvy5hbqepmcraz3txt3igs7dbjwwhlfm3433a\",\"image\",250)\n</code></pre> Source code in <code>nucleus/sdk/storage/types.py</code> <pre><code>@dataclass(slots=True)\nclass Object:\n\"\"\"Distributed/Stored media representation.\n    This class is used to represent any media decentralized and already stored in IPFS.\n\n    Usage:\n\n        # generally, these objects are returned by storage operations\n        stored_object = Object(\"bafyjvzacdjrk37kqvy5hbqepmcraz3txt3igs7dbjwwhlfm3433a\",\"image\",250)\n    \"\"\"\n\n    hash: CID\n    name: str\n    size: int\n</code></pre>"},{"location":"reference/storage/types/#nucleus.sdk.storage.types.Pin","title":"<code>Pin</code>  <code>dataclass</code>","text":"<p>Represents ipfs pin output</p> <p>Usage:</p> <pre><code># generally, returned by pinning operations\npin = Pin(\"bafyjvzacdjrk37kqvy5hbqepmcraz3txt3igs7dbjwwhlfm3433a\",\"pinned\", \"image.jpg\")\n</code></pre> Source code in <code>nucleus/sdk/storage/types.py</code> <pre><code>@dataclass(slots=True)\nclass Pin:\n\"\"\"Represents ipfs pin output\n\n    Usage:\n\n        # generally, returned by pinning operations\n        pin = Pin(\"bafyjvzacdjrk37kqvy5hbqepmcraz3txt3igs7dbjwwhlfm3433a\",\"pinned\", \"image.jpg\")\n    \"\"\"\n\n    cid: CID\n    status: str\n    name: Optional[str]\n</code></pre>"},{"location":"reference/storage/types/#nucleus.sdk.storage.types.Client","title":"<code>Client</code>","text":"<p>         Bases: <code>Protocol</code></p> <p>Provides an standard interface for handling IPFS storage services. Each storage service represents a remote cache service, such as Estuary.</p> Source code in <code>nucleus/sdk/storage/types.py</code> <pre><code>@runtime_checkable\nclass Client(Protocol):\n\"\"\"Provides an standard interface for handling IPFS storage services. Each storage service\n    represents a remote cache service, such as Estuary.\n    \"\"\"\n\n    def pin(self, obj: Object) -&gt; Pin:\n\"\"\"Pin cid to storage service\n\n        :param obj: Object to pin\n        :return: Pin object\n        \"\"\"\n        ...\n\n    def unpin(self, cid: CID) -&gt; CID:\n\"\"\"Remove pin from storage service\n\n        :param cid: The cid to remove from service\n        :return: The just removed object cid\n        \"\"\"\n        ...\n</code></pre>"},{"location":"reference/storage/types/#nucleus.sdk.storage.types.Client.pin","title":"<code>pin(obj)</code>","text":"<p>Pin cid to storage service</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Object</code> <p>Object to pin</p> required <p>Returns:</p> Type Description <code>Pin</code> <p>Pin object</p> Source code in <code>nucleus/sdk/storage/types.py</code> <pre><code>def pin(self, obj: Object) -&gt; Pin:\n\"\"\"Pin cid to storage service\n\n    :param obj: Object to pin\n    :return: Pin object\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/storage/types/#nucleus.sdk.storage.types.Client.unpin","title":"<code>unpin(cid)</code>","text":"<p>Remove pin from storage service</p> <p>Parameters:</p> Name Type Description Default <code>cid</code> <code>CID</code> <p>The cid to remove from service</p> required <p>Returns:</p> Type Description <code>CID</code> <p>The just removed object cid</p> Source code in <code>nucleus/sdk/storage/types.py</code> <pre><code>def unpin(self, cid: CID) -&gt; CID:\n\"\"\"Remove pin from storage service\n\n    :param cid: The cid to remove from service\n    :return: The just removed object cid\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/storage/utilities/","title":"Utilities","text":"<p>Info</p> <p><code>Store</code> is a repository of storage options in the form of a function that automatically selects the appropriate storage strategy based on the type of the parameter.</p>"},{"location":"reference/storage/utilities/#nucleus.sdk.storage.store.ipfs","title":"<code>ipfs(endpoint=None)</code>","text":"<p>Higher-order function to handle storage endpoint and return a singledispatch generic function with preset storage strategies. This is a form of generic function dispatch where the implementation is chosen based on the type of a single argument.</p> <p>Usage:</p> <pre><code>store = storage.ipfs() # default localhost:5001\nstored_object = store(b'test bytes') # auto-choose the storage strategy\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>endpoint</code> <code>Optional[str]</code> <p>Endpoint to connect to the API. If the endpoint is not specified, localhost is used instead.</p> <code>None</code> <p>Returns:</p> Type Description <code>Store</code> <p>Singledispatch decorated function</p> Source code in <code>nucleus/sdk/storage/store.py</code> <pre><code>def ipfs(endpoint: Optional[str] = None) -&gt; Store:\n\"\"\"Higher-order function to handle storage endpoint and\n    return a singledispatch generic function with preset storage strategies.\n    This is a form of generic function dispatch where the\n    implementation is chosen based on the type of a single argument.\n\n    Usage:\n\n        store = storage.ipfs() # default localhost:5001\n        stored_object = store(b'test bytes') # auto-choose the storage strategy\n\n\n    :param endpoint: Endpoint to connect to the API. If the endpoint is not specified, localhost is used instead.\n    :return: Singledispatch decorated function\n    \"\"\"\n\n    # Connect to the IPFS API interface\n    api = ipfs_.rpc(endpoint)\n\n    @functools.singledispatch\n    def store(data: Storable) -&gt; Object:\n\"\"\"Storage single dispatch factory.\n        Uses the data input type to infer the right storage strategy.\n\n        :param data: The model to dispatch\n        :return: Object instance\n        \"\"\"\n        raise NotImplementedError(f'cannot process not registered storable `{data}')\n\n    @store.register\n    def _(data: FileType) -&gt; Object:\n\"\"\"Store files in IPFS.\n\n        :param data: File to store\n        :return: Object instance\n        \"\"\"\n        command = Add(File(data.path))\n        # expected /add output from API\n        # {Hash: .., Name: .., Size: ...}\n        file_output = api(command)\n\n        return Object(\n            name=file_output['Name'],\n            hash=CID(file_output['Hash']),\n            size=int(file_output['Size']),\n        )\n\n    @store.register\n    def _(data: Path) -&gt; Object:\n\"\"\"Store directory in IPFS.\n\n        :param data: Directory path to store\n        :return: Object instance\n        \"\"\"\n        command = Add(\n            input=Dir(data),\n            wrap_with_directory=True,\n        )\n\n        # expected /add output from API\n        # {Hash: .., Name: .., Size: ...}\n        dir_output = api(command)\n\n        return Object(\n            name=dir_output['Name'],\n            hash=CID(dir_output['Hash']),\n            size=int(dir_output['Size']),\n        )\n\n    @store.register\n    def _(data: bytes) -&gt; Object:\n\"\"\"Store bytes in IPFS.\n        Store bytes in raw blocks.\n\n        :param data: Bytes to store\n        :return: Object instance\n        \"\"\"\n\n        command = BlockPut(Text(data))\n        # expected block/put output from API\n        # {Key: .., Size: ..}\n        output = api(command)\n\n        return Object(\n            name=output['Key'],\n            hash=CID(output['Key']),\n            size=len(data),\n        )\n\n    @store.register\n    def _(data: str) -&gt; Object:\n\"\"\"String string in IPFS.\n        Encode string to bytes and store it in raw blocks.\n\n        :param data: String to store\n        :return: Object instance\n        \"\"\"\n\n        bytes_ = bytes(data, 'utf-8')\n        return store(bytes_)\n\n    @store.register\n    def _(data: JSON) -&gt; Object:\n\"\"\"Store JSON in IPFS Dag.\n\n        :param data: JSON to store\n        :return: Object instance\n        \"\"\"\n\n        bytes_ = bytes(data)\n        command = DagPut(Text(bytes_))\n        # expected block/put output from API\n        # {\"Cid\": { \"/\": \"&lt;cid-string&gt;\" }}\n        output = api(command)\n        raw_cid = output['Cid']['/']\n\n        return Object(\n            name=raw_cid,\n            hash=CID(raw_cid),\n            size=len(data),\n        )\n\n    return store\n</code></pre>"},{"location":"reference/storage/utilities/#built-in-partials","title":"Built-in partials","text":"<pre><code># default request to https://api.estuary.tech\nestuary = functools.partial(Estuary, ESTUARY_API_BASE)\n</code></pre> <p>Note</p> <p>These partial allows the fast creation of services. Any storage service that exposes an API is compatible and can be integrated into the SDK by implementing the service protocol.</p>"}]}