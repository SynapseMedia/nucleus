{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started","text":""},{"location":"#nucleus","title":"Nucleus","text":"<p>NOTE! Nucleus is alpha-stage software. It means nucleus hasn't been security audited and programming APIs and data formats can still change.</p> <p>Nucleus is a collection of low-level tools for decentralized media management, that simplifies the processing, storage, and distribution of multimedia. Its key features include:</p> <ol> <li>Metadata harvesting: Simplify the extraction and collection of metadata associated with multimedia resources.</li> <li>Multimedia processing: Robust tools for processing multimedia content, including transcoding and image manipulation.</li> <li>Multimedia storage: Enables secure and efficient storage of multimedia files within the IPFS ecosystem.</li> <li>Metadata distribution: Facilitates seamless distribution of metadata across federated networks.</li> <li>Web3 instruments: Integrates with Web3 technologies, leveraging blockchain and smart contracts.</li> </ol>"},{"location":"#installing","title":"Installing","text":"<p>Try nucleus! Install is simple using pip: <code>pip install nucleus-sdk</code></p> <p>Before using <code>nucleus</code>, FFmpeg and IPFS must be installed:</p> <ul> <li>Check the official docs to install IPFS.</li> <li>There are a variety of ways to install FFmpeg, such as the official download links, or using your package manager of choice (e.g. <code>sudo apt install ffmpeg</code> on Debian/Ubuntu, <code>brew install ffmpeg</code> on OS X, etc.).</li> </ul>"},{"location":"#more-info","title":"More info","text":"<ul> <li>Check our roadmap at synapsemedia.io</li> <li>Follow us on twitter | reddit</li> <li>Get in touch with us on slack | discord </li> <li>For help or reporting bugs, please create an issue.</li> </ul>"},{"location":"dev/","title":"Overview","text":"<p>Nucleus follows a modular and layered design approach:</p> <ol> <li> <p>The Core: This layer contains the building block packages that have minimal or no external dependencies. Any dependencies within the core layer will be limited to other internal packages.</p> </li> <li> <p>The SDK: The SDK exposes the programming-level API to interact with the core functions in a safe and conformant way.</p> </li> <li> <p>The CLI and HTTP API: These components utilize the SDK to provide services through command-line interfaces (CLI) and HTTP API endpoints.</p> </li> </ol>"},{"location":"dev/#development-tools","title":"Development tools","text":"<p>Some available capabilities for dev support:</p> <ul> <li>Install: <code>make install</code></li> <li>Tests: <code>make test</code></li> <li>Debug: <code>make debug</code></li> <li>Lint: <code>make lint</code></li> <li>Lint Fix: <code>make format</code></li> </ul> <p>Note: Run <code>make help</code> to check for more capabilities.  </p>"},{"location":"dev/#more-info","title":"More info","text":"<ul> <li>Check our roadmap at synapsemedia.io</li> <li>Follow us on twitter | reddit</li> <li>Get in touch with us on slack | discord </li> <li>For help or reporting bugs, please create an issue.</li> </ul>"},{"location":"dev/arch/","title":"Architecture","text":"<pre><code>graph LR\n  A[Raw] --&gt; B[Harvesting];\n  B --&gt; C[Expose];\n  B -.-&gt; D[Processing];\n  B -.-&gt; E[Storage]\n  D -.-&gt; E[Storage]\n  E -.-&gt; C[Expose]\n  C --&gt; F[Meta Lake]\n  C -.-&gt; G[Mint]\n  F -.-&gt; G[Mint]</code></pre> <p>Nucleus proposes a sequence of steps (pipeline) for the processing and decentralization of multimedia:</p> <ol> <li>Harvesting: Collect metadata associated with the multimedia content.</li> <li>Processing: Performing media processing tasks.</li> <li>Storage:  Store the processed content in the IPFS network.</li> <li>Expose: Distribute metadata through the IPFS ecosystem.</li> <li>Mint: Create metadata as NFTs (Non-Fungible Tokens).</li> <li>Retrieval: Facilitates the retrieval and unmarshalling of metadata from IPFS ecosystem.</li> </ol> <p>The pipeline is modular and adheres to the decoupling principle, enabling flexible use cases. For instance, the storage component can be optional if data is already stored on the IPFS network. Similarly, the mint component can be skipped if there is no need to create NFTs for the metadata. The processing component may also be unnecessary if the media is already prepared for storage.</p> <p>Tip</p> <p>Harvesting and Expose are the sole essential components necessary for operating the pipeline.</p>"},{"location":"dev/arch/#transmissiondistribution","title":"Transmission/Distribution","text":"<p>As part of the metadata federation, Meta Lake emerges as a new concept in the Nucleus ecosystem, referring to the central communication point for metadata distribution. The serialization process of the metadata determines the transmission medium, with IPLD and Raw Blocks being among the means used by Nucleus eg:</p> <pre><code>graph LR\n  R[Expose] --&gt; A[DagJose]\n  A --&gt; B[IPLD];\n  D[Compact] --&gt; F[Raw Block]\n  R --&gt; D[Compact]</code></pre>"},{"location":"guide/example/","title":"Example","text":""},{"location":"guide/example/#full-pipeline-flow","title":"Full pipeline flow","text":"<pre><code>import nucleus.core.logger as logger\nimport nucleus.sdk.harvest as harvest\nimport nucleus.sdk.processing as processing\nimport nucleus.sdk.storage as storage\nimport nucleus.sdk.expose as expose\n\nfrom nucleus.core.types import List, Path\nfrom nucleus.sdk.harvest import Image, Model\nfrom nucleus.sdk.storage import Store, Client, Object\nfrom nucleus.sdk.processing import Resize, Engine, File\nfrom nucleus.sdk.expose import (\n    Structural,\n    Descriptive,\n    Technical,\n    DagJose,\n    Sign,\n    # Compact\n)\n\n\ndef main():\n\n    LOCAL_ENDPOINT = \"http://localhost:5001\"\n    FAKE_KEY = \"ESTbb693fa8-d758-48ce-9843-a8acadb98a53ARY\"\n\n    # 1. prepare our model schema to collect/validate/clean data\n    with logger.console.status(\"Harvesting\"):\n\n        class Nucleus(Model):\n            name: str\n            description: str\n            contributors: List[str]\n\n        # set our data in the model\n        nucleus: Model = Nucleus(\n            name=\"Nucleus the SDK\",\n            description=\"Building block for multimedia decentralization\",\n            contributors=[\"Jacob\", \"Geo\", \"Dennis\", \"Mark\"],\n        )\n\n    # 2. init our processing engine based on our media model\n    with logger.console.status(\"Processing\"):\n        # \"infer\" engine based on input media type\n        image: Image = harvest.image(path=Path(\"arch.png\"))\n        image_engine: Engine = processing.engine(image)\n        image_engine.configure(Resize(50, 50))\n        # finally save the processed image to our custom dir\n        output_file: File = image_engine.save(Path(\"arch2.png\"))\n\n    # 3. store our processed image in local IPFS node and pin it in estuary\n    with logger.console.status(\"Storage\"):\n        local_storage: Store = storage.ipfs(LOCAL_ENDPOINT)\n        stored_file_object: Object = local_storage(output_file)\n        # choose and connect an edge service to pin our resources. eg. estuary\n        estuary: Client = storage.estuary(FAKE_KEY)\n        estuary.pin(stored_file_object)\n\n    # 4. expose our media through the standard\n    with logger.console.status(\"Expose\"):\n        # technical information about image\n        size = output_file.meta.size\n        width = output_file.meta.width\n        height = output_file.meta.height\n        media_type = output_file.meta.type\n\n        # standard implementation\n        # https://github.com/SynapseMedia/sep/blob/main/SEP/SEP-001.md\n        sep001 = expose.standard(media_type)  # image/png\n        # Prepare serialization\n        sep001.set_operation(Sign)\n        sep001.set_serialization(DagJose)\n        # Add signature/recipient key\n        sep001.add_key(expose.es256())\n        # add metadata into payload\n        sep001.add_metadata(Descriptive(**dict(nucleus)))\n        sep001.add_metadata(Structural(cid=stored_file_object.hash))\n        sep001.add_metadata(Technical(size=size, width=width, height=height))\n        # we get signed dag-jose serialization.. let's store it\n        obj: Object = sep001.serialize().save_to(local_storage)\n        # what we do with our new and cool CID?\n        logger.console.print(obj.hash)\n\n\"\"\"\n        Lets try:\n\n            ipfs dag get bagcqceraajwo66kumbcrxf2todw7wjrmayh7tjwaegwigcgpzk745my4qa5a\n\n        \"\"\"\n</code></pre>"},{"location":"guide/expose/","title":"Expose","text":"<p>After learning how to collect, process, and store our media, it's time to understand how to distribute our metadata to reach our target audience. In this guide, we will explore the necessary steps to process the metadata standard and its corresponding distribution through the federated network.</p>"},{"location":"guide/expose/#sep001-standard","title":"SEP001 Standard","text":"<p>Assuming you are already familiar with the anatomy of the standard, let's now examine its implementation. The adoption of the standard is crucial in ensuring smooth integration and compatibility across the federated network. By adhering to the standard defined in SEP001, metadata is effectively handled through an interface that facilitates signing, payload assignment, and the necessary headers.</p> <p>If you need more details about the specific requirements and guidelines of the standard, please refer to the specification document.</p> <p>Now, let's delve into the implementation of the standard in Nucleus.</p> <p>First, let's define the type of media to distribute in the standard header:</p> <pre><code>import nucleus.sdk.expose as expose\n\n# create a standard instance for \"image/jpeg\" media resource\nsep001 = expose.standard(media_type)  \n</code></pre>"},{"location":"guide/expose/#cryptography-serialization","title":"Cryptography &amp; Serialization","text":"<p>Note</p> <p>In Nucleus, it is possible to extend the signature/encryption algorithms using the Keyring protocol. You can see the JWA standard specification for more.</p> <p>Now we can start establishing the cryptographic operations and serialization method we want for our metadata. Let's see an example following the same definition as the previous standard:</p> <pre><code># serialization and sign operation\nsep001.set_operation(Sign)\nsep001.set_serialization(DagJose)\n</code></pre> <p>An important part of the metadata distribution process is the \"signature,\" which allows us to establish the origin of the data and verify the ownership or authorship of our multimedia resources. This process adds the public key and signature to the metadata header.</p> <p>Signing is simple using some \"built-in\" algorithms in the SDK:</p> <pre><code>key = expose.es256()\nsep001.add_key(key)\n</code></pre> <p>Example</p> <p>We can export/import our key using the methods defined in the KeyRing protocol. Let's see a simple example of how to do it:</p> <pre><code># Export the key to later import it\nexported_key = key.as_dict()\n# Restore key to original state\nkey.from_dict(exported_key)\n</code></pre>"},{"location":"guide/expose/#metadata-storage","title":"Metadata &amp; Storage","text":"<p>Now it's time to associate our data with the payload of the metadata. In this step, we add information related to the \"harvesting,\" \"storage,\" and \"processing\" steps. Let's see how all this information is consolidated in the exported metadata:</p> <pre><code># append metadata into payload\nsep001.add_metadata(Descriptive(**dict(nucleus)))\nsep001.add_metadata(Structural(cid=stored_file_object.hash))\nsep001.add_metadata(Technical(size=size, width=width, height=height))\n</code></pre> <p>To store the standard, we can use the \"store\" function, which automatically determines the appropriate storage location based on the selected serialization type. If the serialization is set to DagJose, the metadata will be sent to the IPLD environment through the IPFS DAG service. If it is a compact version, it will be stored directly in a Raw Block. Let's see the example:</p> <pre><code># we get signed dag-jose serialization.. let's store it\nobj = sep001.serialize().save_to(local_storage)\n# What should we do with our new and cool CID?\nlogger.console.print(obj.hash)\n</code></pre> <p>Example</p> <p>It is easy to retrieve our metadata using the tools provided by IPFS. In this case, we can use DAG to traverse DagJose or retrieve the compact version using Block:</p> <pre><code>ipfs dag get bagcqceraajwo66kumbcrxf2todw7wjrmayh7tjwaegwigcgpzk745my4qa5a\nipfs block get bagcqceraajwo66kumbcrxf2todw7wjrmayh7tjwaegwigcgpzk745my4qa5a\n</code></pre>"},{"location":"guide/harvest/","title":"Harvesting","text":"<p>The data harvesting stage involves obtaining \"raw\" information that is available to clean, structure, and validate it, and then distribute it on the network.</p>"},{"location":"guide/harvest/#metadata","title":"Metadata","text":"<p>Metadata collection is carried out using models created based on the requirements of each user and following the SEP001 specification (the standard on which Nucleus is based for metadata management), which provides flexibility for different use cases.</p> <p>Underneath the validation and schematization of the models is pydantic, so we can use python standard library types to define fields.</p> <p>In the example below, we have a model called Nucleus that extends the Model class. It includes fields such as name, description, and contributors, each defined with their respective types (str and List[str]).</p> <pre><code>from nucleus.sdk.harvest import Model\n\nclass Nucleus(Model):\n    name: str\n    description: str\n    contributors: List[str]\n</code></pre> <p>To create an instance of the Nucleus model and populate it with data, you can do the following:</p> <pre><code>nucleus = Nucleus(\n    name=\"Nucleus the SDK\",\n    description=\"Building block for multimedia decentralization\",\n    contributors=[\"Jacob\", \"Geo\", \"Dennis\", \"Mark\"],\n)\n</code></pre>"},{"location":"guide/harvest/#media","title":"Media","text":"<p>Let's explore multimedia resources and how to collect them using the SDK's built-in types.</p> <p>In order to properly handle multimedia resources such as images, videos, music, text, and more, it is important to collect and categorize them using the appropriate types defined or provided by the SDK. These types allow for easy identification and handling of the resources during subsequent stages or processes in the pipeline.</p> <p>Here's an example of how to collect media using the built-in media types:</p> <pre><code>import nucleus.sdk.harvest as harvest\n\n# harvest image and video using built-in types \nimage = harvest.image(path=Path(\"/local/path/image.jpg\"))\nvideo = harvest.video(path=Path(\"/local/path/video.mp4\"))\n</code></pre> <p>Note</p> <p>It is also possible to create our own multimedia type as long as it is accompanied by an engine that takes care of its processing. Please check built-in media types and built-in engines.</p>"},{"location":"guide/processing/","title":"Processing","text":"<p>This step involves processing multimedia resources by performing transformations, transcoding, or other necessary operations based on the required parameters for each specific use case. These operations prepare the resources for consumption over the network.</p>"},{"location":"guide/processing/#engines","title":"Engines","text":"<p>Engines are responsible for processing different types of media, providing configurations according to the nature of each multimedia type and its underlying library. These engines offer flexibility in modifying their behavior through their configurations and expose a standard output.</p> <p>In this example, we will invoke the image processing engine and its configuration process based on the <code>settings</code>. Initializing an engine is straightforward with the functions offered by the processing package:</p> <pre><code>import nucleus.sdk.harvest as harvest\nimport nucleus.sdk.processing as processing\n\nfrom nucleus.core.types import Path\n\n# harvest media using media types\nimage = harvest.image(path=Path(\"image.jpg\"))\nvideo = harvest.video(path=Path(\"video.mp4\"))\n\n# get engines based on media type\nimage_engine = processing.engine(image)\nvideo_engine = processing.engine(video)\n</code></pre> <p>Tip</p> <p>The <code>engine</code> function from the <code>processing</code> package automatically selects the appropriate engine based on the type of multimedia passed as a parameter. Please see more about built-in engines and utilities reference.</p>"},{"location":"guide/processing/#settings","title":"Settings","text":"<p>Each engine provides a set of built-in settings that modify the engine's output and are tailored to the specific characteristics of each multimedia type.</p> <p>Configuring our engine is straightforward with the use of the <code>configure</code> method. Let's explore an example of how to configure the image engine:</p> <pre><code>from nucleus.sdk.processing import Thumbnail\n\n# let's define how the output of our image should be.\nimage_engine.configure(Thumbnail(50,50)) # 50x50 px\noutput_image = engine.save(Path(\"image2.jpg\"))\n</code></pre> <p>Example processing a video:</p> <pre><code>from nucleus.sdk.processing import HLS, VP9, Screen, Bitrate\n\n# let's define how the output of our video should be.\nvideo_engine.configure(HLS(VP9()))\nvideo_engine.configure(Screen.Q1080)\nvideo_engine.configure(Bitrate.B1080)\nvideo_engine.save(Path(\"index.m3u8\"))\n</code></pre> <p>Info</p> <p>Given that the engines emulate the underlying libraries, the available settings are based on the methods or configurations set within each respective library. For further details on the available settings, please refer to the video or image documentation.</p>"},{"location":"guide/storage/","title":"Storage","text":"<p>In this guide, we will explore how to store processed media on the IPFS network using the storage package. We'll cover local storage, services, and clients. We have already learned how to collect multimedia resources and metadata, as well as basic aspects of multimedia processing.</p>"},{"location":"guide/storage/#local-storage","title":"Local Storage","text":"<p>To store our media in the local IPFS node, we can use the <code>local storage</code> feature provided by the storage package. Initializing the local node is straightforward using the <code>ipfs</code> function.</p> <p>Here's an example of how to store an image:</p> <pre><code>import nucleus.sdk.storage as storage\n\nlocal_storage = storage.ipfs(\"http://localhost:5001\")\n# in this case que are storing a File instance, we can obtain it from a processing output\n# if we have an already processed media we can create a custom File instance\nstored_file_object = local_storage(output_image) \n</code></pre> <p>After storing the file locally, we can proceed to pin it or perform further actions.</p> <p>Tip</p> <p>The <code>local_storage</code> is a repository of storage options in the form of a function that automatically selects the appropriate storage strategy based on the type of the parameter. Please see more about in utilities reference.</p>"},{"location":"guide/storage/#services","title":"Services","text":"<p>Services are storage providers within the IPFS ecosystem. Currently, the SDK supports Estuary, a service that provides storage through the IPFS and Filecoin network. Here are some examples of how to configure the service and use it to store multimedia resources.</p> <pre><code>from nucleus.sdk.storage import Estuary\n\nestuary_endpoint = \"https://api.estuary.tech\"\nestuary_key =  \"ESTbb693fa8-d758-48ce-9843-a8acadb98a53ARY\" # fake key\nestuary = Estuary(estuary_endpoint, estuary_key)\n</code></pre> <p>Alternatively, we can use the partial function to make it easier:</p> <pre><code>import nucleus.sdk.storage as storage\n\n# by default the endpoint is bundled inside the factory\nestuary = storage.estuary(estuary_key)\n</code></pre> <p>Since our storage primarily takes place on our local node, we only need to pin our CID on the edge service. Here's an example:</p> <pre><code># ...\nestuary.pin(stored_file_object)\n</code></pre> <p>Tip</p> <p>Any storage service that exposes an API is compatible and can be integrated into the SDK by implementing the service protocol. See more about built-in services reference.</p>"},{"location":"reference/exceptions/","title":"Exceptions","text":""},{"location":"reference/exceptions/#nucleus.sdk.exceptions.HarvestingError","title":"<code>HarvestingError</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Exception raised for errors related to harvesting tasks.</p> Source code in <code>nucleus/sdk/exceptions.py</code> <pre><code>class HarvestingError(Exception):\n\"\"\"Exception raised for errors related to harvesting tasks.\"\"\"\n\n    def __init__(self, message: str, *args: Any, **kwargs: Any):\n        self.message = f'SDK :: Harvesting -&gt; {message}'\n        super().__init__(self.message, *args, **kwargs)\n</code></pre>"},{"location":"reference/exceptions/#nucleus.sdk.exceptions.ProcessingError","title":"<code>ProcessingError</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Exception raised for errors related to processing tasks.</p> Source code in <code>nucleus/sdk/exceptions.py</code> <pre><code>class ProcessingError(Exception):\n\"\"\"Exception raised for errors related to processing tasks.\"\"\"\n\n    def __init__(self, message: str, *args: Any, **kwargs: Any):\n        self.message = f'SDK :: Processing -&gt; {message}'\n        super().__init__(self.message, *args, **kwargs)\n</code></pre>"},{"location":"reference/exceptions/#nucleus.sdk.exceptions.StorageError","title":"<code>StorageError</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Exception raised for errors related to storage tasks.</p> Source code in <code>nucleus/sdk/exceptions.py</code> <pre><code>class StorageError(Exception):\n\"\"\"Exception raised for errors related to storage tasks.\"\"\"\n\n    def __init__(self, message: str, *args: Any, **kwargs: Any):\n        self.message = f'SDK :: Storage -&gt; {message}'\n        super().__init__(self.message, *args, **kwargs)\n</code></pre>"},{"location":"reference/exceptions/#nucleus.sdk.exceptions.ModelManagerError","title":"<code>ModelManagerError</code>","text":"<p>         Bases: <code>HarvestingError</code></p> <p>Raised when a model fails to persist or interact with the underlying cache. ModelManagerError error is a subclass from HarvestingError.</p> Source code in <code>nucleus/sdk/exceptions.py</code> <pre><code>class ModelManagerError(HarvestingError):\n\"\"\"Raised when a model fails to persist or interact with the underlying cache.\n    ModelManagerError error is a subclass from HarvestingError.\n    \"\"\"\n\n    ...\n</code></pre>"},{"location":"reference/exceptions/#nucleus.sdk.exceptions.ModelValidationError","title":"<code>ModelValidationError</code>","text":"<p>         Bases: <code>HarvestingError</code></p> <p>Raised when a model fails during schema validation. ModelValidationError error is a subclass from HarvestingError.</p> Source code in <code>nucleus/sdk/exceptions.py</code> <pre><code>class ModelValidationError(HarvestingError):\n\"\"\"Raised when a model fails during schema validation.\n    ModelValidationError error is a subclass from HarvestingError.\n    \"\"\"\n\n    ...\n</code></pre>"},{"location":"reference/exceptions/#nucleus.sdk.exceptions.StorageServiceError","title":"<code>StorageServiceError</code>","text":"<p>         Bases: <code>StorageError</code></p> <p>Raised when something fails when trying to operate on the edge services. StorageServiceError error is a subclass from StorageError.</p> Source code in <code>nucleus/sdk/exceptions.py</code> <pre><code>class StorageServiceError(StorageError):\n\"\"\"Raised when something fails when trying to operate on the edge services.\n    StorageServiceError error is a subclass from StorageError.\n    \"\"\"\n\n    ...\n</code></pre>"},{"location":"reference/exceptions/#nucleus.sdk.exceptions.ProcessingEngineError","title":"<code>ProcessingEngineError</code>","text":"<p>         Bases: <code>ProcessingError</code></p> <p>Raised when something fail during media processing. ProcessingEngineError error is a subclass from ProcessingError.</p> Source code in <code>nucleus/sdk/exceptions.py</code> <pre><code>class ProcessingEngineError(ProcessingError):\n\"\"\"Raised when something fail during media processing.\n    ProcessingEngineError error is a subclass from ProcessingError.\n    \"\"\"\n\n    ...\n</code></pre>"},{"location":"reference/exceptions/#nucleus.sdk.exceptions.FFProbeError","title":"<code>FFProbeError</code>","text":"<p>         Bases: <code>ProcessingError</code></p> <p>Raised when something fail during ffprobe call. FFProbeError error is a subclass from ProcessingError.</p> Source code in <code>nucleus/sdk/exceptions.py</code> <pre><code>class FFProbeError(ProcessingError):\n\"\"\"Raised when something fail during ffprobe call.\n    FFProbeError error is a subclass from ProcessingError.\n    \"\"\"\n\n    ...\n</code></pre>"},{"location":"reference/expose/serializers/","title":"Serializers","text":"<p>Que hacen? de que estan a cargo?</p>"},{"location":"reference/expose/serializers/#nucleus.sdk.expose.marshall.Compact","title":"<code>Compact(standard)</code>","text":"<p>JWS Compact serialization observer.</p> Source code in <code>nucleus/sdk/expose/marshall.py</code> <pre><code>def __init__(self, standard: Standard):\n    raw_payload = standard.payload()\n    self._header = standard.header()\n    self._claims = list(map(bytes, map(JSON, raw_payload.values())))\n    self._payload = self._payload_cid_values(raw_payload)\n</code></pre>"},{"location":"reference/expose/serializers/#nucleus.sdk.expose.marshall.Compact.__bytes__","title":"<code>__bytes__()</code>","text":"<p>SEP001 as compact serialization</p> Source code in <code>nucleus/sdk/expose/marshall.py</code> <pre><code>def __bytes__(self) -&gt; bytes:\n\"\"\"SEP001 as compact serialization\"\"\"\n    return bytes(self._payload)\n</code></pre>"},{"location":"reference/expose/serializers/#nucleus.sdk.expose.marshall.Compact.update","title":"<code>update(jwt)</code>","text":"<p>Encode JWS/JWE compact serialization when crypto operation notify</p> Source code in <code>nucleus/sdk/expose/marshall.py</code> <pre><code>def update(self, jwt: JWT) -&gt; Compact:\n\"\"\"Encode JWS/JWE compact serialization when crypto operation notify\"\"\"\n    # set new state for serialization attribute\n    self._s11n = jwt.serialize(True)\n    return self\n</code></pre>"},{"location":"reference/expose/serializers/#nucleus.sdk.expose.marshall.DagJose","title":"<code>DagJose(standard)</code>","text":"<p>Dag-JOSE serialization observer.</p> Source code in <code>nucleus/sdk/expose/marshall.py</code> <pre><code>def __init__(self, standard: Standard):\n    self._header = standard.header()\n    self._cbor = dag_cbor.encode(standard.payload())\n    self._cid = _cid_from_bytes(self._cbor, 'dag-cbor')\n</code></pre>"},{"location":"reference/expose/serializers/#nucleus.sdk.expose.marshall.DagJose.__bytes__","title":"<code>__bytes__()</code>","text":"<p>Serialize SEP001 using dag-jose IPLD standard ref: https://ipld.io/specs/codecs/dag-jose/spec/</p> Source code in <code>nucleus/sdk/expose/marshall.py</code> <pre><code>def __bytes__(self) -&gt; bytes:\n\"\"\"Serialize SEP001 using dag-jose IPLD standard\n    ref: https://ipld.io/specs/codecs/dag-jose/spec/\n    \"\"\"\n    return bytes(self._cid)\n</code></pre>"},{"location":"reference/expose/serializers/#nucleus.sdk.expose.marshall.DagJose.update","title":"<code>update(jwt)</code>","text":"<p>Encode JWS/JWE general serialization to dag-jose when crypto operation notify</p> Source code in <code>nucleus/sdk/expose/marshall.py</code> <pre><code>def update(self, jwt: JWT) -&gt; DagJose:\n\"\"\"Encode JWS/JWE general serialization to dag-jose when crypto operation notify\"\"\"\n    general_json = json_decode(jwt.serialize(False))\n    # set new state for serialization attribute\n    self._s11n = JSON({'link': self._cid, **general_json})\n    return self\n</code></pre>"},{"location":"reference/expose/types/","title":"Types","text":""},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Keyring","title":"<code>Keyring</code>","text":"<p>         Bases: <code>Protocol</code></p> <p>Keyring specifies the required methods for handling keys based on the JWK (JSON Web Key) RFC 7517 standard.</p>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Keyring.__iter__","title":"<code>__iter__()</code>","text":"<p>Yield <code>alg</code> and <code>jwk</code> headers specified in RFC 7517/7516 standard.</p> <p>Returns:</p> Type Description <code>Setting</code> <p>The iterable header settings to associate</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def __iter__(self) -&gt; Setting:\n\"\"\"Yield `alg` and `jwk` headers specified in RFC 7517/7516 standard.\n\n    :return: The iterable header settings to associate\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Keyring.as_dict","title":"<code>as_dict()</code>","text":"<p>Export Keyring as JWK JSON format</p> <p>Returns:</p> Type Description <code>Raw</code> <p>Keyring as dict</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def as_dict(self) -&gt; Raw:\n\"\"\"Export Keyring as JWK JSON format\n\n    :return: Keyring as dict\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Keyring.fingerprint","title":"<code>fingerprint()</code>","text":"<p>Return the base64 decoded thumbprint as specified by RFC 7638</p> <p>Returns:</p> Type Description <code>str</code> <p>The decoded thumbprint as string. eg: sha256, blake, etc..</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def fingerprint(self) -&gt; str:\n\"\"\"Return the base64 decoded thumbprint as specified by RFC 7638\n\n    :return: The decoded thumbprint as string. eg: sha256, blake, etc..\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Keyring.from_dict","title":"<code>from_dict(raw_key)</code>","text":"<p>Initialize Keyring using JWK JSON format</p> <p>Parameters:</p> Name Type Description Default <code>raw_key</code> <code>Raw</code> <p>Keyring to import as dict (JSON format)</p> required <p>Returns:</p> Type Description <code>Keyring</code> <p>KeyRing object</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def from_dict(self, raw_key: Raw) -&gt; Keyring:\n\"\"\"Initialize Keyring using JWK JSON format\n\n    :param raw_key: Keyring to import as dict (JSON format)\n    :return: KeyRing object\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Keyring.jwk","title":"<code>jwk()</code>","text":"<p>Return the internal JWK (JSON Web Key) instance</p> <p>Returns:</p> Type Description <code>JWK</code> <p>The JWK (JSON Web Key) instance</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def jwk(self) -&gt; JWK:\n\"\"\"Return the internal JWK (JSON Web Key) instance\n\n    :return: The JWK (JSON Web Key) instance\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Serializer","title":"<code>Serializer(standard)</code>","text":"<p>         Bases: <code>Protocol</code></p> <p>Serializer observer specifies the methods needed to handle SEP001 serialization. Defines how to handle serialization for each strategy according to the specification, which includes:</p> <ul> <li>Compact</li> <li>DAG-JOSE</li> </ul> <p>This template class must be implemented by other classes that provide concrete serialization logic. ref: https://github.com/SynapseMedia/sep/blob/main/SEP/SEP-001.md</p> <p>Serializer must be initialized with Standard implementation</p> <p>Parameters:</p> Name Type Description Default <code>standard</code> <code>Standard</code> <p>The standard implementation</p> required Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def __init__(self, standard: Standard):\n\"\"\"Serializer must be initialized with Standard implementation\n\n    :param standard: The standard implementation\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Serializer.__bytes__","title":"<code>__bytes__()</code>","text":"<p>The payload data ready to sign/encrypt</p> <p>Returns:</p> Type Description <code>bytes</code> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def __bytes__(self) -&gt; bytes:\n\"\"\"The payload data ready to sign/encrypt\n\n    :return:\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Serializer.__iter__","title":"<code>__iter__()</code>","text":"<p>Yield <code>typ</code> headers specified in RFC 7517/7516 standard.</p> <p>Returns:</p> Type Description <code>Setting</code> <p>The iterable media type settings</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def __iter__(self) -&gt; Setting:\n\"\"\"Yield `typ` headers specified in RFC 7517/7516 standard.\n\n    :return: The iterable media type settings\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Serializer.__str__","title":"<code>__str__()</code>","text":"<p>The serialized data as string</p> <p>Returns:</p> Type Description <code>str</code> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def __str__(self) -&gt; str:\n\"\"\"The serialized data as string\n\n    :return: \n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Serializer.save_to","title":"<code>save_to(store)</code>","text":"<p>Could be used to store assets. eg. After generate CID from payload dag-cbor we need to store the bytes into blocks</p> <p>Parameters:</p> Name Type Description Default <code>store</code> <code>Store</code> <p>The local store function</p> required <p>Returns:</p> Type Description <code>Object</code> <p>Object instance</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def save_to(self, store: Store) -&gt; Object:\n\"\"\"Could be used to store assets.\n    eg. After generate CID from payload dag-cbor we need to store the bytes into blocks\n\n    :param store: The local store function\n    :return: Object instance\n    \"\"\"\n\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Serializer.update","title":"<code>update(jwt)</code>","text":"<p>Receive updates when serialization is ready to handle any additional encoding step. In this step we could add a new state or operate over JWS/JWE to handle any additional encoding.</p> <p>Parameters:</p> Name Type Description Default <code>jwt</code> <code>JWT</code> <p>The type of JWT implementation to handle</p> required <p>Returns:</p> Type Description <code>Serializer</code> <p>Self serializer</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def update(self, jwt: JWT) -&gt; Serializer:\n\"\"\"Receive updates when serialization is ready to handle any additional encoding step.\n    In this step we could add a new state or operate over JWS/JWE to handle any additional encoding.\n\n    :param jwt: The type of JWT implementation to handle\n    :return: Self serializer\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Crypto","title":"<code>Crypto(serializer)</code>","text":"<p>         Bases: <code>Protocol</code></p> <p>Specify a pub/sub middleware that handle cryptographic operations on serializers.</p> <p>Initialize with the serializer on which we will operate.</p> <p>Parameters:</p> Name Type Description Default <code>serializer</code> <code>Serializer</code> <p>The serializer implementation</p> required Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def __init__(self, serializer: Serializer):\n\"\"\"Initialize with the serializer on which we will operate.\n\n    :param serializer: The serializer implementation\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Crypto.add_key","title":"<code>add_key(kr)</code>","text":"<p>Bind keys to the serialization process.</p> <p>Parameters:</p> Name Type Description Default <code>kr</code> <code>Keyring</code> <p>Keyring to associate with operation</p> required <p>Returns:</p> Type Description <code>Crypto</code> <p>Crypto object</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def add_key(self, kr: Keyring) -&gt; Crypto:\n\"\"\"Bind keys to the serialization process.\n\n    :param kr: Keyring to associate with operation\n    :return: Crypto object\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/expose/types/#nucleus.sdk.expose.types.Crypto.serialize","title":"<code>serialize()</code>","text":"<p>Notify the underlying serializer of the current state of the cryptographic operation. During this process, the serializer may modify its state or store the results of the operations.</p> <p>Returns:</p> Type Description <code>Serializer</code> <p>The input Serializer with a new ready to use state</p> Source code in <code>nucleus/sdk/expose/types.py</code> <pre><code>def serialize(self) -&gt; Serializer:\n\"\"\"Notify the underlying serializer of the current state of the cryptographic operation.\n    During this process, the serializer may modify its state or store the results of the operations.\n\n    :return: The input Serializer with a new ready to use state\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/harvest/media/","title":"Media","text":"<p>Info</p> <p>This section outlines the supported multimedia resource types. Each type is used for selecting the appropriate processing engine. If necessary, additional types can be easily incorporated.</p> <p>Tip</p> <p>Each media type specifies \"Path\" as the source types from which it can be collected.</p>"},{"location":"reference/harvest/media/#nucleus.sdk.harvest.media.Image","title":"<code>Image</code>","text":"<p>         Bases: <code>Media[Path]</code></p> <p>Represents an image media type.</p> <p>Usage:</p> <pre><code># create a new image type\nimage = Image(path=Path(\"image.jpg\"))\n</code></pre> Source code in <code>nucleus/sdk/harvest/media.py</code> <pre><code>class Image(Media[Path]):\n\"\"\"Represents an image media type.\n\n    Usage:\n\n        # create a new image type\n        image = Image(path=Path(\"image.jpg\"))\n\n\n    \"\"\"\n\n    ...\n</code></pre>"},{"location":"reference/harvest/media/#nucleus.sdk.harvest.media.Video","title":"<code>Video</code>","text":"<p>         Bases: <code>Media[Path]</code></p> <p>Represents a video media type.</p> <p>Usage:</p> <pre><code># create a new video type\nvideo = Video(path=Path(\"video.mp4\"))\n</code></pre> Source code in <code>nucleus/sdk/harvest/media.py</code> <pre><code>class Video(Media[Path]):\n\"\"\"Represents a video media type.\n\n    Usage:\n\n        # create a new video type\n        video = Video(path=Path(\"video.mp4\"))\n\n    \"\"\"\n\n    ...\n</code></pre>"},{"location":"reference/harvest/models/","title":"Models","text":"<p>Info</p> <p>Models serve as the primary mechanism for metadata harvesting. By extending pydantic, defining data models and validating input data becomes effortless.</p>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Base","title":"<code>Base</code>","text":"<p>         Bases: <code>pydantic.BaseModel</code></p> <p>Base model provides efficient model persistence and data validation capabilities. The persistence mechanism relies on sqlite and pickle, allowing the entire model to be stored as a snapshot</p> <p>Usage:</p> <pre><code>class MyModel(BaseModel):\n    name: str\n\n# store a snapshot of the model\nstored_model = MyModel(name=\"Model\")\nstored_model.save()\n\n# we should be able to retrieve the same model\nassert MyModel.all() == [stored_model] # True\n</code></pre> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>class Base(pydantic.BaseModel, metaclass=_Manager):\n\"\"\"Base model provides efficient model persistence and data validation capabilities.\n    The persistence mechanism relies on sqlite and pickle, allowing the entire model to be stored as a snapshot\n\n    Usage:\n\n        class MyModel(BaseModel):\n            name: str\n\n        # store a snapshot of the model\n        stored_model = MyModel(name=\"Model\")\n        stored_model.save()\n\n        # we should be able to retrieve the same model\n        assert MyModel.all() == [stored_model] # True\n    \"\"\"\n\n    _alias: str\n    _conn: Connection\n\n    class Config:\n        # Frozen model behavior\n        # ref: https://docs.pydantic.dev/usage/model_config/\n        frozen = True\n        smart_union = True\n        use_enum_values = True\n        arbitrary_types_allowed = True\n        anystr_strip_whitespace = True\n\n    def __init__(self, *args: Any, **kwargs: Any):\n        try:\n            super().__init__(*args, **kwargs)\n        except ValidationError as e:\n            raise ModelValidationError(f'raised exception during model initialization: {str(e)}')\n\n        sqlite3.register_converter(self._alias, pickle.loads)\n        sqlite3.register_adapter(type(self), pickle.dumps)\n\n    @classmethod\n    @decorators.proxy_exception(\n        expected=sqlite3.ProgrammingError,\n        target=ModelManagerError,\n    )\n    def get(cls) -&gt; Base:\n\"\"\"Exec query and fetch first entry from local database.\n\n        :return: First registered snapshot\n        :raises ModelManagerError: If there is an error fetching entry\n        \"\"\"\n\n        response = cls._conn.execute(FETCH % cls._alias)\n        row = response.fetchone()\n        return row[0]\n\n    @classmethod\n    @decorators.proxy_exception(\n        expected=sqlite3.ProgrammingError,\n        target=ModelManagerError,\n    )\n    def all(cls) -&gt; Iterator[Base]:\n\"\"\"Exec query and fetch a list of data from local database.\n\n        :return: all registered snapshots\n        :raises ModelManagerError: If there is an error fetching entries\n        \"\"\"\n        response = cls._conn.execute(FETCH % cls._alias)\n        rows = response.fetchall()\n        return map(lambda r: r[0], rows)\n\n    @decorators.proxy_exception(\n        expected=sqlite3.ProgrammingError,\n        target=ModelManagerError,\n    )\n    def save(self) -&gt; bool:\n\"\"\"Exec insertion query into local database\n\n        :return: True if successful else False\n        :raises ModelManagerError: If there is an error saving entry\n        \"\"\"\n\n        # https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.lastrowid\n        cursor = self._conn.execute(INSERT % self._alias, (self,))\n        return cursor.rowcount &gt; 0\n</code></pre>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Base.all","title":"<code>all()</code>  <code>classmethod</code>","text":"<p>Exec query and fetch a list of data from local database.</p> <p>Returns:</p> Type Description <code>Iterator[Base]</code> <p>all registered snapshots</p> <p>Raises:</p> Type Description <code>ModelManagerError</code> <p>If there is an error fetching entries</p> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>@classmethod\n@decorators.proxy_exception(\n    expected=sqlite3.ProgrammingError,\n    target=ModelManagerError,\n)\ndef all(cls) -&gt; Iterator[Base]:\n\"\"\"Exec query and fetch a list of data from local database.\n\n    :return: all registered snapshots\n    :raises ModelManagerError: If there is an error fetching entries\n    \"\"\"\n    response = cls._conn.execute(FETCH % cls._alias)\n    rows = response.fetchall()\n    return map(lambda r: r[0], rows)\n</code></pre>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Base.get","title":"<code>get()</code>  <code>classmethod</code>","text":"<p>Exec query and fetch first entry from local database.</p> <p>Returns:</p> Type Description <code>Base</code> <p>First registered snapshot</p> <p>Raises:</p> Type Description <code>ModelManagerError</code> <p>If there is an error fetching entry</p> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>@classmethod\n@decorators.proxy_exception(\n    expected=sqlite3.ProgrammingError,\n    target=ModelManagerError,\n)\ndef get(cls) -&gt; Base:\n\"\"\"Exec query and fetch first entry from local database.\n\n    :return: First registered snapshot\n    :raises ModelManagerError: If there is an error fetching entry\n    \"\"\"\n\n    response = cls._conn.execute(FETCH % cls._alias)\n    row = response.fetchone()\n    return row[0]\n</code></pre>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Base.save","title":"<code>save()</code>","text":"<p>Exec insertion query into local database</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful else False</p> <p>Raises:</p> Type Description <code>ModelManagerError</code> <p>If there is an error saving entry</p> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>@decorators.proxy_exception(\n    expected=sqlite3.ProgrammingError,\n    target=ModelManagerError,\n)\ndef save(self) -&gt; bool:\n\"\"\"Exec insertion query into local database\n\n    :return: True if successful else False\n    :raises ModelManagerError: If there is an error saving entry\n    \"\"\"\n\n    # https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.lastrowid\n    cursor = self._conn.execute(INSERT % self._alias, (self,))\n    return cursor.rowcount &gt; 0\n</code></pre>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Media","title":"<code>Media</code>","text":"<p>         Bases: <code>Base</code>, <code>Generic[T]</code></p> <p>Generic media model to create media subtypes. Each subtype represents a specific media type and provides a generic specification of the sources from which it can be collected.</p> <p>Usage:</p> <pre><code>class Video(Media[Path]):\n    # represents a video file type .\n    ...\n\nclass Image(Media[URL]):\n    # represents an image url type.\n    ...\n</code></pre> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>class Media(Base, Generic[T]):\n\"\"\"Generic media model to create media subtypes.\n    Each subtype represents a specific media type and provides a generic specification\n    of the sources from which it can be collected.\n\n    Usage:\n\n        class Video(Media[Path]):\n            # represents a video file type .\n            ...\n\n        class Image(Media[URL]):\n            # represents an image url type.\n            ...\n    \"\"\"\n\n    path: T\n</code></pre>"},{"location":"reference/harvest/models/#nucleus.sdk.harvest.models.Model","title":"<code>Model</code>","text":"<p>         Bases: <code>Base</code></p> <p>Model class specifies by default the attributes needed for the metadata model and allows its extension to create metadata sub-models with custom attributes.</p> <p>Usage:</p> <pre><code>class Nucleus(Model):\n    name: str # default property\n    description: str # default property\n    address: str # my custom property\n</code></pre> Source code in <code>nucleus/sdk/harvest/models.py</code> <pre><code>class Model(Base):\n\"\"\"Model class specifies by default the attributes needed for the metadata model\n    and allows its extension to create metadata sub-models with custom attributes.\n\n    Usage:\n\n        class Nucleus(Model):\n            name: str # default property\n            description: str # default property\n            address: str # my custom property\n    \"\"\"\n\n    name: str  # the name of the resource\n    description: str  # the description of the resource\n</code></pre>"},{"location":"reference/harvest/types/","title":"Types","text":""},{"location":"reference/harvest/types/#nucleus.sdk.harvest.types.Collector","title":"<code>Collector</code>","text":"<p>         Bases: <code>ABC</code></p> <p>Abstract class for metadata collection. Collector define an abstraction with methods needed to handle metadata collection process. Subclasses should implement the iter method to collect metadata from various data inputs. Use this class to create collector subtypes.</p> <p>Usage:</p> <pre><code>class File(Collector):\n\n    def __iter__(self):\n        # read our file and yield the content\n        with open('dummy.json') as file:\n            for data in json.load(file):\n                yield JSON(data)\n</code></pre> Source code in <code>nucleus/sdk/harvest/types.py</code> <pre><code>class Collector(ABC):\n\"\"\"Abstract class for metadata collection.\n    Collector define an abstraction with methods needed to handle metadata collection process.\n    Subclasses should implement the __iter__ method to collect metadata from various data inputs.\n    Use this class to create collector subtypes.\n\n    Usage:\n\n        class File(Collector):\n\n            def __iter__(self):\n                # read our file and yield the content\n                with open('dummy.json') as file:\n                    for data in json.load(file):\n                        yield JSON(data)\n\n    \"\"\"\n\n    @abstractmethod\n    def __iter__(self) -&gt; Iterator[JSON]:\n\"\"\"Collect metadata from any kind of data input and return an iterator\n\n        :return: The iterable JSON with data to process.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"reference/harvest/types/#nucleus.sdk.harvest.types.Collector.__iter__","title":"<code>__iter__()</code>  <code>abstractmethod</code>","text":"<p>Collect metadata from any kind of data input and return an iterator</p> <p>Returns:</p> Type Description <code>Iterator[JSON]</code> <p>The iterable JSON with data to process.</p> Source code in <code>nucleus/sdk/harvest/types.py</code> <pre><code>@abstractmethod\ndef __iter__(self) -&gt; Iterator[JSON]:\n\"\"\"Collect metadata from any kind of data input and return an iterator\n\n    :return: The iterable JSON with data to process.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/harvest/utilities/","title":"Utilities","text":"<p>Info</p> <p>Partial functions allow us to derive specific functions from complex functions, making their usage simpler. They are particularly useful when creating specialized versions of existing functions, reducing the number of arguments required for each call.</p> <p>Tip</p> <p>We can extend the list of multimedia partials using <code>media_factory</code> and our own media type.</p>"},{"location":"reference/harvest/utilities/#nucleus.sdk.harvest.partials.media_factory","title":"<code>media_factory(*, base, **kwargs)</code>","text":"<p>Generic model factory. Allows the creation of a new model based on the given <code>base</code> model.</p> <p>Usage:</p> <pre><code># create our own media partial\nmusic = functools.partial(media_factory, base=Music)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>base</code> <code>Type[T]</code> <p>The base type for model</p> required <code>**kwargs</code> <code>Any</code> <p>The fields to declare into media model</p> <code>{}</code> <p>Returns:</p> Type Description <code>T</code> <p>New media type instance</p> <p>Raises:</p> Type Description <code>ModelValidationError</code> <p>If model fails during schema validation</p> Source code in <code>nucleus/sdk/harvest/partials.py</code> <pre><code>def media_factory(*, base: Type[T], **kwargs: Any) -&gt; T:\n\"\"\"Generic model factory.\n    Allows the creation of a new model based on the given `base` model.\n\n    Usage:\n\n        # create our own media partial\n        music = functools.partial(media_factory, base=Music)\n\n    :param base: The base type for model\n    :param **kwargs: The fields to declare into media model\n    :return: New media type instance\n    :raises ModelValidationError: If model fails during schema validation\n    \"\"\"\n    try:\n        return parse_obj_as(base, kwargs)\n    except ValidationError as e:\n        raise ModelValidationError(f'exceptions raised during schema validation in partials factory: {str(e)}')\n</code></pre>"},{"location":"reference/harvest/utilities/#built-in-partials","title":"Built-in partials","text":"<pre><code>model = functools.partial(create_model, __base__=Model)\n</code></pre> <p>Info</p> <p>The partial <code>model</code> enhance the <code>create_model</code> pydantic factory function by extending the default model as a base argument. This partial allows the fast creation of metadata models. For more information check here.</p> <pre><code>image = functools.partial(media_factory, base=Image)\nvideo = functools.partial(media_factory, base=Video)\n</code></pre> <p>Info</p> <p>These partial allows the fast creation of media types.</p>"},{"location":"reference/processing/engines/","title":"Engines","text":"<p>Info</p> <p>The engines are adapter classes that facilitate the interaction with underlying libraries, simplifying the processing of multimedia resources. Each engine establishes a contract through a protocol, which allows for the extension to new engines, as well as smooth uniform communication and collaboration.</p>"},{"location":"reference/processing/engines/#nucleus.sdk.processing.engines.ImageEngine","title":"<code>ImageEngine</code>","text":"<p>         Bases: <code>Engine</code></p> <p>Engine that adapts the Pillow library to support image processing.</p> <p>Usage:</p> <pre><code># adapt pillow Image\nlibrary = PIL.open(media.path)\nreturn ImageEngine(library)\n</code></pre> Source code in <code>nucleus/sdk/processing/engines.py</code> <pre><code>class ImageEngine(Engine):\n\"\"\"Engine that adapts the Pillow library to support image processing.\n\n    Usage:\n\n        # adapt pillow Image\n        library = PIL.open(media.path)\n        return ImageEngine(library)\n    \"\"\"\n\n    def __init__(self, lib: Pillow):\n        # compile the pattern to avoid overhead in loop and bind underlying lib\n        self._pattern = re.compile(r'(?&lt;!^)(?=[A-Z])')\n        super().__init__(lib)\n\n    def _to_snake_case(self, class_name: str) -&gt; str:\n\"\"\"Transform PascalCase class definition to snake_case method name\n\n        :para name: The class name to parse\n        :return: The snake case version for class name\n        \"\"\"\n        return self._pattern.sub('_', class_name).lower()\n\n    def _setup_methods(self):\n\"\"\"Call and chain methods based on settings\"\"\"\n        for class_name, params in self.compile():\n            # The method to call should be the same as the option name.\n            method = self._to_snake_case(class_name)\n            func = getattr(self._library, method)\n            # pillow chaining features\n            # all methods return a new instance of the Image class, holding the resulting image\n            # ref:\n            # https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image\n            self._library = func(**dict(params))\n\n    def introspect(self, path: Path) -&gt; Introspection:\n        # fet the mime type from file path\n        (mime_type, _) = mimetypes.guess_type(path)\n        # get attributes from PIL.Image object\n        members = inspect.getmembers(PIL.Image.open(path))\n        filter_private = filter(lambda x: not x[0].startswith('_'), members)\n        filter_method = filter(lambda x: not inspect.ismethod(x[1]), filter_private)\n        image_introspection = _to_object(dict(filter_method))\n        # patch to avoid size conflict keyword\n        delattr(image_introspection, 'size')\n\n        # extend introspection with custom PIL.Image attributes\n        return Introspection(\n            size=path.size(),\n            type=str(mime_type),\n            **vars(image_introspection),\n        )\n\n    def save(self, path: Path) -&gt; File:\n        # We generate the expected path after processing\n        try:\n            self._setup_methods()\n            self._library.save(path)\n\n            # after low level processing happen!!\n            i8t = self.introspect(path)\n            return File(path=path, meta=i8t)\n        except Exception as e:\n            # Standard exceptions raised\n            raise ProcessingEngineError(f'error while trying to save image output: {str(e)}')\n</code></pre>"},{"location":"reference/processing/engines/#nucleus.sdk.processing.engines.VideoEngine","title":"<code>VideoEngine</code>","text":"<p>         Bases: <code>Engine</code></p> <p>Engine that adapts the FFMPEG Python library to support low-level transcoding.</p> <p>Usage:</p> <pre><code># adapt ffmpeg lib\nlibrary = ffmpeg.input(media.path)\nreturn VideoEngine(library)\n</code></pre> Source code in <code>nucleus/sdk/processing/engines.py</code> <pre><code>class VideoEngine(Engine):\n\"\"\"Engine that adapts the FFMPEG Python library to support low-level transcoding.\n\n    Usage:\n\n        # adapt ffmpeg lib\n        library = ffmpeg.input(media.path)\n        return VideoEngine(library)\n    \"\"\"\n\n    def __init__(self, lib: FFMPEG):\n        super().__init__(lib)\n\n    def _build_output_args(self) -&gt; ChainMap[Any, Any]:\n\"\"\"Join config as output arguments for ffmpeg\"\"\"\n        mapped_args = [y for _, y in self.compile()]\n        return ChainMap(*mapped_args)\n\n    def introspect(self, path: Path) -&gt; Introspection:\n        # process the arg path or use the current media file path\n        (mime_type, _) = mimetypes.guess_type(path)\n        video_introspection = _to_object(processing.probe(path))\n\n        # extend introspection with custom video ffprobe\n        return Introspection(\n            size=path.size(),\n            type=str(mime_type),\n            **vars(video_introspection),\n        )\n\n    def save(self, path: Path) -&gt; File:\n        # TODO allow see ffmpeg progress\n        # TODO pubsub? Observer: Keep reading on event?\n        try:\n            output_args = self._build_output_args()\n            # We generate the expected path after transcode\n            self._library.output(path, **output_args).run()\n\n            # after low level processing happen!!\n            i8t = self.introspect(path)\n            return File(path=path, meta=i8t)\n        except Exception as e:\n            # Standard exceptions raised\n            raise ProcessingEngineError(f'error while trying to save video output: {str(e)}')\n</code></pre>"},{"location":"reference/processing/types/","title":"Types","text":""},{"location":"reference/processing/types/#nucleus.sdk.processing.types.Introspection","title":"<code>Introspection</code>","text":"<p>         Bases: <code>Dynamic</code></p> <p>Introspection holds internal media information and metadata. For each result, the media metadata is associated with the <code>meta</code> attribute, and it could change based on the media type and underlying library.</p> <p>Usage:</p> <pre><code># Introspect from ffprobe video info or PIL.Image, etc.\nvideo = Introspection(**ffprobe)\nimage = Introspection(**PIL.Image)\n\n# Introspection dynamically receives all the metadata from the underlying library output.\n# The \"WARNING\" here is that based on the media type,\n# the introspection content could change and requires an extra review.\n</code></pre>"},{"location":"reference/processing/types/#nucleus.sdk.processing.types.File","title":"<code>File</code>","text":"<p>         Bases: <code>Media[Path]</code></p> <p>Local media file representation. This class is used to represent any media stored in local host.</p> <p>Usage:</p> <pre><code># Introspect from ffprobe video info or PIL.Image, etc.\nvideo_meta = Introspection(**ffprobe)\n\n# create a local file with metadata information\nfile = File(Path(\"local_video.mp4\"), video_meta)\n</code></pre>"},{"location":"reference/processing/types/#nucleus.sdk.processing.types.Engine","title":"<code>Engine(lib)</code>","text":"<p>         Bases: <code>ABC</code></p> <p>Engine implements a media engine abstract adapter. It uses an underlying library as an interface to process media files. It produce output based on the provided settings. Use this class to create engine subtypes.</p> <p>Usage:</p> <pre><code>class MusicEngine(Engine):\n\n    def __init__(self, lib: MusicLib):\n        super().__init__(lib)\n\n    def introspect(self, path: Path) -&gt; Introspection:\n        # implementation for introspecting the music file at the specified path\n        ...\n\n    def save(self, path: Path) -&gt; File:\n        # implementation for saving the processed music file to the specified path\n        ...\n</code></pre> <p>Initialize a new instance with bound library</p> Source code in <code>nucleus/sdk/processing/types.py</code> <pre><code>def __init__(self, lib: Any):\n\"\"\"Initialize a new instance with bound library\"\"\"\n    self._library = lib\n    self._settings = []\n</code></pre>"},{"location":"reference/processing/types/#nucleus.sdk.processing.types.Engine.compile","title":"<code>compile()</code>","text":"<p>Compile engine settings into an map of arguments</p> <p>Returns:</p> Type Description <code>Iterator[Tuple[str, Any]]</code> <p>A new map of compiled arguments based on settings</p> Source code in <code>nucleus/sdk/processing/types.py</code> <pre><code>def compile(self) -&gt; Iterator[Tuple[str, Any]]:\n\"\"\"Compile engine settings into an map of arguments\n\n    :return: A new map of compiled arguments based on settings\n    \"\"\"\n    for preset in self._settings:\n        yield type(preset).__name__, dict(preset)\n</code></pre>"},{"location":"reference/processing/types/#nucleus.sdk.processing.types.Engine.configure","title":"<code>configure(setting)</code>","text":"<p>Add setting to media processing context</p> <p>Parameters:</p> Name Type Description Default <code>setting</code> <code>Settings</code> <p>The setting to apply to the engine output.</p> required <p>Returns:</p> Type Description <code>Engine</code> <p>Engine object</p> Source code in <code>nucleus/sdk/processing/types.py</code> <pre><code>def configure(self, setting: Settings) -&gt; Engine:\n\"\"\"Add setting to media processing context\n\n    :param setting: The setting to apply to the engine output.\n    :return: Engine object\n    \"\"\"\n\n    self._settings.append(setting)\n    return self\n</code></pre>"},{"location":"reference/processing/types/#nucleus.sdk.processing.types.Engine.introspect","title":"<code>introspect(path)</code>  <code>abstractmethod</code>","text":"<p>Return technical information of the input media.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The media path</p> required <p>Returns:</p> Type Description <code>Introspection</code> <p>Any technical information collected from media.</p> Source code in <code>nucleus/sdk/processing/types.py</code> <pre><code>@abstractmethod\ndef introspect(self, path: Path) -&gt; Introspection:\n\"\"\"Return technical information of the input media.\n\n    :param path: The media path\n    :return: Any technical information collected from media.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/processing/types/#nucleus.sdk.processing.types.Engine.save","title":"<code>save(path)</code>  <code>abstractmethod</code>","text":"<p>Store the new media based on settings and bound library.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The output path</p> required <p>Returns:</p> Type Description <code>File</code> <p>File object</p> <p>Raises:</p> Type Description <code>ProcessingEngineError</code> <p>If any exception is captured during processing</p> Source code in <code>nucleus/sdk/processing/types.py</code> <pre><code>@abstractmethod\ndef save(self, path: Path) -&gt; File:\n\"\"\"Store the new media based on settings and bound library.\n\n    :param path: The output path\n    :return: File object\n    :raises ProcessingEngineError: If any exception is captured during processing\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/processing/utilities/","title":"Utilities","text":"<p>Info</p> <p>For the inference of engines based on multimedia types, we use the singledispatch decorator to simplify the selection process of the appropriate engines. The decorator transforms a function into a generic function that can have different engine implementations depending on the type of the input media.</p>"},{"location":"reference/processing/utilities/#nucleus.sdk.processing.process.engine","title":"<code>engine(media)</code>","text":"<p>Engine singledispatch factory. Use the media input to infer the right engine.</p> <p>Usage:</p> <pre><code># create an image type to pass into engine function \nimage = harvest.image(path=Path(\"image.jpg\"))\nengine = processing.engine(image)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>media</code> <code>Media[Path]</code> <p>The media type to dispatch</p> required <p>Returns:</p> Type Description <code>Engine</code> <p>The appropriate engine implementation for the type of media</p> <p>Raises:</p> Type Description <code>ProcessingEngineError</code> <p>If any error occurs during engine initialization</p> Source code in <code>nucleus/sdk/processing/process.py</code> <pre><code>@functools.singledispatch\ndef engine(media: Media[Path]) -&gt; Engine:\n\"\"\"Engine singledispatch factory.\n    Use the media input to infer the right engine.\n\n    Usage:\n\n        # create an image type to pass into engine function \n        image = harvest.image(path=Path(\"image.jpg\"))\n        engine = processing.engine(image)\n\n    :param media: The media type to dispatch\n    :return: The appropriate engine implementation for the type of media\n    :raises ProcessingEngineError:  If any error occurs during engine initialization\n\n\n    \"\"\"\n    raise NotImplementedError(f'cannot process not registered media `{media}')\n</code></pre>"},{"location":"reference/processing/image/settings/","title":"Settings","text":""},{"location":"reference/processing/image/settings/#nucleus.sdk.processing.image.settings.Crop","title":"<code>Crop</code>  <code>dataclass</code>","text":"<p>Crop a rectangular region from an image.</p> <p>Usage:</p> <pre><code># crop an image using coords\ncrop = Crop(Coord(10, 10, 50, 50))\n</code></pre> Source code in <code>nucleus/sdk/processing/image/settings.py</code> <pre><code>@dataclass(slots=True)\nclass Crop:\n\"\"\"Crop a rectangular region from an image.\n\n    Usage:\n\n        # crop an image using coords\n        crop = Crop(Coord(10, 10, 50, 50))\n    \"\"\"\n\n    box: Coord\n\n    def __iter__(self):\n        yield 'box', (\n            self.box.left,\n            self.box.top,\n            self.box.right,\n            self.box.bottom,\n        )\n</code></pre>"},{"location":"reference/processing/image/settings/#nucleus.sdk.processing.image.settings.Thumbnail","title":"<code>Thumbnail</code>  <code>dataclass</code>","text":"<p>Resize the image into a thumbnail.</p> <p>Usage:</p> <pre><code># thumbnail size 50x50 pixels\nthumb = Thumbnail(50, 50)\n</code></pre> Source code in <code>nucleus/sdk/processing/image/settings.py</code> <pre><code>@dataclass(slots=True)\nclass Thumbnail:\n\"\"\"Resize the image into a thumbnail.\n\n    Usage:\n\n        # thumbnail size 50x50 pixels\n        thumb = Thumbnail(50, 50)\n    \"\"\"\n\n    _size: Tuple[int, int] = field(init=False)\n    _gap: float = field(init=False)\n    _resample: Resampling = field(init=False)\n\n    width: int\n    height: int\n\n    def __post_init__(self):\n        self._gap = 2.0\n        self._size = (self.width, self.height)\n        self._resample = Resampling.BICUBIC\n\n    def reducing_gap(self, gap: float):\n        self._gap = gap\n\n    def resample(self, resample: Resampling):\n        self._resample = resample\n\n    def __iter__(self):\n        yield 'size', self._size\n        yield 'resample', self._resample\n        yield 'reducing_gap', self._gap\n</code></pre>"},{"location":"reference/processing/image/settings/#nucleus.sdk.processing.image.settings.Resize","title":"<code>Resize</code>  <code>dataclass</code>","text":"<p>Resize the image to a given size.</p> <p>Usage:</p> <pre><code># new image size 100x100\nresize = Resize(100, 100)\n</code></pre> Source code in <code>nucleus/sdk/processing/image/settings.py</code> <pre><code>@dataclass(slots=True)\nclass Resize:\n\"\"\"Resize the image to a given size.\n\n    Usage:\n\n        # new image size 100x100\n        resize = Resize(100, 100)\n    \"\"\"\n\n    _size: Tuple[int, int] = field(init=False)\n    _box: Tuple[int, int, int, int] = field(init=False)\n    _resample: Resampling = field(init=False)\n\n    width: int\n    height: int\n\n    def __post_init__(self):\n        self._size = (self.width, self.height)\n        self._box = (0, 0, *self._size)\n        self._resample = Resampling.BICUBIC\n\n    def crop(self, box: Coord):\n        self._box = (box.left, box.top, box.right, box.bottom)\n\n    def resample(self, resample: Resampling):\n        self._resample = resample\n\n    def __iter__(self):\n        yield 'size', self._size\n        yield 'resample', self._resample\n        yield 'box', self._box\n</code></pre>"},{"location":"reference/processing/image/settings/#coordinate-system","title":"Coordinate System","text":"<p>\"The Python Imaging Library uses a Cartesian pixel coordinate system, with (0,0) in the upper left corner. Note that the coordinates refer to the implied pixel corners; the centre of a pixel addressed as (0, 0) actually lies at (0.5, 0.5).\" - pillow</p> <p>Note</p> <p>During processing time, the setting classes are parsed as a method to dynamically call pillow image object. To know more about the settings implemented in this reference please see pillow docs.</p>"},{"location":"reference/processing/image/settings/#nucleus.sdk.processing.image.settings.Coord","title":"<code>Coord</code>  <code>dataclass</code>","text":"<p>Represents a cartesian pixel coordinate.</p> <p>Usage:</p> <pre><code># two points in the cartesian plane: top + left, right + bottom\ncoord = Coord(10, 10, 50, 50) # left, top, right, bottom coordinates\n</code></pre> Source code in <code>nucleus/sdk/processing/image/settings.py</code> <pre><code>@dataclass(slots=True)\nclass Coord:\n\"\"\"Represents a cartesian pixel coordinate.\n\n    Usage:\n\n        # two points in the cartesian plane: top + left, right + bottom\n        coord = Coord(10, 10, 50, 50) # left, top, right, bottom coordinates\n    \"\"\"\n\n    left: int\n    top: int\n    right: int\n    bottom: int\n</code></pre>"},{"location":"reference/processing/video/codecs/","title":"Codecs","text":"<p>Info</p> <p>Most of the parameters set for the codecs are those established by default in ffmpeg official docs. However, some parameters have been modified in order to achieve an improvement in performance. </p> <pre><code># HLS default constants\n# https://developer.apple.com/documentation/http-live-streaming/hls-authoring-specification-for-apple-devices\nHLS_TIME = 10\nHLS_LIST_SIZE = 0\nHLS_TAG_VIDEO_FORMAT = 'hvc1'\nHLS_PLAYLIST_TYPE = 'vod'\n\n\nDEFAULT_AUDIO_CODEC = 'aac'\n# The range of the CRF scale is 0\u201351, where 0 is lossless (higher quality)\nDEFAULT_CRF = 0\n# The preset determines compression efficiency and therefore affects encoding speed\n# This option itemizes a range of choices from veryfast (best speed) to\n# veryslow (best quality).\nDEFAULT_PRESET = 'medium'\n# keyframes minimum every 100 frames\nDEFAULT_KEY_MIN = 100\n# maximum amount of GOP size, maximum every 100 frames there will be a\n# keyframe, together with -keyint_min this gives a keyframe every 100\n# frames\nDEFAULT_GOP = 100\n# ffmpeg has scene detection. 0 (stands for false)\nDEFAULT_SC_THRESHOLD = 0\n</code></pre>"},{"location":"reference/processing/video/codecs/#nucleus.sdk.processing.video.codecs.Copy","title":"<code>Copy</code>","text":"<p>Used to <code>copy</code> the codec from the source to the output. Special value copy (output only) to indicate that the stream is not to be re-encoded.</p> <p>Usage:</p> <pre><code>copy_audio_stream = Copy(\"a\")\ncopy_video_stream = Copy(\"v\")\n</code></pre> Source code in <code>nucleus/sdk/processing/video/codecs.py</code> <pre><code>class Copy:\n\"\"\"Used to `copy` the codec from the source to the output.\n    Special value copy (output only) to indicate that the stream is not to be re-encoded.\n\n    Usage:\n\n        copy_audio_stream = Copy(\"a\")\n        copy_video_stream = Copy(\"v\")\n    \"\"\"\n\n    _stream_specifier: str\n\n    def __init__(self, stream: Literal['v', 'a'] = 'v'):  # noqa: F821\n        self._stream_specifier = stream\n\n    def __contains__(self, codec: str) -&gt; bool:\n        ...\n\n    def __iter__(self):\n        yield f'c:{self._stream_specifier}', 'copy'\n</code></pre>"},{"location":"reference/processing/video/codecs/#nucleus.sdk.processing.video.codecs.H264","title":"<code>H264</code>","text":"<p>H264 codec ffmpeg settings.</p> <p>Usage:</p> <pre><code>h264 = H264()\n</code></pre> Source code in <code>nucleus/sdk/processing/video/codecs.py</code> <pre><code>class H264:\n\"\"\"H264 codec ffmpeg settings.\n\n    Usage:\n\n        h264 = H264()\n\n    \"\"\"\n\n    def __contains__(self, codec: str) -&gt; bool:\n        videos = ['libx264', 'h264', 'h264_afm', 'h264_nvenc']\n        audios = ['aac', 'libvo_aacenc', 'libfaac', 'libmp3lame', 'libfdk_aac']\n        allowed_codecs = videos + audios\n        return codec in allowed_codecs\n\n    def __iter__(self):\n        yield 'bf', 1\n        yield 'g', DEFAULT_GOP\n        yield 'crf', DEFAULT_CRF\n        yield 'keyint_min', DEFAULT_KEY_MIN\n        yield 'sc_threshold', DEFAULT_SC_THRESHOLD\n        yield 'c:a', DEFAULT_AUDIO_CODEC\n        yield 'c:v', 'libx264'\n</code></pre>"},{"location":"reference/processing/video/codecs/#nucleus.sdk.processing.video.codecs.HEVC","title":"<code>HEVC</code>","text":"<p>HEVC codec ffmpeg settings.</p> <p>Usage:</p> <pre><code>hevc = HEVC()\n</code></pre> Source code in <code>nucleus/sdk/processing/video/codecs.py</code> <pre><code>class HEVC:\n\"\"\"HEVC codec ffmpeg settings.\n\n    Usage:\n\n        hevc = HEVC()\n\n    \"\"\"\n\n    def __contains__(self, codec: str) -&gt; bool:\n        videos = ['libx265', 'h265']\n        audios = ['aac', 'libvo_aacenc', 'libfaac', 'libmp3lame', 'libfdk_aac']\n        allowed_codecs = videos + audios\n        return codec in allowed_codecs\n\n    def __iter__(self):\n        yield 'g', DEFAULT_GOP\n        yield 'crf', DEFAULT_CRF\n        yield 'keyint_min', DEFAULT_KEY_MIN\n        yield 'sc_threshold', DEFAULT_SC_THRESHOLD\n        yield 'c:a', DEFAULT_AUDIO_CODEC\n        yield 'c:v', 'libx265'\n        yield 'x265-params', 'lossless=1'\n</code></pre>"},{"location":"reference/processing/video/codecs/#nucleus.sdk.processing.video.codecs.VP9","title":"<code>VP9</code>","text":"<p>Vp9 codec ffmpeg settings.</p> <p>Usage:</p> <pre><code>vp9 = VP9()\n</code></pre> Source code in <code>nucleus/sdk/processing/video/codecs.py</code> <pre><code>class VP9:\n\"\"\"Vp9 codec ffmpeg settings.\n\n    Usage:\n\n        vp9 = VP9()\n\n    \"\"\"\n\n    def __contains__(self, codec: str) -&gt; bool:\n        videos = ['libvpx', 'libvpx-vp9']\n        audios = ['aac', 'libvo_aacenc', 'libfaac', 'libmp3lame', 'libfdk_aac']\n        allowed_codecs = videos + audios\n        return codec in allowed_codecs\n\n    def __iter__(self):\n        yield 'c:a', DEFAULT_AUDIO_CODEC\n        yield 'c:v', 'libvpx-vp9'\n</code></pre>"},{"location":"reference/processing/video/protocols/","title":"Protocols","text":""},{"location":"reference/processing/video/protocols/#nucleus.sdk.processing.video.protocols.HLS","title":"<code>HLS</code>  <code>dataclass</code>","text":"<p>HLS streaming protocol.</p> <p>Usage:</p> <pre><code># use h264 as codec\nhls = HLS(H264())\n</code></pre> Source code in <code>nucleus/sdk/processing/video/protocols.py</code> <pre><code>@dataclass(slots=True)\nclass HLS:\n\"\"\"HLS streaming protocol.\n\n    Usage:\n\n        # use h264 as codec\n        hls = HLS(H264())\n\n    \"\"\"\n\n    codec: Codec\n\n    def __iter__(self):\n        yield 'hls_time', HLS_TIME\n        yield 'hls_list_size', HLS_LIST_SIZE\n        yield 'hls_playlist_type', HLS_PLAYLIST_TYPE,\n        yield 'tag:v', HLS_TAG_VIDEO_FORMAT,\n        yield from self.codec\n</code></pre>"},{"location":"reference/processing/video/settings/","title":"Settings","text":""},{"location":"reference/processing/video/settings/#nucleus.sdk.processing.video.settings.FPS","title":"<code>FPS</code>  <code>dataclass</code>","text":"<p>Set the frame rate (Hz value, fraction or abbreviation).</p> <p>Usage:</p> <pre><code># frame per seconds\nfps = FPS(fs=60)\n</code></pre> Source code in <code>nucleus/sdk/processing/video/settings.py</code> <pre><code>@dataclass(slots=True)\nclass FPS:\n\"\"\"Set the frame rate (Hz value, fraction or abbreviation).\n\n    Usage:\n\n        # frame per seconds\n        fps = FPS(fs=60)\n    \"\"\"\n\n    fps: float\n\n    def __iter__(self):\n        yield 'r', self.fps\n</code></pre>"},{"location":"reference/processing/video/settings/#nucleus.sdk.processing.video.settings.BR","title":"<code>BR</code>  <code>dataclass</code>","text":"<p>Set the Video/Audio bitrate.</p> <p>Usage:</p> <pre><code># set bitrate for both streams or independent\nbr = BR(100) # audio/video\nbr = BR(150, 94) # video b:v 150, audio b:a 94\n</code></pre> Source code in <code>nucleus/sdk/processing/video/settings.py</code> <pre><code>@dataclass(slots=True)\nclass BR:\n\"\"\"Set the Video/Audio bitrate.\n\n    Usage:\n\n        # set bitrate for both streams or independent\n        br = BR(100) # audio/video\n        br = BR(150, 94) # video b:v 150, audio b:a 94\n\n    \"\"\"\n\n    video: int\n    audio: int = 0\n\n    def __iter__(self):\n        # if we only receive video bitrate, we consider it as overall bitrate\n        if self.video and not self.audio:\n            yield 'b', f'{self.video}k'\n            return\n\n        yield 'b:v', f'{self.video}k'\n        yield 'b:a', f'{self.audio}k'\n</code></pre>"},{"location":"reference/processing/video/settings/#nucleus.sdk.processing.video.settings.Custom","title":"<code>Custom</code>  <code>dataclass</code>","text":"<p>Special class for directly specifying custom settings to the ffmpeg command.</p> <p>Usage:</p> <pre><code># create a custom command based on ffmpeg option -fs\n# No further chunk of bytes is written after the limit is exceeded.\ncustom = Custom(fs=100)\n</code></pre> Source code in <code>nucleus/sdk/processing/video/settings.py</code> <pre><code>@dataclass(slots=True)\nclass Custom:\n\"\"\"Special class for directly specifying custom settings to the ffmpeg command.\n\n    Usage:\n\n        # create a custom command based on ffmpeg option -fs\n        # No further chunk of bytes is written after the limit is exceeded.\n        custom = Custom(fs=100)\n    \"\"\"\n\n    _custom: Mapping[str, Any]\n\n    def __init__(self, **kwargs: Any):\n        self._custom = kwargs\n\n    def __iter__(self):\n        yield from self._custom.items()\n</code></pre>"},{"location":"reference/processing/video/settings/#nucleus.sdk.processing.video.settings.FrameSize","title":"<code>FrameSize</code>  <code>dataclass</code>","text":"<p>Set the frame size.</p> <p>Usage:</p> <pre><code># the output screen size\nsize = FrameSize(200, 200)\n</code></pre> Source code in <code>nucleus/sdk/processing/video/settings.py</code> <pre><code>@dataclass(slots=True)\nclass FrameSize:\n\"\"\"Set the frame size.\n\n    Usage:\n\n        # the output screen size\n        size = FrameSize(200, 200)\n    \"\"\"\n\n    width: int\n    height: int\n\n    def __str__(self) -&gt; str:\n        return f'{self.width}x{self.height}'\n\n    def __iter__(self):\n        yield 's', str(self)\n</code></pre>"},{"location":"reference/processing/video/settings/#defaults","title":"Defaults","text":"<p>Note</p> <p>During processing time, the setting classes are parsed as configuration arguments for FFMPEG python library. To know more about the settings implemented in this reference please see FFMPEG main options.</p>"},{"location":"reference/processing/video/settings/#nucleus.sdk.processing.video.settings.Screen","title":"<code>Screen</code>  <code>dataclass</code>","text":"<p>Default standard screen size settings.</p> <p>Usage:</p> <pre><code># using default screen sizes\nbr = Screen.Q720 # appropriate size 720p\n</code></pre> Source code in <code>nucleus/sdk/processing/video/settings.py</code> <pre><code>@dataclass(frozen=True)\nclass Screen:\n\"\"\"Default standard screen size settings.\n\n    Usage:\n\n        # using default screen sizes\n        br = Screen.Q720 # appropriate size 720p\n\n    \"\"\"\n\n    Q240 = FrameSize(416, 234)\n    Q360 = FrameSize(640, 360)\n    Q480 = FrameSize(854, 480)\n    Q720 = FrameSize(1280, 720)\n    Q1080 = FrameSize(1920, 1080)\n    Q2k = FrameSize(2560, 1440)\n    Q4k = FrameSize(3840, 2160)\n</code></pre>"},{"location":"reference/processing/video/settings/#nucleus.sdk.processing.video.settings.Bitrate","title":"<code>Bitrate</code>  <code>dataclass</code>","text":"<p>Default standard bitrate settings.</p> <p>Usage:</p> <pre><code># using default standard bitrate\nbr = Bitrate.B720 # appropriate bitrate for 720p\n</code></pre> Source code in <code>nucleus/sdk/processing/video/settings.py</code> <pre><code>@dataclass(frozen=True)\nclass Bitrate:\n\"\"\"Default standard bitrate settings.\n\n    Usage:\n\n        # using default standard bitrate\n        br = Bitrate.B720 # appropriate bitrate for 720p\n    \"\"\"\n\n    B240 = BR(150, 94)\n    B360 = BR(276, 128)\n    B480 = BR(750, 192)\n    B720 = BR(2048, 320)\n    B1080 = BR(4096, 320)\n    B2k = BR(6144, 320)\n    B4k = BR(17408, 320)\n</code></pre>"},{"location":"reference/processing/video/types/","title":"Types","text":""},{"location":"reference/processing/video/types/#nucleus.sdk.processing.video.types.Codec","title":"<code>Codec</code>","text":"<p>         Bases: <code>Settings</code>, <code>Protocol</code></p> <p>Codec specify the behavior of video compression formats.</p>"},{"location":"reference/processing/video/types/#nucleus.sdk.processing.video.types.Codec.__contains__","title":"<code>__contains__(codec)</code>","text":"<p>Check if the available codecs contain the specified codec. This method can be useful to avoid re-encoding by checking if a codec match exists allowing for a direct copy operation.</p> <p>Parameters:</p> Name Type Description Default <code>codec</code> <code>str</code> <p>The name of the codec to match</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if match else False</p> Source code in <code>nucleus/sdk/processing/video/types.py</code> <pre><code>def __contains__(self, codec: str) -&gt; bool:\n\"\"\"Check if the available codecs contain the specified codec.\n    This method can be useful to avoid re-encoding by checking if a codec match exists\n    allowing for a direct copy operation.\n\n    :param codec: The name of the codec to match\n    :returns: True if match else False\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/storage/services/","title":"Services","text":"<p>Info</p> <p>Services are storage providers within the IPFS ecosystem. Any storage service that exposes an API is compatible and can be integrated into the SDK by implementing the service protocol.</p>"},{"location":"reference/storage/services/#nucleus.sdk.storage.services.Estuary","title":"<code>Estuary</code>  <code>dataclass</code>","text":"<p>Estuary API service client.</p> <p>Usage:</p> <pre><code>estuary_endpoint = \"https://api.estuary.tech\"\nestuary_key =  \"ESTbb693fa8-d758-48ce-9843-a8acadb98a53ARY\" # fake key\nestuary = EstuaryClient(estuary_endpoint, estuary_key)\n\npin = estuary.pin(stored_object)\nremoved_cid = estuary.unpin(pin.cid)\n</code></pre> Source code in <code>nucleus/sdk/storage/services.py</code> <pre><code>@dataclass\nclass Estuary:\n\"\"\"Estuary API service client.\n\n    Usage:\n\n        estuary_endpoint = \"https://api.estuary.tech\"\n        estuary_key =  \"ESTbb693fa8-d758-48ce-9843-a8acadb98a53ARY\" # fake key\n        estuary = EstuaryClient(estuary_endpoint, estuary_key)\n\n        pin = estuary.pin(stored_object)\n        removed_cid = estuary.unpin(pin.cid)\n\n\n    \"\"\"\n\n    endpoint: URL\n    key: str\n\n    def __post_init__(self):\n        self._http = http_client.live_session(self.endpoint)\n        self._http.headers.update({'Authorization': f'Bearer {self.key}'})\n\n    def _safe_request(self, res: Response) -&gt; JSON:\n\"\"\"Amplifier helper method to handle response from Estuary API\n\n        :param res: Expected response\n        :return: Json response\n        :raises StorageServiceError: If an error occurs during request\n        \"\"\"\n\n        # expected response as json\n        response = res.json()\n\n        # if response fail\n        if not res.ok:\n\"\"\"\n            Observable behavior:\n                {\n                    \"code\": 0,\n                    \"details\": \"string\",\n                    \"reason\": \"string\"\n                }\n            \"\"\"\n            error_description = response['error']['details']\n            raise StorageServiceError(f'exception raised during request: {error_description}')\n\n        return JSON(response)\n\n    def _content_by_cid(self, cid: CID) -&gt; JSON:\n\"\"\"Collect details from estuary based on CID\n        ref: https://docs.estuary.tech/Reference/SwaggerUI#/public/get_public_by_cid__cid_\n\n        :param cid: Cid to retrieve content details\n        :return: Cid content details\n        :raises EdgePinException: If pin request fails\n        \"\"\"\n\n        content_uri = f'{ESTUARY_API_PUBLIC}/by-cid/{cid}'\n        req = self._http.get(content_uri)\n\n        # expected response as json\n        response = self._safe_request(req)\n        return response.get('content', {})\n\n    def pin(self, obj: Object, **kwargs: Any) -&gt; Pin:\n\"\"\"Pin cid into estuary\n\n        :param obj: Object to pin\n        :return: Pin object\n        :raises StorageServiceError: If pin request fails\n        \"\"\"\n\n        # https://docs.estuary.tech/Reference/SwaggerUI#/pinning/post_pinning_pins\n        data = {'cid': obj.hash, **kwargs}\n        req = self._http.post(ESTUARY_API_PIN, data=data)\n        json_response = self._safe_request(req)\n\n        return Pin(\n            cid=json_response['cid'],\n            name=json_response['name'],\n            status='pending',\n        )\n\n    def unpin(self, cid: CID) -&gt; CID:\n\"\"\"Remove pin from estuary\n\n        :param cid: The cid to remove from service\n        :return: The recently removed CID\n        :raises StorageServiceError: if an error occurs during request\n        \"\"\"\n\n        # content id is same as pin id\n        pin_id = self._content_by_cid(cid).get('id')\n        response = self._http.delete(f'{ESTUARY_API_PIN}/{pin_id}')\n        # If error happens then raise standard exception.\n        self._safe_request(response)\n        return cid\n</code></pre>"},{"location":"reference/storage/services/#nucleus.sdk.storage.services.Estuary.pin","title":"<code>pin(obj, **kwargs)</code>","text":"<p>Pin cid into estuary</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Object</code> <p>Object to pin</p> required <p>Returns:</p> Type Description <code>Pin</code> <p>Pin object</p> <p>Raises:</p> Type Description <code>StorageServiceError</code> <p>If pin request fails</p> Source code in <code>nucleus/sdk/storage/services.py</code> <pre><code>def pin(self, obj: Object, **kwargs: Any) -&gt; Pin:\n\"\"\"Pin cid into estuary\n\n    :param obj: Object to pin\n    :return: Pin object\n    :raises StorageServiceError: If pin request fails\n    \"\"\"\n\n    # https://docs.estuary.tech/Reference/SwaggerUI#/pinning/post_pinning_pins\n    data = {'cid': obj.hash, **kwargs}\n    req = self._http.post(ESTUARY_API_PIN, data=data)\n    json_response = self._safe_request(req)\n\n    return Pin(\n        cid=json_response['cid'],\n        name=json_response['name'],\n        status='pending',\n    )\n</code></pre>"},{"location":"reference/storage/services/#nucleus.sdk.storage.services.Estuary.unpin","title":"<code>unpin(cid)</code>","text":"<p>Remove pin from estuary</p> <p>Parameters:</p> Name Type Description Default <code>cid</code> <code>CID</code> <p>The cid to remove from service</p> required <p>Returns:</p> Type Description <code>CID</code> <p>The recently removed CID</p> <p>Raises:</p> Type Description <code>StorageServiceError</code> <p>if an error occurs during request</p> Source code in <code>nucleus/sdk/storage/services.py</code> <pre><code>def unpin(self, cid: CID) -&gt; CID:\n\"\"\"Remove pin from estuary\n\n    :param cid: The cid to remove from service\n    :return: The recently removed CID\n    :raises StorageServiceError: if an error occurs during request\n    \"\"\"\n\n    # content id is same as pin id\n    pin_id = self._content_by_cid(cid).get('id')\n    response = self._http.delete(f'{ESTUARY_API_PIN}/{pin_id}')\n    # If error happens then raise standard exception.\n    self._safe_request(response)\n    return cid\n</code></pre>"},{"location":"reference/storage/types/","title":"Types","text":""},{"location":"reference/storage/types/#nucleus.sdk.storage.types.Object","title":"<code>Object</code>  <code>dataclass</code>","text":"<p>Distributed/Stored media representation. This class is used to represent any media decentralized and already stored in IPFS.</p> <p>Usage:</p> <pre><code># generally, these objects are returned by storage operations\nstored_object = Object(\"bafyjvzacdjrk37kqvy5hbqepmcraz3txt3igs7dbjwwhlfm3433a\",\"image\",250)\n</code></pre> Source code in <code>nucleus/sdk/storage/types.py</code> <pre><code>@dataclass(slots=True)\nclass Object:\n\"\"\"Distributed/Stored media representation.\n    This class is used to represent any media decentralized and already stored in IPFS.\n\n    Usage:\n\n        # generally, these objects are returned by storage operations\n        stored_object = Object(\"bafyjvzacdjrk37kqvy5hbqepmcraz3txt3igs7dbjwwhlfm3433a\",\"image\",250)\n    \"\"\"\n\n    hash: CID\n    name: str\n    size: int\n</code></pre>"},{"location":"reference/storage/types/#nucleus.sdk.storage.types.Pin","title":"<code>Pin</code>  <code>dataclass</code>","text":"<p>Represents ipfs pin output</p> <p>Usage:</p> <pre><code># generally, returned by pinning operations\npin = Pin(\"bafyjvzacdjrk37kqvy5hbqepmcraz3txt3igs7dbjwwhlfm3433a\",\"pinned\", \"image.jpg\")\n</code></pre> Source code in <code>nucleus/sdk/storage/types.py</code> <pre><code>@dataclass(slots=True)\nclass Pin:\n\"\"\"Represents ipfs pin output\n\n    Usage:\n\n        # generally, returned by pinning operations\n        pin = Pin(\"bafyjvzacdjrk37kqvy5hbqepmcraz3txt3igs7dbjwwhlfm3433a\",\"pinned\", \"image.jpg\")\n    \"\"\"\n\n    cid: CID\n    status: str\n    name: Optional[str]\n</code></pre>"},{"location":"reference/storage/types/#nucleus.sdk.storage.types.Client","title":"<code>Client</code>","text":"<p>         Bases: <code>Protocol</code></p> <p>Provides an standard interface for handling IPFS storage services. Each storage service represents a remote cache service, such as Estuary. This class can be used as a base to create subtypes for specific edge clients.</p> <p>Usage:</p> <pre><code>class EdgeService:\n\n    def pin(self, obj: Object, **kwargs: Any) -&gt; Pin:\n        # implementation for pinning the object\n        ...\n\n    def unpin(self, cid: CID) -&gt; CID:\n        # implementation for unpinning the CID\n        ...\n</code></pre> Source code in <code>nucleus/sdk/storage/types.py</code> <pre><code>class Client(Protocol):\n\"\"\"Provides an standard interface for handling IPFS storage services. Each storage service\n    represents a remote cache service, such as Estuary. This class can be used as a base to\n    create subtypes for specific edge clients.\n\n    Usage:\n\n        class EdgeService:\n\n            def pin(self, obj: Object, **kwargs: Any) -&gt; Pin:\n                # implementation for pinning the object\n                ...\n\n            def unpin(self, cid: CID) -&gt; CID:\n                # implementation for unpinning the CID\n                ...\n\n    \"\"\"\n\n    def pin(self, obj: Object) -&gt; Pin:\n\"\"\"Pin cid to storage service\n\n        :param obj: Object to pin\n        :return: Pin object\n        \"\"\"\n        ...\n\n    def unpin(self, cid: CID) -&gt; CID:\n\"\"\"Remove pin from storage service\n\n        :param cid: The cid to remove from service\n        :return: The just removed object cid\n        \"\"\"\n        ...\n</code></pre>"},{"location":"reference/storage/types/#nucleus.sdk.storage.types.Client.pin","title":"<code>pin(obj)</code>","text":"<p>Pin cid to storage service</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Object</code> <p>Object to pin</p> required <p>Returns:</p> Type Description <code>Pin</code> <p>Pin object</p> Source code in <code>nucleus/sdk/storage/types.py</code> <pre><code>def pin(self, obj: Object) -&gt; Pin:\n\"\"\"Pin cid to storage service\n\n    :param obj: Object to pin\n    :return: Pin object\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/storage/types/#nucleus.sdk.storage.types.Client.unpin","title":"<code>unpin(cid)</code>","text":"<p>Remove pin from storage service</p> <p>Parameters:</p> Name Type Description Default <code>cid</code> <code>CID</code> <p>The cid to remove from service</p> required <p>Returns:</p> Type Description <code>CID</code> <p>The just removed object cid</p> Source code in <code>nucleus/sdk/storage/types.py</code> <pre><code>def unpin(self, cid: CID) -&gt; CID:\n\"\"\"Remove pin from storage service\n\n    :param cid: The cid to remove from service\n    :return: The just removed object cid\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/storage/utilities/","title":"Utilities","text":"<p>Info</p> <p><code>Store</code> is a repository of storage options in the form of a function that automatically selects the appropriate storage strategy based on the type of the parameter</p>"},{"location":"reference/storage/utilities/#nucleus.sdk.storage.store.ipfs","title":"<code>ipfs(endpoint=None)</code>","text":"<p>Higher-order function to handle storage endpoint and return a singledispatch generic function with preset storage strategies. This is a form of generic function dispatch where the implementation is chosen based on the type of a single argument.</p> <p>Usage:</p> <pre><code>store = storage.ipfs() # default localhost:5001\nstored_object = store(b'test bytes') # auto-choose the storage strategy\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>endpoint</code> <code>Optional[str]</code> <p>Endpoint to connect to the API. If the endpoint is not specified, localhost is used instead.</p> <code>None</code> <p>Returns:</p> Type Description <code>Store</code> <p>Singledispatch decorated function</p> Source code in <code>nucleus/sdk/storage/store.py</code> <pre><code>def ipfs(endpoint: Optional[str] = None) -&gt; Store:\n\"\"\"Higher-order function to handle storage endpoint and\n    return a singledispatch generic function with preset storage strategies.\n    This is a form of generic function dispatch where the\n    implementation is chosen based on the type of a single argument.\n\n    Usage:\n\n        store = storage.ipfs() # default localhost:5001\n        stored_object = store(b'test bytes') # auto-choose the storage strategy\n\n\n    :param endpoint: Endpoint to connect to the API. If the endpoint is not specified, localhost is used instead.\n    :return: Singledispatch decorated function\n    \"\"\"\n\n    # Connect to the IPFS API interface\n    api = ipfs_.rpc(endpoint)\n\n    @functools.singledispatch\n    def store(data: Storable) -&gt; Object:\n\"\"\"Storage single dispatch factory.\n        Uses the data input type to infer the right storage strategy.\n\n        :param data: The model to dispatch\n        :return: Object instance\n        \"\"\"\n        raise NotImplementedError(f'cannot process not registered storable `{data}')\n\n    @store.register\n    def _(data: FileType) -&gt; Object:\n\"\"\"Store files in IPFS.\n\n        :param data: String to store\n        :return: Object instance\n        \"\"\"\n        command = Add(File(data.path))\n        # expected /add output from API\n        # {Hash: .., Name: .., Size: ...}\n        file_output = api(command)\n\n        return Object(\n            name=file_output['Name'],\n            hash=CID(file_output['Hash']),\n            size=int(file_output['Size']),\n        )\n\n    @store.register\n    def _(data: bytes) -&gt; Object:\n\"\"\"Store bytes in IPFS.\n        Store bytes in raw blocks.\n\n        :param data: Bytes to store\n        :return: Object instance\n        \"\"\"\n\n        command = BlockPut(Text(data))\n        # expected block/put output from API\n        # {Key: .., Size: ..}\n        output = api(command)\n\n        return Object(\n            name=output['Key'],\n            hash=CID(output['Key']),\n            size=len(data),\n        )\n\n    @store.register\n    def _(data: str) -&gt; Object:\n\"\"\"String string in IPFS.\n        Encode string to bytes and store it in raw blocks.\n\n        :param data: String to store\n        :return: Object instance\n        \"\"\"\n\n        bytes_ = bytes(data, 'utf-8')\n        return store(bytes_)\n\n    @store.register\n    def _(data: JSON) -&gt; Object:\n\"\"\"Store JSON in IPFS Dag.\n\n        :param data: JSON to store\n        :return: Object instance\n        \"\"\"\n\n        bytes_ = bytes(data)\n        command = DagPut(Text(bytes_))\n        # expected block/put output from API\n        # {\"Cid\": { \"/\": \"&lt;cid-string&gt;\" }}\n        output = api(command)\n        raw_cid = output['Cid']['/']\n\n        return Object(\n            name=raw_cid,\n            hash=CID(raw_cid),\n            size=len(data),\n        )\n\n    return store\n</code></pre>"},{"location":"reference/storage/utilities/#built-in-partials","title":"Built-in partials","text":"<pre><code># default request to https://api.estuary.tech\nestuary = functools.partial(Estuary, ESTUARY_API_BASE)\n</code></pre> <p>Info</p> <p>These partial allows the fast creation of services.</p>"}]}